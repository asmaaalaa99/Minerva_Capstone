{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Libraries "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import os\nimport sys\n# Repository source: https://github.com/qubvel/efficientnet\nimport tensorflow \nfrom tensorflow.python.keras.applications.efficientnet import EfficientNetB3\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential,Model\n\nimport glob\nfrom tensorflow.keras.layers import TimeDistributed, GRU, Dense, Dropout\nimport numpy as np\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.layers import Dense, LSTM\nfrom tensorflow.keras.models import load_model, Model\n\n\nimport re\nfrom tensorflow.keras.backend import argmax\nfrom tensorflow.keras.models  Sequential\n\nimport numpy as np\nfrom tensorflow.keras.layers import TimeDistributed, GRU, Dense, Dropout\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\nimport time\nimport os.path\n\n#metrices \n# demonstration of calculating metrics for a neural network model using sklearn\nfrom sklearn.datasets import make_circles\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Arcface Loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport math as m\nimport tensorflow \nfrom tensorflow.python.keras.applications.efficientnet import EfficientNetB3\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow as tf\n#reused code from the original paper: https://github.com/deepinsight/insightface\ndef get_logits(labels, y_pred):\n    s = 64.\n    cos_t = y_pred\n    sin_m = tf.math.sin(0.5)\n    cos_m = tf.math.cos(0.5)\n    cos_t2 = tf.square(cos_t, name='cos_2')\n    sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n    sin_t = tf.sqrt(sin_t2, name='sin_t')\n    cos_mt = s * tf.subtract(tf.multiply(cos_t, cos_m), tf.multiply(sin_t, sin_m), name='cos_mt')\n    threshold = tf.math.cos(tf.constant(m.pi) - 0.5)\n    cond_v = cos_t - threshold\n    cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n    mm = sin_m * 0.5\n    keep_val = s*(cos_t - mm)\n    cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n    mask = tf.one_hot(labels, depth=2, name='one_hot_mask')\n    inv_mask = tf.subtract(1., mask, name='inverse_mask')\n    s_cos_t = tf.multiply(s, cos_t, name='scalar_cos_t')\n    output = tf.add(tf.multiply(s_cos_t, inv_mask), tf.multiply(cos_mt_temp, mask), name='arcface_logits')\n    return output\ndef loss(y_true, y_pred):\n    labels = argmax(y_true, axis=-1)\n    logits = get_logits(labels, y_pred)\n    #tf.keras.losses.SparseCategoricalCrossentropy()\n    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n    return loss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extract the Features From the Images "},{"metadata":{"trusted":true},"cell_type":"code","source":"Processed_datasets = {\n    'train_dir': '../input/capstone-dataset/base__dir/train_dir',\n    'val_dir': '../input/capstone-dataset/base__dir/val_dir',\n    'test_dir':'../input/capstone-dataset/base__dir/test_dir'\n    \n}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/capstone-dataset/base__dir/train_data.csv\")\ndf_val = pd.read_csv(\"../input/capstone-dataset/base__dir/val_data.csv\")\ndf_test = pd.read_csv(\"../input/capstone-dataset/base__dir/test_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_train_samples = len(df_train)\nnum_val_samples = len(df_val)\nnum_test_samples = len(df_test)\n\ntrain_batch_size = 10\nval_batch_size = 10\ntest_batch_size = 10\n\ntrain_steps = np.ceil(num_train_samples / train_batch_size)\nval_steps = np.ceil(num_val_samples / val_batch_size)\ntest_steps = np.ceil(num_test_samples / test_batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(rescale=1.0/255)\n\ntrain_gen = datagen.flow_from_directory(Processed_datasets['train_dir'],\n                                        target_size=(299,299),\n                                        batch_size=train_batch_size,\n                                        class_mode='categorical')\n\nval_gen = datagen.flow_from_directory(Processed_datasets['val_dir'],\n                                        target_size=(299,299),\n                                        batch_size=val_batch_size,\n                                        class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"effnet = EfficientNetB3(weights = \"imagenet\", include_top = False, input_shape=(299,299,3), pooling = \"avg\", classes = 2)\n\nfor layer in effnet.layers:\n    layer.trainable = True\nx = effnet.output\ndroup_out = Dropout(0.3)(x)\npredicted = Dense(2,activation ='softmax')(droup_out)\nmodel = Model(effnet.input, predicted)\n\nmodel.compile(loss=loss,\n                      optimizer=Adam(lr=0.0001), \n                  metrics=['acc'])\nprint(model.summary())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mode_version = \"EfficientNetB3\"\ncheckpoint = ModelCheckpoint(f'weights-{mode_version}', monitor='val_acc',\n                                           save_best_only=True, save_weights_only=True, verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pretraining_EfficientNetB3 =model.fit(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=30,callbacks =[checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_full = pd.read_csv(\"../input/data-files/Data/data_full.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_with_nframes = pd.read_csv(\"../input/data-files/Data/only_videos_with_labels.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import img_to_array, load_img\nimport numpy as np\n\ndef process_image(image, target_shape):\n    Given an image, process it and return the array.\n    # Load the image.\n    h, w, _ = target_shape\n    print(image)\n    image = load_img(image, target_size=(h, w))\n\n    # Turn it into numpy, normalize and return.\n    img_arr = img_to_array(image)\n    x = (img_arr / 255.).astype(np.float32)\n\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\nimport numpy as np\nimport random\nimport glob\nimport os.path\nimport sys\nimport operator\nimport threading\n\nfrom keras.utils import to_categorical\n\nclass threadsafe_iterator:\n    def __init__(self, iterator):\n        self.iterator = iterator\n        self.lock = threading.Lock()\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        with self.lock:\n            return next(self.iterator)\n\ndef threadsafe_generator(func):\n    \"\"\"Decorator\"\"\"\n    def gen(*a, **kw):\n        return threadsafe_iterator(func(*a, **kw))\n    return gen\n\nclass DataSet():\n\n    def __init__(self, seq_length=40, class_limit=None, image_shape=(224, 224, 3)):\n        \"\"\"Constructor.\n        seq_length = (int) the number of frames to consider\n        class_limit = (int) number of classes to limit the data to.\n            None = no limit.\n        \"\"\"\n        self.seq_length = seq_length\n        self.class_limit = class_limit\n        self.sequence_path = os.path.join('data', 'sequences')\n        self.max_frames = 300  # max number of frames a video can have for us to use it\n\n        # Get the data.\n        self.data = self.get_data()\n\n        # Get the classes.\n        self.classes = self.get_classes()\n\n        # Now do some minor data cleaning.\n        #self.data = self.clean_data()\n\n        self.image_shape = image_shape\n    @staticmethod\n    def get_data():\n        \"\"\"Load our data from file.\"\"\"\n        with open(os.path.join('../input/data-files/Data/', 'only_videos_with_labels.csv'), 'r') as fin:\n            reader = csv.reader(fin)\n            data = list(reader)\n\n        return data\n\n    def clean_data(self):\n        \"\"\"Limit samples to greater than the sequence length and fewer\n        than N frames. Also limit it to classes we want to use.\"\"\"\n        data_clean = []\n        for item in self.data:\n            if int(item[1]) >= self.seq_length and int(item[1]) <= self.max_frames \\\n                    and item[2] in self.classes:\n                data_clean.append(item)\n\n        return data_clean\n\n    def get_classes(self):\n        \"\"\"Extract the classes from our data. If we want to limit them,\n        only return the classes we need.\"\"\"\n        classes = []\n        for i in range (1, len(self.data)):\n            item = self.data[i]\n            if item[2] not in classes:\n                classes.append(item[2])\n        # Sort them.\n        classes = sorted(classes)\n        # Return.\n        if self.class_limit is not None:\n            return classes[:self.class_limit]\n        else:\n            return classes\n\n    def get_class_one_hot(self, class_str):\n        \"\"\"Given a class as a string, return its number in the classes\n        list. This lets us encode and one-hot it for training.\"\"\"\n        # Encode it first.\n        #label_encoded = self.classes.index(class_str)\n\n        # Now one-hot it.\n        #label_hot = to_categorical(class_str, len(self.classes))\n        label_hot = float(class_str)\n        #assert len(label_hot) == len(self.classes)\n\n        return label_hot\n\n    def split_train_test(self):\n        \"\"\"Split the data into train and test groups.\"\"\"\n        train = []\n        test = []\n        valid = []\n        for i in range(1,len(self.data)):\n            item = self.data[i]\n            if item[3] == 'Train':\n                train.append(item)\n            elif item[3] == 'Valid':\n                valid.append(item)\n            else:\n                test.append(item)\n        return train, valid, test\n\n    def get_all_sequences_in_memory(self, train_test, data_type):\n        \"\"\"\n        This is a mirror of our generator, but attempts to load everything into\n        memory so we can train way faster.\n        \"\"\"\n        # Get the right dataset.\n        train, valid, test = self.split_train_test()\n        if train_test == 'train':\n            data = train \n        elif train_test == 'valid':\n            data = valid\n        else: \n            data = test\n\n        print(\"Loading %d samples into memory for %sing.\" % (len(data), train_test))\n\n        X, y = [], []\n        for row in data:\n\n            if data_type == 'images':\n                frames = self.get_frames_for_sample(row)\n                frames = self.rescale_list(frames, self.seq_length)\n\n                # Build the image sequence\n                sequence = self.build_image_sequence(frames)\n\n            else:\n                sequence = self.get_extracted_sequence(data_type, row)\n\n                if sequence is None:\n                    print(\"Can't find sequence. Did you generate them?\")\n                    raise\n\n            X.append(sequence)\n            y.append(row[2])\n\n        return np.array(X), np.array(y)\n\n    @threadsafe_generator\n    def frame_generator(self, batch_size, train_test, data_type):\n        \"\"\"Return a generator that we can use to train on. There are\n        a couple different things we can return:\n\n        data_type: 'features', 'images'\n        \"\"\"\n        # Get the right dataset for the generator.\n        train, valid, test = self.split_train_test()\n        if train_test == 'train':\n            data = train \n        elif train_test == 'valid':\n            data = valid\n        else: \n            data = test\n\n        print(\"Creating %s generator with %d samples.\" % (train_test, len(data)))\n\n        while 1:\n            X, y = [], []\n\n            # Generate batch_size samples.\n            for _ in range(batch_size):\n                # Reset to be safe.\n                sequence = None\n\n                # Get a random sample.\n                sample = random.choice(data)\n\n                # Check to see if we've already saved this sequence.\n                if data_type is \"images\":\n                    # Get and resample frames.\n                    frames = self.get_frames_for_sample(sample)\n                    frames = self.rescale_list(frames, self.seq_length)\n\n                    # Build the image sequence\n                    sequence = self.build_image_sequence(frames)\n                else:\n                    # Get the sequence from disk.\n                    sequence = self.get_extracted_sequence(data_type, sample)\n\n                    if sequence is None:\n                        raise ValueError(\"Can't find sequence. Did you generate them?\")\n\n                X.append(sequence)\n                y.append(self.get_class_one_hot(sample[2]))\n\n            yield np.array(X), np.array(y)\n\n    def build_image_sequence(self, frames):\n        \"\"\"Given a set of frames (filenames), build our sequence.\"\"\"\n        return [process_image(x, self.image_shape) for x in frames]\n\n    def get_extracted_sequence(self, data_type, sample):\n        \"\"\"Get the saved extracted features.\"\"\"\n        filename = sample[0]\n        #data_path = \"../input/sequences/\"\n        data_path = \"../input/sequences/\"\n        path = os.path.join(data_path, \"sequences\",filename + '-' + str(self.seq_length) + \\\n            '-' + data_type + '.npy')\n        if os.path.isfile(path):\n            return np.load(path)\n        else:\n            return None\n\n    def get_frames_by_filename(self, filename, data_type):\n        \"\"\"Given a filename for one of our samples, return the data\n        the model needs to make predictions.\"\"\"\n        # First, find the sample row.\n        sample = None\n        for row in self.data:\n            if row[0] == filename:\n                sample = row\n                break\n        if sample is None:\n            raise ValueError(\"Couldn't find sample: %s\" % filename)\n\n        if data_type == \"images\":\n            # Get and resample frames.\n            frames = self.get_frames_for_sample(sample)\n            frames = self.rescale_list(frames, self.seq_length)\n            # Build the image sequence\n            sequence = self.build_image_sequence(frames)\n        else:\n            # Get the sequence from disk.\n            sequence = self.get_extracted_sequence(data_type, sample)\n\n            if sequence is None:\n                raise ValueError(\"Can't find sequence. Did you generate them?\")\n\n        return sequence\n\n    @staticmethod\n    def get_frames_for_sample(sample):\n        sample = sample[0]\n        sources = []\n        images = data_full.loc[data_full['Video_ID'] == sample]['Frame_ID']\n        target = data_full.loc[data_full['Video_ID'] == sample]['Label']\n        if target.any() == 0:\n            for i in images:\n                src = os.path.join(training_dataset['Real'], i)\n                sources.append(src)\n        else: \n            for i in images:\n                src = os.path.join(training_dataset['Fake'], i)\n                sources.append(src)\n        return sources\n\n    @staticmethod\n    def get_filename_from_image(filename):\n        parts = filename.split(os.path.sep)\n        return parts[-1].replace('.jpg', '')\n\n    @staticmethod\n    def rescale_list(input_list, size):\n        \"\"\"Given a list and a size, return a rescaled/samples list. For example,\n        if we want a list of size 5 and we have a list of size 25, return a new\n        list of size five which is every 5th element of the origina list.\"\"\"\n        assert len(input_list) >= size\n\n        # Get the number to skip between iterations.\n        skip = len(input_list) // size\n\n        # Build our new output.\n        output = [input_list[i] for i in range(0, len(input_list), skip)]\n\n        # Cut off the last one if needed.\n        return output[:size]\n\n    def print_class_from_prediction(self, predictions, nb_to_return=5):\n        \"\"\"Given a prediction, print the top classes.\"\"\"\n        # Get the prediction for each label.\n        label_predictions = {}\n        for i, label in enumerate(self.classes):\n            label_predictions[label] = predictions[i]\n\n        # Now sort them.\n        sorted_lps = sorted(\n            label_predictions.items(),\n            key=operator.itemgetter(1),\n            reverse=True\n        )\n\n        # And return the top N.\n        for i, class_prediction in enumerate(sorted_lps):\n            if i > nb_to_return - 1 or class_prediction[1] == 0.0:\n                break\n            print(\"%s: %.2f\" % (class_prediction[0], class_prediction[1]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Input\nimport numpy as np\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import TimeDistributed\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.layers import TimeDistributed\nfrom tensorflow.keras.layers import (Conv2D, MaxPooling3D, Conv3D,\n    MaxPooling2D)\nfrom collections import deque\nimport sys","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential,Model\nfrom tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization, Flatten\n\nfrom tensorflow.keras import initializers, regularizers, constraints","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.layers import TimeDistributed\nfrom tensorflow.keras.layers import (Conv2D, MaxPooling3D, Conv3D,\n    MaxPooling2D)\nfrom collections import deque\nimport sys\n\nclass ResearchModels():\n    def __init__(self, nb_classes, model, seq_length,\n                 saved_model=None, features_length=2304):\n        # Set defaults.\n        self.seq_length = seq_length\n        self.load_model = load_model\n        self.saved_model = saved_model\n        self.nb_classes = nb_classes\n        self.feature_queue = deque()\n\n        # Set the metrics. Only use top k if there's a need.\n        metrics = ['accuracy']\n        # Get the appropriate model.\n        if self.saved_model is not None:\n            print(\"Loading model %s\" % self.saved_model)\n            self.model = load_model(self.saved_model)\n        elif model == 'gru':\n            print(\"Loading gru model.\")\n            self.input_shape = (seq_length, features_length)\n            self.model = self.gru()\n        # Now compile the network.\n        optimizer=Adam(lr=0.001, decay=1e-6)\n        self.model.compile(loss='binary_crossentropy', optimizer=optimizer,\n                           metrics=metrics)\n\n        print(self.model.summary())\n\n    def gru(self):\n        model = Sequential()\n        model.add(BatchNormalization(input_shape=self.input_shape))\n        model.add(GRU(256, activation='relu',return_sequences=True))\n        model.add(Dropout(0.3))\n\n        #model.add(Bidirectional(GRU(128, activation='relu',return_sequences=True)))\n        #model.add(Dropout(0.3))\n        #model.add(Bidirectional(GRU(64, activation='relu',return_sequences=True)))\n        #model.add(Dropout(0.3))\n        #model.add(BatchNormalization())\n        model.add(GRU(128,activation='relu', return_sequences=False))\n        #model.add(GRU(512, return_sequences=False))\n        #model.add(Bidirectional(GRU(128, dropout=0.1, recurrent_dropout=0.1, activation='relu', return_sequences=True)))\n        #model.add(Bidirectional(GRU(128, dropout=0.1, recurrent_dropout=0.1, activation='relu', return_sequences=True)))\n        #model.add(Flatten())\n        model.add(Dropout(0.3))\n        model.add(Dense(64, activation='relu'))\n        model.add(Dense(1,activation='sigmoid'))\n        return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\nimport time\nimport os.path\n\ndef train(data_type, seq_length, model, saved_model=None,\n          class_limit=None, image_shape=None,\n          load_to_memory=False, batch_size=10, nb_epoch=100):\n    # Helper: Save the model.\n    mode_version = \"GRU\"\n    checkpoint = ModelCheckpoint(f'weights-{mode_version}.h5', monitor='val_accuracy',\n                                           save_best_only=True, save_weights_only=True, verbose=1)\n\n    # Helper: TensorBoard\n    #tb = TensorBoard(log_dir=os.path.join('data', 'logs', model))\n\n    # Helper: Stop when we stop learning.\n    early_stopper = EarlyStopping(monitor =\"val_accuracy\", patience=5)\n    \n    # Helper: Save results.\n\n    # Get the data and process it.\n    if image_shape is None:\n        data = DataSet(\n            seq_length=seq_length,\n            class_limit=class_limit\n        )\n    else:\n        data = DataSet(\n            seq_length=seq_length,\n            class_limit=class_limit,\n            image_shape=image_shape\n        )\n\n    # Get samples per epoch.\n    # Multiply by 0.7 to attempt to guess how much of data.data is the train set.\n    steps_per_epoch =  3600// batch_size\n    validation_steps = 1200// batch_size\n    if load_to_memory:\n        # Get data.\n        X, y = data.get_all_sequences_in_memory('train', data_type)\n        X_test, y_test = data.get_all_sequences_in_memory('test', data_type)\n    else:\n        # Get generators.\n        generator = data.frame_generator(batch_size, 'train', data_type)\n        val_generator = data.frame_generator(batch_size, 'valid', data_type)\n        test_generator = data.frame_generator(batch_size, 'test', data_type)\n\n\n    # Get the model.\n    rm = ResearchModels(1, model, seq_length, saved_model)\n\n    # Fit!\n    if load_to_memory:\n        # Use standard fit.\n        rm.model.fit(\n            X,\n            y,\n            batch_size=batch_size,\n            validation_data=(X_test, y_test),\n            verbose=1,\n            callbacks=[early_stopper, csv_logger],\n            epochs=nb_epoch)\n\n    else:\n        # Use fit generator.\n        rm.model.fit_generator(\n            generator,\n            steps_per_epoch=steps_per_epoch,\n            epochs=nb_epoch,\n            verbose=1,\n            callbacks=[checkpoint,early_stopper],\n            validation_data=val_generator,\n            validation_steps = validation_steps,\n            workers=4)\n        Gru_history = pd.DataFrame(rm.model.history.history)\n        Gru_history.to_csv(\"Gru_history.history.csv\")\n        return (rm.model)\n\n\nmodel = 'gru'\nsaved_model = None  # None or weights file\nclass_limit = None # int, can be 1-101 or None\nseq_length = 40\nload_to_memory = False  # pre-load the sequences into memory\nbatch_size = 32\nnb_epoch = 100\n\nif model in ['gru', 'mlp']:\n    data_type = 'features'\n    image_shape = None\nelse:\n    raise ValueError(\"Invalid model. See train.py for options.\")\n\nGRU_model = train(data_type, seq_length, model, saved_model=saved_model,class_limit=class_limit, image_shape=image_shape,load_to_memory=False, batch_size=batch_size, nb_epoch=nb_epoch)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = DataSet(\n            seq_length=seq_length,\n            class_limit=class_limit,\n            image_shape=image_shape\n        )\ntest_generator = data.frame_generator(batch_size, 'test', data_type)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test, y_test = data.get_all_sequences_in_memory('test', data_type)\nX_valid, y_valid = data.get_all_sequences_in_memory('valid', data_type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_valid = y_valid.astype(np.int32)\ny_test= y_test.astype(np.int32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get the Metrices of the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n \n \n# predict probabilities for test set\nyhat_probs = GRU_model.predict(X_test)\nyhat_classes = GRU_model.predict_classes(X_test)\n\n# predict crisp classes for test set\nyhat_probs = yhat_probs[:, 0]\nyhat_classes = yhat_classes[:, 0]\n#yhat_classes = np.argmax(yhat_probs,axis=1)\n# reduce to 1d array\n#yhat_probs = yhat_probs[:, 0]\n \n# accuracy: (tp + tn) / (p + n)\naccuracy = accuracy_score(y_test, yhat_classes)\nprint('Test Accuracy: %f' % accuracy)\n# precision tp / (tp + fp)\nprecision = precision_score(y_test, yhat_classes)\nprint(' TestPrecision: %f' % precision)\n# recall: tp / (tp + fn)\nrecall = recall_score(y_test, yhat_classes)\nprint('Test Recall: %f' % recall)\n# f1: 2 tp / (2 tp + fp + fn)\nf1 = f1_score(y_test, yhat_classes)\nprint('Test F1 score: %f' % f1)\n \n# kappa\n\n# ROC AUC\nauc = roc_auc_score(y_test, yhat_probs)\nprint('Test ROC AUC: %f' % auc)\n# confusion matrix\nmatrix = confusion_matrix(y_test, yhat_classes)\nprint(matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict probabilities for test set\nyhat_probs = GRU_model.predict(X_valid)\nyhat_classes = GRU_model.predict_classes(X_valid)\n\n# predict crisp classes for test set\nyhat_probs = yhat_probs[:, 0]\nyhat_classes = yhat_classes[:, 0]\n#yhat_classes = np.argmax(yhat_probs,axis=1)\n# reduce to 1d array\n#yhat_probs = yhat_probs[:, 0]\n \n# accuracy: (tp + tn) / (p + n)\naccuracy = accuracy_score(y_valid, yhat_classes)\nprint('Valid Accuracy: %f' % accuracy)\n# precision tp / (tp + fp)\nprecision = precision_score(y_valid, yhat_classes)\nprint('Valid Precision: %f' % precision)\n# recall: tp / (tp + fn)\nrecall = recall_score(y_valid, yhat_classes)\nprint('Valid Recall: %f' % recall)\n# f1: 2 tp / (2 tp + fp + fn)\nf1 = f1_score(y_valid, yhat_classes)\nprint('Valid F1 score: %f' % f1)\n \n# kappa\n\n# ROC AUC\nauc = roc_auc_score(y_valid, yhat_probs)\nprint('Valid ROC AUC: %f' % auc)\n# confusion matrix\nmatrix = confusion_matrix(y_valid, yhat_classes)\nprint(matrix)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}