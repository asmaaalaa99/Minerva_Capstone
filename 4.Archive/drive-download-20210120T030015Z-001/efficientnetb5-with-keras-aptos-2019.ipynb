{"cells":[{"metadata":{},"cell_type":"markdown","source":["# Implementation of EfficientNetB5 for the APTOS 2019 competition with Keras"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"metadata":{},"cell_type":"markdown","source":["## Dependencies <a id=\"1\"></a>"]},{"metadata":{},"cell_type":"markdown","source":["Special thanks to [qubvel](https://github.com/qubvel/efficientnet) for sharing an amazing wrapper to get the EfficientNet architecture in one line of code!"]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":["import os\n","import sys\n","# Repository source: https://github.com/qubvel/efficientnet\n","import tensorflow \n","from tensorflow.python.keras.applications.efficientnet import EfficientNetB3\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n"],"execution_count":29,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Metric (Quadratic Weighted Kappa) <a id=\"3\"></a>"]},{"metadata":{},"cell_type":"markdown","source":["Batch Normalization becomes unstable with small batch sizes (<16) and that is why we use [Group Normalization ](https://arxiv.org/pdf/1803.08494.pdf) layers instead. Big thanks to [Somshubra Majumdar](https://github.com/titu1994) for building an implementation of Group Normalization for Keras.\n","\n","Keras makes it incredibly easy to replace layers. Just loop through the layers and replace each Batch Normalization layer with a Group Normalization layer."]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["import os\n","import sys\n","# Repository source: https://github.com/qubvel/efficientnet\n","import tensorflow \n","from tensorflow.python.keras.applications.efficientnet import EfficientNetB3\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","\n","def get_logits(labels, y_pred):\n","    s = 64.\n","    cos_t = y_pred\n","    sin_m = tf.math.sin(0.5)\n","    cos_m = tf.math.cos(0.5)\n","    cos_t2 = tf.square(cos_t, name='cos_2')\n","    sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n","    sin_t = tf.sqrt(sin_t2, name='sin_t')\n","    cos_mt = s * tf.subtract(tf.multiply(cos_t, cos_m), tf.multiply(sin_t, sin_m), name='cos_mt')\n","    cond_v = cos_t - threshold\n","    cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n","    keep_val = s*(cos_t - mm)\n","    cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n","    mask = tf.one_hot(labels, depth=class_num, name='one_hot_mask')\n","    inv_mask = tf.subtract(1., mask, name='inverse_mask')\n","    s_cos_t = tf.multiply(s, cos_t, name='scalar_cos_t')\n","    output = tf.add(tf.multiply(s_cos_t, inv_mask), tf.multiply(cos_mt_temp, mask), name='arcface_logits')\n","    return output\n","def loss(y_true, y_pred):\n","    labels = K.argmax(y_true, axis=-1)\n","    logits = get_logits(labels, y_pred)\n","    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n","    return loss"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["effnet = EfficientNetB3(weights = \"imagenet\", include_top = False, input_shape=(299,299,3), pooling = None, classes = 2)"]},{"metadata":{"trusted":true},"cell_type":"code","source":["import os\n","import sys\n","# Repository source: https://github.com/qubvel/efficientnet\n","import tensorflow \n","from tensorflow.python.keras.applications.efficientnet import EfficientNetB3\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","\n","def get_logits(labels, y_pred):\n","    s = 64.\n","    cos_t = y_pred\n","    sin_m = tf.math.sin(0.5)\n","    cos_m = tf.math.cos(0.5)\n","    cos_t2 = tf.square(cos_t, name='cos_2')\n","    sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n","    sin_t = tf.sqrt(sin_t2, name='sin_t')\n","    cos_mt = s * tf.subtract(tf.multiply(cos_t, cos_m), tf.multiply(sin_t, sin_m), name='cos_mt')\n","    cond_v = cos_t - threshold\n","    cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n","    keep_val = s*(cos_t - mm)\n","    cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n","    mask = tf.one_hot(labels, depth=class_num, name='one_hot_mask')\n","    inv_mask = tf.subtract(1., mask, name='inverse_mask')\n","    s_cos_t = tf.multiply(s, cos_t, name='scalar_cos_t')\n","    output = tf.add(tf.multiply(s_cos_t, inv_mask), tf.multiply(cos_mt_temp, mask), name='arcface_logits')\n","    return output\n","def loss(y_true, y_pred):\n","    labels = K.argmax(y_true, axis=-1)\n","    logits = get_logits(labels, y_pred)\n","    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n","    return loss\n","effnet = EfficientNetB3(weights = \"imagenet\", include_top = False, input_shape=(299,299,3), pooling = None, classes = 2)\n","model = Sequential()\n","model.add(effnet)\n","model.add(GlobalAveragePooling2D())\n","model.add(Dropout(0.5))\n","model.add(Dense(5, activation='relu'))\n","model.add(Dense(1, activation=\"linear\"))\n","model.compile(loss=loss,\n","                      optimizer=Adam(lr=0.00005), \n","                  metrics=['mse', 'acc'])\n","print(model.summary())\n","\n","# Initialize model\n","model.fit_generator(train_generator,\n","                    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n","                    epochs=35,\n","                    validation_data=val_generator,\n","                    validation_steps = val_generator.samples // BATCH_SIZE,\n","                    callbacks=[kappa_metrics, es, rlr])"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_12\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nefficientnetb3 (Model)       (None, 10, 10, 1536)      10783535  \n_________________________________________________________________\nglobal_average_pooling2d_10  (None, 1536)              0         \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 1536)              0         \n_________________________________________________________________\ndense_17 (Dense)             (None, 5)                 7685      \n_________________________________________________________________\ndense_18 (Dense)             (None, 1)                 6         \n=================================================================\nTotal params: 10,791,226\nTrainable params: 10,703,923\nNon-trainable params: 87,303\n_________________________________________________________________\nNone\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'train_generator' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-d12412457dd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Initialize model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m model.fit_generator(train_generator,\n\u001b[0m\u001b[1;32m     14\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"]}]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":["# For tracking Quadratic Weighted Kappa score\n","# Begin training\n","model.fit_generator(train_generator,\n","                    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n","                    epochs=35,\n","                    validation_data=val_generator,\n","                    validation_steps = val_generator.samples // BATCH_SIZE,\n","                    callbacks=[kappa_metrics, es, rlr])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":["# Visualize mse\n","history_df = pd.DataFrame(model.history.history)\n","history_df[['loss', 'val_loss']].plot(figsize=(12,5))\n","plt.title(\"Loss (MSE)\", fontsize=16, weight='bold')\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss (MSE)\")\n","history_df[['acc', 'val_acc']].plot(figsize=(12,5))\n","plt.title(\"Accuracy\", fontsize=16, weight='bold')\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"% Accuracy\");"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Evaluation <a id=\"7\"></a>"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Load best weights according to MSE\n","model.load_weights(SAVED_MODEL_NAME)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["To evaluate our performance we predict values from the generator and round them of to the nearest integer to get valid predictions. After that we calculate the Quadratic Weighted Kappa score on the training set and the validation set."]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":["# Calculate QWK on train set\n","y_train_preds, train_labels = get_preds_and_labels(model, train_generator)\n","y_train_preds = np.rint(y_train_preds).astype(np.uint8).clip(0, 4)\n","\n","# Calculate score\n","train_score = cohen_kappa_score(train_labels, y_train_preds, weights=\"quadratic\")\n","\n","# Calculate QWK on validation set\n","y_val_preds, val_labels = get_preds_and_labels(model, val_generator)\n","y_val_preds = np.rint(y_val_preds).astype(np.uint8).clip(0, 4)\n","\n","# Calculate score\n","val_score = cohen_kappa_score(val_labels, y_val_preds, weights=\"quadratic\")"],"execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":["print(f\"The Training Cohen Kappa Score is: {round(train_score, 5)}\")\n","print(f\"The Validation Cohen Kappa Score is: {round(val_score, 5)}\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["We can optimize the validation score by doing a [Grid Search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) over rounding thresholds instead of doing \"normal\" rounding. The \"OptimizedRounder\" class by [Abhishek Thakur](https://www.kaggle.com/abhishek) is a great way to do this. The original class can be found in [this Kaggle kernel](https://www.kaggle.com/abhishek/optimizer-for-quadratic-weighted-kappa)."]},{"metadata":{"trusted":true},"cell_type":"code","source":["class OptimizedRounder(object):\n","    \"\"\"\n","    An optimizer for rounding thresholds\n","    to maximize Quadratic Weighted Kappa score\n","    \"\"\"\n","    def __init__(self):\n","        self.coef_ = 0\n","\n","    def _kappa_loss(self, coef, X, y):\n","        \"\"\"\n","        Get loss according to\n","        using current coefficients\n","        \n","        :param coef: A list of coefficients that will be used for rounding\n","        :param X: The raw predictions\n","        :param y: The ground truth labels\n","        \"\"\"\n","        X_p = np.copy(X)\n","        for i, pred in enumerate(X_p):\n","            if pred < coef[0]:\n","                X_p[i] = 0\n","            elif pred >= coef[0] and pred < coef[1]:\n","                X_p[i] = 1\n","            elif pred >= coef[1] and pred < coef[2]:\n","                X_p[i] = 2\n","            elif pred >= coef[2] and pred < coef[3]:\n","                X_p[i] = 3\n","            else:\n","                X_p[i] = 4\n","\n","        ll = cohen_kappa_score(y, X_p, weights='quadratic')\n","        return -ll\n","\n","    def fit(self, X, y):\n","        \"\"\"\n","        Optimize rounding thresholds\n","        \n","        :param X: The raw predictions\n","        :param y: The ground truth labels\n","        \"\"\"\n","        loss_partial = partial(self._kappa_loss, X=X, y=y)\n","        initial_coef = [0.5, 1.5, 2.5, 3.5]\n","        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n","\n","    def predict(self, X, coef):\n","        \"\"\"\n","        Make predictions with specified thresholds\n","        \n","        :param X: The raw predictions\n","        :param coef: A list of coefficients that will be used for rounding\n","        \"\"\"\n","        X_p = np.copy(X)\n","        for i, pred in enumerate(X_p):\n","            if pred < coef[0]:\n","                X_p[i] = 0\n","            elif pred >= coef[0] and pred < coef[1]:\n","                X_p[i] = 1\n","            elif pred >= coef[1] and pred < coef[2]:\n","                X_p[i] = 2\n","            elif pred >= coef[2] and pred < coef[3]:\n","                X_p[i] = 3\n","            else:\n","                X_p[i] = 4\n","        return X_p\n","\n","    def coefficients(self):\n","        \"\"\"\n","        Return the optimized coefficients\n","        \"\"\"\n","        return self.coef_['x']"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Optimize on validation data and evaluate again\n","y_val_preds, val_labels = get_preds_and_labels(model, val_generator)\n","optR = OptimizedRounder()\n","optR.fit(y_val_preds, val_labels)\n","coefficients = optR.coefficients()\n","opt_val_predictions = optR.predict(y_val_preds, coefficients)\n","new_val_score = cohen_kappa_score(val_labels, opt_val_predictions, weights=\"quadratic\")"],"execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":["print(f\"Optimized Thresholds:\\n{coefficients}\\n\")\n","print(f\"The Validation Quadratic Weighted Kappa (QWK)\\n\\\n","with optimized rounding thresholds is: {round(new_val_score, 5)}\\n\")\n","print(f\"This is an improvement of {round(new_val_score - val_score, 5)}\\n\\\n","over the unoptimized rounding\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Submission <a id=\"8\"></a>"]},{"metadata":{},"cell_type":"markdown","source":["Since the test set is not that large we will not be using a generator for making the final predictions on the test set."]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Place holder for diagnosis column\n","test_df['diagnosis'] = np.zeros(test_df.shape[0]) \n","# For preprocessing test images\n","test_generator = ImageDataGenerator(preprocessing_function=preprocess_image, \n","                                    rescale=1 / 128.).flow_from_dataframe(test_df, \n","                                                                          x_col='id_code', \n","                                                                          y_col='diagnosis',\n","                                                                          directory=TEST_IMG_PATH,\n","                                                                          target_size=(IMG_WIDTH, IMG_HEIGHT),\n","                                                                          batch_size=BATCH_SIZE,\n","                                                                          class_mode='other',\n","                                                                          shuffle=False)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["As mentioned earlier, we use custom thresholds to optimize our score. The same thresholds should be used when creating the final predictions."]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":["# Make final predictions, round predictions and save to csv\n","y_test, _ = get_preds_and_labels(model, test_generator)\n","y_test = optR.predict(y_test, coefficients).astype(np.uint8)\n","test_df['diagnosis'] = y_test\n","# Remove .png from ids\n","test_df['id_code'] = test_df['id_code'].str.replace(r'.png$', '')\n","test_df.to_csv('submission.csv', index=False)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["After creating the submission I always check the format and the distribution of the test predictions. Do they makes sense given the label distribution of the training data?"]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":["# Check submission\n","print(\"Submission File\")\n","display(test_df.head())"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":["# Label distribution\n","train_df['diagnosis'].value_counts().sort_index().plot(kind=\"bar\", \n","                                                       figsize=(12,5), \n","                                                       rot=0)\n","plt.title(\"Label Distribution (Training Set)\", \n","          weight='bold', \n","          fontsize=18)\n","plt.xticks(fontsize=15)\n","plt.yticks(fontsize=15)\n","plt.xlabel(\"Label\", fontsize=17)\n","plt.ylabel(\"Frequency\", fontsize=17);"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":["# Distribution of predictions\n","test_df['diagnosis'].value_counts().sort_index().plot(kind=\"bar\", \n","                                                      figsize=(12,5), \n","                                                      rot=0)\n","plt.title(\"Label Distribution (Predictions)\", \n","          weight='bold', \n","          fontsize=18)\n","plt.xticks(fontsize=15)\n","plt.yticks(fontsize=15)\n","plt.xlabel(\"Label\", fontsize=17)\n","plt.ylabel(\"Frequency\", fontsize=17);"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":["# Check kernels run-time. GPU limit for this competition is set to ± 9 hours.\n","t_finish = time.time()\n","total_time = round((t_finish-t_start) / 3600, 4)\n","print('Kernel runtime = {} hours ({} minutes)'.format(total_time, \n","                                                      int(total_time*60)))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["That's it! Feel free to experiment with this kernel and try a larger implementation of EfficientNet. This kernel provides weights for EfficientNetB0 through B5. Weights for EfficientNetB6 and B7 can be found in [Google AI's repository for EfficientNet](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet).\n","\n","**If you like this Kaggle kernel, feel free to give an upvote and leave a comment! I will try to implement your suggestions in this kernel!**"]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.0 64-bit","metadata":{"interpreter":{"hash":"752579dbebe7f4dfe7c1aa72eac13e23fc88be2cc1ea7ab14e1f8d69b2d97d12"}}},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.8.0-final","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}