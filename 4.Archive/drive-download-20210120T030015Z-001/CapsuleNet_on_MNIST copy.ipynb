{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "version": "3.8.0-final",
      "name": "python"
    },
    "colab": {
      "name": "CapsuleNet on MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7f4c4917-22fb-4b10-879e-51c600e6c3af",
        "_uuid": "9b086e5ec535ad75eada3ca72bf5e6534251074f",
        "id": "LQnu9movo8xz"
      },
      "source": [
        "# Overview\n",
        "\n",
        "The new model CapsuleNet proposed by Sara Sabour (and Geoffry Hinton) claims to deliver state of the art results on [MNIST](https://arxiv.org/abs/1710.09829). The kernel aims to create and train the model using the Kaggle Dataset and then make a submission to see where it actually ends up. Given the constraint of using a Kaggle Kernel means it can't be trained as long as we would like or with GPU's but IMHO if a model can't be reasonably well trained in an hour on a 28x28 dataset, that model probably won't be too useful in the immediate future.\n",
        "\n",
        "## Implementation Details\n",
        "\n",
        "* Keras implementation of CapsNet in Hinton's paper Dynamic Routing Between Capsules.\n",
        "* Code adapted from https://github.com/XifengGuo/CapsNet-Keras/blob/master/capsulenet.py\n",
        "*  Author: Xifeng Guo, E-mail: `guoxifeng1990@163.com`, Github: `https://github.com/XifengGuo/CapsNet-Keras`\n",
        "*     The current version maybe only works for TensorFlow backend. Actually it will be straightforward to re-write to TF code.\n",
        "*     Adopting to other backends should be easy, but I have not tested this. \n",
        "\n",
        "Result:\n",
        "    Validation accuracy > 99.5% after 20 epochs. Still under-fitting.\n",
        "    About 110 seconds per epoch on a single GTX1070 GPU card\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "e30e2e10-a909-485d-be9d-dc6f592911a7",
        "_uuid": "c7e569699c6d067cd9fdf9c77299775e399b2ef3",
        "id": "qWnuqFe2o8x2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5da50037-4aa3-47db-83e1-42db3eae5305"
      },
      "source": [
        "import numpy as np\n",
        "#from keras.preprocessing.image import ImageDataGenerator\n",
        "#from keras import callbacks\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import callbacks\n",
        "#from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import re \n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "import pandas as pd\n",
        "print(tf.__version__)\n",
        "import sys, os\n",
        "from facenet_pytorch import MTCNN\n",
        "from PIL import Image\n",
        "import torch\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from joblib import Parallel, delayed\n",
        "import cv2\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9776fd57-44e0-4211-a7a5-c7e647a10704",
        "_uuid": "f4b5499a472b312d5c5f0274ad429567aced6841",
        "id": "xYHeLw1do8x5"
      },
      "source": [
        "# Capsule Layers \n",
        "Here is the implementation of the necessary layers for the CapsuleNet. These are not optimized yet and can be made significantly more performant. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "167d39ca-ee32-4eec-a83b-86194252b14f",
        "_uuid": "90c180a9a8c20e3fb8a93c3eb42588927cfcd6b6",
        "id": "dQti96GTo8x5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "73dd133a-5bc2-47f2-ea08-c4de4c135fdb"
      },
      "source": [
        "\n",
        "class Length(layers.Layer):\n",
        "    \"\"\"\n",
        "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss.\n",
        "    Using this layer as model's output can directly predict labels by using `y_pred = np.argmax(model.predict(x), 1)`\n",
        "    inputs: shape=[None, num_vectors, dim_vector]\n",
        "    output: shape=[None, num_vectors]\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), -1) + K.epsilon())\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:-1]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Length, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n",
        "class Mask(layers.Layer):\n",
        "    \"\"\"\n",
        "    Mask a Tensor with shape=[None, num_capsule, dim_vector] either by the capsule with max length or by an additional \n",
        "    input mask. Except the max-length capsule (or specified capsule), all vectors are masked to zeros. Then flatten the\n",
        "    masked Tensor.\n",
        "    For example:\n",
        "        ```\n",
        "        x = keras.layers.Input(shape=[8, 3, 2])  # batch_size=8, each sample contains 3 capsules with dim_vector=2\n",
        "        y = keras.layers.Input(shape=[8, 3])  # True labels. 8 samples, 3 classes, one-hot coding.\n",
        "        out = Mask()(x)  # out.shape=[8, 6]\n",
        "        # or\n",
        "        out2 = Mask()([x, y])  # out2.shape=[8,6]. Masked with true labels y. Of course y can also be manipulated.\n",
        "        ```\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if type(inputs) is list:  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n",
        "            assert len(inputs) == 2\n",
        "            inputs, mask = inputs\n",
        "        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n",
        "            # compute lengths of capsules\n",
        "            x = tf.sqrt(tf.reduce_sum(tf.square(inputs), -1))\n",
        "            # generate the mask which is a one-hot code.\n",
        "            # mask.shape=[None, n_classes]=[None, num_capsule]\n",
        "            mask = tf.one_hot(indices=tf.argmax(x, 1), depth=x.shape[1])\n",
        "\n",
        "        # inputs.shape=[None, num_capsule, dim_capsule]\n",
        "        # mask.shape=[None, num_capsule]\n",
        "        # masked.shape=[None, num_capsule * dim_capsule]\n",
        "        masked = K.batch_flatten(inputs * tf.expand_dims(mask, -1))\n",
        "        return masked\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if type(input_shape[0]) is tuple:  # true label provided\n",
        "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
        "        else:  # no true label provided\n",
        "            return tuple([None, input_shape[1] * input_shape[2]])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Mask, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n",
        "def squash(vectors, axis=-1):\n",
        "    \"\"\"\n",
        "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
        "    :param vectors: some vectors to be squashed, N-dim tensor\n",
        "    :param axis: the axis to squash\n",
        "    :return: a Tensor with same shape as input vectors\n",
        "    \"\"\"\n",
        "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / tf.sqrt(s_squared_norm + K.epsilon())\n",
        "    return scale * vectors\n",
        "\n",
        "\n",
        "class CapsuleLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the\n",
        "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
        "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_capsule] and output shape = \\\n",
        "    [None, num_capsule, dim_capsule]. For Dense Layer, input_dim_capsule = dim_capsule = 1.\n",
        "    :param num_capsule: number of capsules in this layer\n",
        "    :param dim_capsule: dimension of the output vectors of the capsules in this layer\n",
        "    :param routings: number of iterations for the routing algorithm\n",
        "    \"\"\"\n",
        "    def __init__(self, num_capsule, dim_capsule, routings=3,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
        "        self.input_num_capsule = input_shape[1]\n",
        "        self.input_dim_capsule = input_shape[2]\n",
        "\n",
        "        # Transform matrix, from each input capsule to each output capsule, there's a unique weight as in Dense layer.\n",
        "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
        "                                        self.dim_capsule, self.input_dim_capsule],\n",
        "                                 initializer=self.kernel_initializer,\n",
        "                                 name='W')\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n",
        "        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule, 1]\n",
        "        inputs_expand = tf.expand_dims(tf.expand_dims(inputs, 1), -1)\n",
        "\n",
        "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
        "        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule, 1]\n",
        "        inputs_tiled = tf.tile(inputs_expand, [1, self.num_capsule, 1, 1, 1])\n",
        "\n",
        "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n",
        "        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n",
        "        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule, 1]\n",
        "        # Regard the first two dimensions as `batch` dimension, then\n",
        "        # matmul(W, x): [..., dim_capsule, input_dim_capsule] x [..., input_dim_capsule, 1] -> [..., dim_capsule, 1].\n",
        "        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
        "        inputs_hat = tf.squeeze(tf.map_fn(lambda x: tf.matmul(self.W, x), elems=inputs_tiled))\n",
        "\n",
        "        # Begin: Routing algorithm ---------------------------------------------------------------------#\n",
        "        # The prior for coupling coefficient, initialized as zeros.\n",
        "        # b.shape = [None, self.num_capsule, 1, self.input_num_capsule].\n",
        "        b = tf.zeros(shape=[inputs.shape[0], self.num_capsule, 1, self.input_num_capsule])\n",
        "\n",
        "        assert self.routings > 0, 'The routings should be > 0.'\n",
        "        for i in range(self.routings):\n",
        "            # c.shape=[batch_size, num_capsule, 1, input_num_capsule]\n",
        "            c = tf.nn.softmax(b, axis=1)\n",
        "\n",
        "            # c.shape = [batch_size, num_capsule, 1, input_num_capsule]\n",
        "            # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
        "            # The first two dimensions as `batch` dimension,\n",
        "            # then matmal: [..., 1, input_num_capsule] x [..., input_num_capsule, dim_capsule] -> [..., 1, dim_capsule].\n",
        "            # outputs.shape=[None, num_capsule, 1, dim_capsule]\n",
        "            outputs = squash(tf.matmul(c, inputs_hat))  # [None, 10, 1, 16]\n",
        "\n",
        "            if i < self.routings - 1:\n",
        "                # outputs.shape =  [None, num_capsule, 1, dim_capsule]\n",
        "                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
        "                # The first two dimensions as `batch` dimension, then\n",
        "                # matmal:[..., 1, dim_capsule] x [..., input_num_capsule, dim_capsule]^T -> [..., 1, input_num_capsule].\n",
        "                # b.shape=[batch_size, num_capsule, 1, input_num_capsule]\n",
        "                b += tf.matmul(outputs, inputs_hat, transpose_b=True)\n",
        "        # End: Routing algorithm -----------------------------------------------------------------------#\n",
        "\n",
        "        return tf.squeeze(outputs)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'num_capsule': self.num_capsule,\n",
        "            'dim_capsule': self.dim_capsule,\n",
        "            'routings': self.routings\n",
        "        }\n",
        "        base_config = super(CapsuleLayer, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
        "    \"\"\"\n",
        "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "    :param inputs: 4D tensor, shape=[None, width, height, channels]\n",
        "    :param dim_capsule: the dim of the output vector of capsule\n",
        "    :param n_channels: the number of types of capsules\n",
        "    :return: output tensor, shape=[None, num_capsule, dim_capsule]\n",
        "    \"\"\"\n",
        "    output = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
        "                           name='primarycap_conv2d')(inputs)\n",
        "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output)\n",
        "    return layers.Lambda(squash, name='primarycap_squash')(outputs)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# The following is another way to implement primary capsule layer. This is much slower.\n",
        "# Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
        "    outputs = []\n",
        "    for _ in range(n_channels):\n",
        "        output = layers.Conv2D(filters=dim_capsule, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n",
        "        outputs.append(layers.Reshape([output.get_shape().as_list()[1] ** 2, dim_capsule])(output))\n",
        "    outputs = layers.Concatenate(axis=1)(outputs)\n",
        "    return layers.Lambda(squash)(outputs)\n",
        "\"\"\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# The following is another way to implement primary capsule layer. This is much slower.\\n# Apply Conv2D `n_channels` times and concatenate all capsules\\ndef PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\\n    outputs = []\\n    for _ in range(n_channels):\\n        output = layers.Conv2D(filters=dim_capsule, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\\n        outputs.append(layers.Reshape([output.get_shape().as_list()[1] ** 2, dim_capsule])(output))\\n    outputs = layers.Concatenate(axis=1)(outputs)\\n    return layers.Lambda(squash)(outputs)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7cd17730-22b6-4ac3-a612-31f18902fa78",
        "_uuid": "61c38c7ee701bb3ee2190263cf907fcdbe40dca2",
        "id": "UDdQcGoko8x8"
      },
      "source": [
        "# Build the Model\n",
        "Here we use the layers to build up the model. The model is a bit different from a standard $X\\rightarrow y$  model, it is $(X,y)\\rightarrow (y,X)$ meaning it attempts to predict the class from the image, and then at the same time, using the same capsule reconstruct the image from the class. The approach appears very cGAN-like where the task of reconstructing better helps the model 'understand' the image data better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "# load model without classifier layers\n",
        "model = VGG19(include_top=False, input_shape=(299, 299, 3))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "bc101123-d53c-4c2e-a187-101c434885da",
        "_uuid": "2497453eb1895f624ad84617dd98c230f5640304",
        "id": "HCMIciV0o8x9"
      },
      "source": [
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "def CapsNet(input_shape, n_class, routings, batch_size):\n",
        "    \"\"\"\n",
        "    A Capsule Network on MNIST.\n",
        "    :param input_shape: data shape, 3d, [width, height, channels]\n",
        "    :param n_class: number of classes\n",
        "    :param routings: number of routing iterations\n",
        "    :param batch_size: size of batch\n",
        "    :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
        "            `eval_model` can also be used for training.\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    x = layers.Input(shape=input_shape, batch_size=batch_size)\n",
        "\n",
        "    # Layer 1: Just a conventional Conv2D layer\n",
        "    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "\n",
        "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
        "    primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
        "\n",
        "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
        "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings, name='digitcaps')(primarycaps)\n",
        "\n",
        "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
        "    # If using tensorflow, this will not be necessary. :)\n",
        "    out_caps = Length(name='capsnet')(digitcaps)\n",
        "\n",
        "    # Decoder network.\n",
        "    y = layers.Input(shape=(n_class,))\n",
        "    masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
        "    masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
        "\n",
        "    # Shared Decoder model in training and prediction\n",
        "    decoder = models.Sequential(name='decoder')\n",
        "    decoder.add(layers.Dense(512, activation='relu', input_dim=16 * n_class))\n",
        "    decoder.add(layers.Dense(1024, activation='relu'))\n",
        "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
        "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
        "\n",
        "    # Models for training and evaluation (prediction)\n",
        "    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
        "    eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
        "\n",
        "    # manipulate model\n",
        "    noise = layers.Input(shape=(n_class, 16))\n",
        "    noised_digitcaps = layers.Add()([digitcaps, noise])\n",
        "    masked_noised_y = Mask()([noised_digitcaps, y])\n",
        "    manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
        "    return train_model, eval_model, manipulate_model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "c6d84e5a-c33c-40c8-89c3-aba3454f7025",
        "_uuid": "9f27c6b0623ebffb6c8a24579f9dd4e321d6b1c2",
        "id": "LS09Ic7qo8x_"
      },
      "source": [
        "def margin_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
        "    :param y_true: [None, n_classes]\n",
        "    :param y_pred: [None, num_capsule]\n",
        "    :return: a scalar loss value.\n",
        "    \"\"\"\n",
        "    # return tf.reduce_mean(tf.square(y_pred))\n",
        "    L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n",
        "        0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n",
        "\n",
        "    return tf.reduce_mean(tf.reduce_sum(L, 1))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7d75c4e0-ffca-45fc-8acc-620fe2825f82",
        "_uuid": "3e810fabad89045b7f4b51fe8540164f90e7698c",
        "id": "LjrtUDsVo8yE"
      },
      "source": [
        "# Load MNIST Data\n",
        "Here we load and reformat the Kaggle contest data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JBMdPcyZrla"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "169b7f78-12c7-4fed-886e-60024fe59339",
        "_uuid": "02b7db879a533e7bfb3116522bebf3867b23498c",
        "id": "0zSuXAxxo8yQ"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import csv\n",
        "import math\n",
        "import pandas\n",
        "\n",
        "def combine_images(generated_images, height=None, width=None):\n",
        "    num = generated_images.shape[0]\n",
        "    if width is None and height is None:\n",
        "        width = int(math.sqrt(num))\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif width is not None and height is None:  # height not given\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif height is not None and width is None:  # width not given\n",
        "        width = int(math.ceil(float(num)/height))\n",
        "\n",
        "    shape = generated_images.shape[1:3]\n",
        "    image = np.zeros((height*shape[0], width*shape[1]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
        "            img[:, :, 0]\n",
        "    return image\n",
        "\n",
        "def plot_log(filename, show=True):\n",
        "\n",
        "    data = pandas.read_csv(filename)\n",
        "\n",
        "    fig = plt.figure(figsize=(4,6))\n",
        "    fig.subplots_adjust(top=0.95, bottom=0.05, right=0.95)\n",
        "    fig.add_subplot(211)\n",
        "    for key in data.keys():\n",
        "        if key.find('loss') >= 0 and not key.find('val') >= 0:  # training loss\n",
        "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
        "    plt.legend()\n",
        "    plt.title('Training loss')\n",
        "\n",
        "    fig.add_subplot(212)\n",
        "    for key in data.keys():\n",
        "        if key.find('acc') >= 0:  # acc\n",
        "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
        "    plt.legend()\n",
        "    plt.title('Training and validation accuracy')\n",
        "\n",
        "    # fig.savefig('result/log.png')\n",
        "    if show:\n",
        "        plt.show()    \n",
        "\n",
        "def test(model, data, args):\n",
        "    x_test, y_test = data\n",
        "    y_pred, x_recon = model.predict(x_test, batch_size=100)\n",
        "    print('-' * 30 + 'Begin: test' + '-' * 30)\n",
        "    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1)) / y_test.shape[0])\n",
        "\n",
        "    img = combine_images(np.concatenate([x_test[:50], x_recon[:50]]))\n",
        "    image = img * 255\n",
        "    Image.fromarray(image.astype(np.uint8)).save(args.save_dir + \"/real_and_recon.png\")\n",
        "    print()\n",
        "    print('Reconstructed images are saved to %s/real_and_recon.png' % args.save_dir)\n",
        "    print('-' * 30 + 'End: test' + '-' * 30)\n",
        "    plt.imshow(plt.imread(args.save_dir + \"/real_and_recon.png\"))\n",
        "    plt.show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "e698ab37-4e74-43e6-b35b-a0507449d916",
        "_uuid": "c0374dabdf452026e3f231ffe689b5dd9f99288b",
        "id": "TZJyVmido8yK"
      },
      "source": [
        "def train(model, data, args):\n",
        "#def train(model, train_gen, val_gen,args):\n",
        "\n",
        "    \"\"\"\n",
        "    Training a CapsuleNet\n",
        "    :param model: the CapsuleNet model\n",
        "    :param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n",
        "    :param args: arguments\n",
        "    :return: The trained model\n",
        "    \"\"\"\n",
        "    # unpacking the data\n",
        "    (x_train, y_train), (x_test, y_test) = data\n",
        "\n",
        "    # callbacks\n",
        "    log = callbacks.CSVLogger(args.save_dir + '/log.csv')\n",
        "    checkpoint = callbacks.ModelCheckpoint(args.save_dir + '/weights-{epoch:02d}.h5', monitor='val_capsnet_accuracy',\n",
        "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
        "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args.lr * (args.lr_decay ** epoch))\n",
        "\n",
        "    # compile the model\n",
        "    model.compile(optimizer=optimizers.Adam(lr=args.lr),\n",
        "                  loss=[margin_loss, 'mse'],\n",
        "                  loss_weights=[1., args.lam_recon],\n",
        "                  metrics={'capsnet': 'accuracy'})\n",
        "\n",
        "    \"\"\"\n",
        "    # Training without data augmentation:\n",
        "    model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs,\n",
        "              validation_data=[[x_test, y_test], [y_test, x_test]], callbacks=[log, tb, checkpoint, lr_decay])\n",
        "    \"\"\"\n",
        "\n",
        "    # Begin: Training with data augmentation ---------------------------------------------------------------------#\n",
        "    def train_generator(x, y, batch_size, shift_fraction=0.):\n",
        "        train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
        "                                           height_shift_range=shift_fraction)  # shift up to 2 pixel for MNIST\n",
        "        generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
        "        while 1:\n",
        "            x_batch, y_batch = generator.next()\n",
        "            yield (x_batch, y_batch), (y_batch, x_batch)\n",
        "\n",
        "    # Training with data augmentation. If shift_fraction=0., no augmentation.\n",
        "    model.fit(train_generator(x_train, y_train, args.batch_size, args.shift_fraction),\n",
        "              steps_per_epoch=int(np.shape(y_train)[0] / args.batch_size),\n",
        "              epochs=args.epochs,\n",
        "              validation_data=((x_test, y_test), (y_test, x_test)), batch_size=args.batch_size,\n",
        "              callbacks=[log, checkpoint, lr_decay])\n",
        "        \n",
        "    # End: Training with data augmentation -----------------------------------------------------------------------#\n",
        "\n",
        "    model.save_weights(args.save_dir + '/trained_model.h5')\n",
        "    print('Trained model saved to \\'%s/trained_model.h5\\'' % args.save_dir)\n",
        "\n",
        "    plot_log(args.save_dir + '/log.csv', show=True)\n",
        "\n",
        "    # End: Training with data augmentation -----------------------------------------------------------------------#\n",
        "\n",
        "    model.save_weights(args.save_dir + '/trained_model.h5')\n",
        "    print('Trained model saved to \\'%s/trained_model.h5\\'' % args.save_dir)\n",
        "\n",
        "    plot_log(args.save_dir + '/log.csv', show=True)\n",
        "    return model\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EKbfeEhiYkr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c7bb18a-fcdc-44c1-8d91-2ae9be8488f0"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "parser = argparse.ArgumentParser(description=\"Capsule Network on MNIST.\")\n",
        "parser.add_argument('--epochs', default=10, type=int)\n",
        "parser.add_argument('--batch_size', default=10, type=int)\n",
        "parser.add_argument('--lr', default=0.001, type=float,\n",
        "                        help=\"Initial learning rate\")\n",
        "parser.add_argument('--lr_decay', default=0.9, type=float,\n",
        "                        help=\"The value multiplied by lr at each epoch. Set a larger value for larger epochs\")\n",
        "parser.add_argument('--lam_recon', default=0.392, type=float,\n",
        "                        help=\"The coefficient for the loss of decoder\")\n",
        "parser.add_argument('-r', '--routings', default=1, type=int,\n",
        "                        help=\"Number of iterations used in routing algorithm. should > 0\")\n",
        "parser.add_argument('--shift_fraction', default=0.1, type=float,\n",
        "                        help=\"Fraction of pixels to shift at most in each direction.\")\n",
        "parser.add_argument('--debug', action='store_true',\n",
        "                        help=\"Save weights by TensorBoard\")\n",
        "parser.add_argument('--save_dir', default='./result')\n",
        "parser.add_argument('-t', '--testing', action='store_true',\n",
        "                        help=\"Test the trained model on testing dataset\")\n",
        "parser.add_argument('--digit', default=5, type=int,\n",
        "                        help=\"Digit to manipulate\")\n",
        "parser.add_argument('-w', '--weights', default=None,\n",
        "                        help=\"The path of the saved weights. Should be specified when testing\")\n",
        "args, unknown = parser.parse_known_args()\n",
        "print(args)\n",
        "\n",
        "if not os.path.exists(args.save_dir):\n",
        "    os.makedirs(args.save_dir)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=10, debug=False, digit=5, epochs=10, lam_recon=0.392, lr=0.001, lr_decay=0.9, routings=1, save_dir='./result', shift_fraction=0.1, testing=False, weights=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "9dbcd67c-8f99-4d8b-8cf7-480d8dc069a4",
        "_uuid": "526436cc40013621251285812ba95725d4a6d749",
        "id": "7UfmktlEo8yF"
      },
      "source": [
        "def load_mnist():\n",
        "    # the data, shuffled and split between train and test sets\n",
        "    from tensorflow.keras.datasets import mnist\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "    x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "    y_train = to_categorical(y_train.astype('float32'))\n",
        "    y_test = to_categorical(y_test.astype('float32'))\n",
        "\n",
        "    # data_slice = 10000\n",
        "    # x_train = x_train[:data_slice,:]\n",
        "    # y_train = y_train[:data_slice,:]\n",
        "    # x_test = x_test[:data_slice,:]\n",
        "    # y_test = y_test[:data_slice,:]\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_images(path):\n",
        "    data = []\n",
        "    filenames = glob.glob(DATASET_PATHS[path]+\"*.jpg\")\n",
        "    #pbar = tqdm(filenames)\n",
        "    #df = pd.DataFrame()\n",
        "    for image in filenames:\n",
        "        id = image.split(\"/\")[-1]\n",
        "        #print(id)\n",
        "        #id = re.findall(r'\\d+',id)[0]\n",
        "        #og_name = image.split(\"\\\\\")[-1]\n",
        "        dataset_type = id.split(\"_\")[0]\n",
        "        if path == 'original':\n",
        "            label = 0\n",
        "            data.append([id, label,dataset_type])\n",
        "        else: \n",
        "            label = 1\n",
        "            data.append([id, label,dataset_type])\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASET_PATHS = {\"original\":\"/Users/asmaaaly/Minerva_Shit/Capstone/Minerva_Capstone/Capstone/Alternative_data/Original_images/\",\n",
        "    \"Deepfakes\": \"/Users/asmaaaly/Minerva_Shit/Capstone/Minerva_Capstone/Capstone/Alternative_data/Mainpulated_images/\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_real = pd.DataFrame(read_images('original'),columns=[\"id\",\"label\",\"dataset_type\"])\n",
        "data_Deepfakes = pd.DataFrame(read_images('Deepfakes'),columns=[\"id\",\"label\",\"dataset_type\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "frames = [data_real, data_Deepfakes]\n",
        "df_data = pd.concat(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "a must be greater than 0 unless no samples are taken",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-cd08372fefb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# filter out class 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# concat the dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[1;32m   5345\u001b[0m             )\n\u001b[1;32m   5346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5347\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5348\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
          ]
        }
      ],
      "source": [
        "df_0 = df_data[df_data['label'] == 0].sample(100, random_state = 101)\n",
        "# filter out class 1\n",
        "df_1 = df_data[df_data['label'] == 1].sample(100, random_state = 101)\n",
        "\n",
        "# concat the dataframes\n",
        "df_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n",
        "# shuffle\n",
        "\n",
        "df_data['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = df_data['label']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-cda5799833c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2121\u001b[0;31m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0m\u001b[1;32m   2122\u001b[0m                                               default_test_size=0.25)\n\u001b[1;32m   2123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1801\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1802\u001b[0m             \u001b[0;34m'With n_samples={}, test_size={} and train_size={}, the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m             \u001b[0;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ],
      "source": [
        "df_train, df_val = train_test_split(df_train, test_size=0.20, random_state=101, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_dir = '/Users/asmaaaly/Minerva_Shit/Capstone/Minerva_Capstone/Capstone/Alternative_data/base_dir/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_dir = '/Users/asmaaaly/Minerva_Shit/Capstone/Minerva_Capstone/Capstone/Alternative_data/base_dir/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_dir = '/Users/asmaaaly/Minerva_Shit/Capstone/Minerva_Capstone/Capstone/Alternative_data/base_dir/'\n",
        "train_dir = os.path.join(base_dir, 'train_dir')\n",
        "os.mkdir(train_dir)\n",
        "# val_dir\n",
        "val_dir = os.path.join(base_dir, 'val_dir')\n",
        "os.mkdir(val_dir)\n",
        "\n",
        "original_os = os.path.join(train_dir, 'Real')\n",
        "os.mkdir(original_youtube_os)\n",
        "fake_os = os.path.join(train_dir, 'Fake')\n",
        "os.mkdir(fake_os)\n",
        "\n",
        "\n",
        "# create new folders inside val_dir\n",
        "original_os = os.path.join(val_dir, 'Real')\n",
        "os.mkdir(original_os)\n",
        "fake_os = os.path.join(val_dir, 'Real')\n",
        "os.mkdir(fake_os)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "original_youtube_os = os.path.join(train_dir, 'original')\n",
        "os.mkdir(original_youtube_os)\n",
        "deepfake_os = os.path.join(train_dir, 'fake')\n",
        "os.mkdir(deepfake_os)\n",
        "\n",
        "\n",
        "# create new folders inside val_dir\n",
        "original_youtube_os = os.path.join(val_dir, 'original')\n",
        "os.mkdir(original_youtube_os)\n",
        "deepfake_os = os.path.join(val_dir, 'fake')\n",
        "os.mkdir(deepfake_os)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-44aabbf26ee3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
          ]
        }
      ],
      "source": [
        "train_list = list(df_train['id'])\n",
        "val_list = list(df_val['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141    1\n",
              "145    1\n",
              "17     0\n",
              "65     0\n",
              "83     0\n",
              "      ..\n",
              "128    1\n",
              "122    1\n",
              "44     0\n",
              "25     0\n",
              "72     0\n",
              "Name: label, Length: 160, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df_train[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_list' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7aa311eabe47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# copy the image from the source to the destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mtransfer_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_train_datset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_list' is not defined"
          ]
        }
      ],
      "source": [
        "def build_train_datset(image):\n",
        "    count = 0\n",
        "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
        "    fname = image\n",
        "    count += 1\n",
        "# get the label for a certain image\n",
        "    target = df_data.loc[df_data['id'] == fname]['label']\n",
        "    if target.any() == 0:\n",
        "        src = os.path.join(\"/Users/asmaaaly/Minerva_Shit/Capstone/Minerva_Capstone/Capstone/Alternative_data/Original_images/\", fname)\n",
        "        label = 'original_youtube'\n",
        "    else:\n",
        "        src = os.path.join(\"/Users/asmaaaly/Minerva_Shit/Capstone/Minerva_Capstone/Capstone/Alternative_data/Mainpulated_images/\",fname)\n",
        "        label = 'deepfake'\n",
        "# destination path to image\n",
        "    dst = os.path.join(train_dir, label,fname)\n",
        "# copy the image from the source to the destination\n",
        "    shutil.copyfile(src, dst) \n",
        "pbar = tqdm(train_list)\n",
        "transfer_images = Parallel(n_jobs=4)(delayed(build_train_datset)(t) for t in pbar)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=40.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f44aca8a19b64d648c9e52acdddabd8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def build_test_datset(image):\n",
        "    fname = image\n",
        "# get the label for a certain image\n",
        "    target = df_data.loc[df_data['id'] == fname]['label']\n",
        "    if target.any() == 0:\n",
        "        src = os.path.join(\"/Users/asmaaaly/Minerva_Shit/Capstone/Minerva_Capstone/Capstone/Alternative_data/Original_images/\", fname)\n",
        "        label = 'original_youtube'\n",
        "    else:\n",
        "        src = os.path.join(\"/Users/asmaaaly/Minerva_Shit/Capstone/Minerva_Capstone/Capstone/Alternative_data/Mainpulated_images/\",fname)\n",
        "        label = 'deepfake'\n",
        "# destination path to image\n",
        "    dst = os.path.join(val_dir,label, fname)\n",
        "# copy the image from the source to the destination\n",
        "    shutil.copyfile(src, dst) \n",
        "pbar = tqdm(val_list)       \n",
        "transfer_images = Parallel(n_jobs=4)(delayed(build_test_datset)(t) for t in pbar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_path = '/Users/asmaaaly/Minerva_Shit/Capstone/Minerva_Capstone/Capstone/Alternative_data/base_dir/train_dir'\n",
        "valid_path = '/Users/asmaaaly/Minerva_Shit/Capstone/Minerva_Capstone/Capstone/Alternative_data/base_dir/val_dir'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_train_samples = len(df_train)\n",
        "num_val_samples = len(df_val)\n",
        "train_batch_size = 10\n",
        "val_batch_size = 10\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 160 images belonging to 2 classes.\nFound 40 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_gen = datagen.flow_from_directory(train_path,\n",
        "                                        target_size=(299,299),\n",
        "                                        batch_size=train_batch_size,\n",
        "                                        class_mode='categorical')\n",
        "\n",
        "val_gen = datagen.flow_from_directory(valid_path,\n",
        "                                        target_size=(299,299),\n",
        "                                        batch_size=val_batch_size,\n",
        "                                        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "#from itertools import izip, imap\n",
        "class_mode='binary'\n",
        "from itertools import zip_longest as izip\n",
        "x, y = izip(*(val_gen[i] for i in range(len(val_gen))))\n",
        "x_val = np.vstack(x)\n",
        "y_val = np.vstack(map(to_categorical, y))[:,0] if class_mode == 'binary' else y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "np.shape(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "#from itertools import izip, imap\n",
        "class_mode='binary'\n",
        "from itertools import zip_longest as izip\n",
        "x, y = izip(*(train_gen[i] for i in range(len(train_gen))))\n",
        "x_tran = np.vstack(x)\n",
        "y_tran = np.vstack(map(to_categorical, y))[:,0] if class_mode == 'binary' else y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dropout,InputLayer,Flatten,Dense,BatchNormalization,MaxPooling2D,Conv2D,Input,Concatenate,LeakyReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18, 18, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "train_features.shape[1:]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-i3c_UESE2P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "dedac7c8-475a-41ff-c571-39dd3a4d5419"
      },
      "source": [
        "\n",
        "model, eval_model, manipulate_model = CapsNet(input_shape=(18,18,512),n_class=2,routings=args.routings,                    batch_size=args.batch_size)\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_9 (InputLayer)            [(10, 18, 18, 512)]  0                                            \n__________________________________________________________________________________________________\nconv1 (Conv2D)                  (10, 10, 10, 256)    10617088    input_9[0][0]                    \n__________________________________________________________________________________________________\nprimarycap_conv2d (Conv2D)      (10, 1, 1, 256)      5308672     conv1[0][0]                      \n__________________________________________________________________________________________________\nprimarycap_reshape (Reshape)    (10, 32, 8)          0           primarycap_conv2d[0][0]          \n__________________________________________________________________________________________________\nprimarycap_squash (Lambda)      (10, 32, 8)          0           primarycap_reshape[0][0]         \n__________________________________________________________________________________________________\ndigitcaps (CapsuleLayer)        (10, 2, 16)          8192        primarycap_squash[0][0]          \n__________________________________________________________________________________________________\ninput_10 (InputLayer)           [(None, 2)]          0                                            \n__________________________________________________________________________________________________\nmask_3 (Mask)                   (10, 32)             0           digitcaps[0][0]                  \n                                                                 input_10[0][0]                   \n__________________________________________________________________________________________________\ncapsnet (Length)                (10, 2)              0           digitcaps[0][0]                  \n__________________________________________________________________________________________________\ndecoder (Sequential)            multiple             170577408   mask_3[0][0]                     \n==================================================================================================\nTotal params: 186,511,360\nTrainable params: 186,511,360\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x_val' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-e1d609945349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tran\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tran\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_val' is not defined"
          ]
        }
      ],
      "source": [
        "train(model=model, data=((train_features, y_tran), (x_val, y_val)), args=args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "# load model without classifier layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "\n",
        "conv_base = VGG19(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(300, 300, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg19\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_4 (InputLayer)         [(None, 300, 300, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 300, 300, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 300, 300, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 150, 150, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 150, 150, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 150, 150, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 75, 75, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 75, 75, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 75, 75, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 75, 75, 256)       590080    \n_________________________________________________________________\nblock3_conv4 (Conv2D)        (None, 75, 75, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n_________________________________________________________________\nblock4_conv4 (Conv2D)        (None, 37, 37, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock5_conv4 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n=================================================================\nTotal params: 20,024,384\nTrainable params: 7,079,424\nNon-trainable params: 12,944,960\n_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_base.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv = Sequential()\n",
        "\n",
        "for layer in conv_base.layers[:18]: # this is where I changed your code\n",
        "    conv.add(layer)    \n",
        "\n",
        "# Freeze the layers \n",
        "for layer in conv.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add 'softmax' instead of earlier 'prediction' layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nblock1_conv1 (Conv2D)        (None, 300, 300, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 300, 300, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 150, 150, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 150, 150, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 150, 150, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 75, 75, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 75, 75, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 75, 75, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 75, 75, 256)       590080    \n_________________________________________________________________\nblock3_conv4 (Conv2D)        (None, 75, 75, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n_________________________________________________________________\nblock4_conv4 (Conv2D)        (None, 37, 37, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n=================================================================\nTotal params: 12,944,960\nTrainable params: 0\nNon-trainable params: 12,944,960\n_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "def extract_features(directory, sample_count):\n",
        "    features = np.zeros(shape=(sample_count, 18, 18, 512))\n",
        "    labels = np.zeros(shape=(sample_count))\n",
        "    generator = datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=(300, 300),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "    i = 0\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch = conv.predict(inputs_batch)\n",
        "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "        i += 1\n",
        "        if i * batch_size >= sample_count:\n",
        "            # Note that since generators yield data indefinitely in a loop,\n",
        "            # we must `break` after every image has been seen once.\n",
        "            break\n",
        "    return features, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "validation_labels.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dir = '/Users/asmaaaly/Minerva_Shit/Capstone/Minerva_Capstone/Capstone/Alternative_data/base_dir/train_dir'\n",
        "validation_dir = '/Users/asmaaaly/Minerva_Shit/Capstone/Minerva_Capstone/Capstone/Alternative_data/base_dir/val_dir'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_train_samples = 160\n",
        "num_val_samples = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 160 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_features, train_labels = extract_features(train_dir, num_train_samples)\n",
        "validation_features, validation_labels = extract_features(validation_dir, num_val_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160, 18, 18, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "np.shape(train_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18, 18, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "np.shape(train_features[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.6221 - capsnet_loss: 0.2469 - decoder_loss: 0.9571 - capsnet_accuracy: 0.4875\n",
            "Epoch 00001: val_capsnet_accuracy improved from -inf to 0.50000, saving model to ./result/weights-01.h5\n",
            "16/16 [==============================] - 20s 1s/step - loss: 0.6221 - capsnet_loss: 0.2469 - decoder_loss: 0.9571 - capsnet_accuracy: 0.4875 - val_loss: 0.6275 - val_capsnet_loss: 0.2131 - val_decoder_loss: 1.0571 - val_capsnet_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5840 - capsnet_loss: 0.2165 - decoder_loss: 0.9377 - capsnet_accuracy: 0.4375\n",
            "Epoch 00002: val_capsnet_accuracy did not improve from 0.50000\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.5840 - capsnet_loss: 0.2165 - decoder_loss: 0.9377 - capsnet_accuracy: 0.4375 - val_loss: 0.6031 - val_capsnet_loss: 0.2132 - val_decoder_loss: 0.9946 - val_capsnet_accuracy: 0.5000 - lr: 9.0000e-04\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5265 - capsnet_loss: 0.2152 - decoder_loss: 0.7944 - capsnet_accuracy: 0.4688\n",
            "Epoch 00003: val_capsnet_accuracy improved from 0.50000 to 0.57500, saving model to ./result/weights-03.h5\n",
            "16/16 [==============================] - 20s 1s/step - loss: 0.5265 - capsnet_loss: 0.2152 - decoder_loss: 0.7944 - capsnet_accuracy: 0.4688 - val_loss: 0.5248 - val_capsnet_loss: 0.2131 - val_decoder_loss: 0.7952 - val_capsnet_accuracy: 0.5750 - lr: 8.1000e-04\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4855 - capsnet_loss: 0.2151 - decoder_loss: 0.6898 - capsnet_accuracy: 0.5188\n",
            "Epoch 00004: val_capsnet_accuracy did not improve from 0.57500\n",
            "16/16 [==============================] - 19s 1s/step - loss: 0.4855 - capsnet_loss: 0.2151 - decoder_loss: 0.6898 - capsnet_accuracy: 0.5188 - val_loss: 0.5238 - val_capsnet_loss: 0.2130 - val_decoder_loss: 0.7927 - val_capsnet_accuracy: 0.5000 - lr: 7.2900e-04\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4979 - capsnet_loss: 0.2267 - decoder_loss: 0.6919 - capsnet_accuracy: 0.4437\n",
            "Epoch 00005: val_capsnet_accuracy did not improve from 0.57500\n",
            "16/16 [==============================] - 21s 1s/step - loss: 0.4979 - capsnet_loss: 0.2267 - decoder_loss: 0.6919 - capsnet_accuracy: 0.4437 - val_loss: 0.5245 - val_capsnet_loss: 0.2147 - val_decoder_loss: 0.7902 - val_capsnet_accuracy: 0.5000 - lr: 6.5610e-04\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4898 - capsnet_loss: 0.2175 - decoder_loss: 0.6946 - capsnet_accuracy: 0.4437\n",
            "Epoch 00006: val_capsnet_accuracy did not improve from 0.57500\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.4898 - capsnet_loss: 0.2175 - decoder_loss: 0.6946 - capsnet_accuracy: 0.4437 - val_loss: 0.5223 - val_capsnet_loss: 0.2124 - val_decoder_loss: 0.7905 - val_capsnet_accuracy: 0.5000 - lr: 5.9049e-04\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4868 - capsnet_loss: 0.2121 - decoder_loss: 0.7008 - capsnet_accuracy: 0.5625\n",
            "Epoch 00007: val_capsnet_accuracy did not improve from 0.57500\n",
            "16/16 [==============================] - 21s 1s/step - loss: 0.4868 - capsnet_loss: 0.2121 - decoder_loss: 0.7008 - capsnet_accuracy: 0.5625 - val_loss: 0.5224 - val_capsnet_loss: 0.2123 - val_decoder_loss: 0.7911 - val_capsnet_accuracy: 0.5000 - lr: 5.3144e-04\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4816 - capsnet_loss: 0.2113 - decoder_loss: 0.6895 - capsnet_accuracy: 0.5250\n",
            "Epoch 00008: val_capsnet_accuracy did not improve from 0.57500\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.4816 - capsnet_loss: 0.2113 - decoder_loss: 0.6895 - capsnet_accuracy: 0.5250 - val_loss: 0.5200 - val_capsnet_loss: 0.2105 - val_decoder_loss: 0.7895 - val_capsnet_accuracy: 0.5750 - lr: 4.7830e-04\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4790 - capsnet_loss: 0.2122 - decoder_loss: 0.6807 - capsnet_accuracy: 0.5437\n",
            "Epoch 00009: val_capsnet_accuracy did not improve from 0.57500\n",
            "16/16 [==============================] - 20s 1s/step - loss: 0.4790 - capsnet_loss: 0.2122 - decoder_loss: 0.6807 - capsnet_accuracy: 0.5437 - val_loss: 0.5211 - val_capsnet_loss: 0.2112 - val_decoder_loss: 0.7906 - val_capsnet_accuracy: 0.5000 - lr: 4.3047e-04\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4967 - capsnet_loss: 0.2187 - decoder_loss: 0.7092 - capsnet_accuracy: 0.4750\n",
            "Epoch 00010: val_capsnet_accuracy did not improve from 0.57500\n",
            "16/16 [==============================] - 24s 1s/step - loss: 0.4967 - capsnet_loss: 0.2187 - decoder_loss: 0.7092 - capsnet_accuracy: 0.4750 - val_loss: 0.5200 - val_capsnet_loss: 0.2101 - val_decoder_loss: 0.7906 - val_capsnet_accuracy: 0.5750 - lr: 3.8742e-04\n",
            "Trained model saved to './result/trained_model.h5'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 288x432 with 2 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"434.99625pt\" version=\"1.1\" viewBox=\"0 0 281.265625 434.99625\" width=\"281.265625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 434.99625 \nL 281.265625 434.99625 \nL 281.265625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.465625 199.045398 \nL 274.065625 199.045398 \nL 274.065625 22.318125 \nL 36.465625 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m5cedccc211\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.265625\" xlink:href=\"#m5cedccc211\" y=\"199.045398\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(44.084375 213.643835)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"95.265625\" xlink:href=\"#m5cedccc211\" y=\"199.045398\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(92.084375 213.643835)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"143.265625\" xlink:href=\"#m5cedccc211\" y=\"199.045398\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(140.084375 213.643835)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"191.265625\" xlink:href=\"#m5cedccc211\" y=\"199.045398\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(188.084375 213.643835)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"239.265625\" xlink:href=\"#m5cedccc211\" y=\"199.045398\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(236.084375 213.643835)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m3261af2d68\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3261af2d68\" y=\"193.455646\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.2 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(13.5625 197.254865)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3261af2d68\" y=\"150.371447\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.4 -->\n      <g transform=\"translate(13.5625 154.170666)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3261af2d68\" y=\"107.287247\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.6 -->\n      <g transform=\"translate(13.5625 111.086466)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3261af2d68\" y=\"64.203048\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.8 -->\n      <g transform=\"translate(13.5625 68.002267)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_10\">\n    <path clip-path=\"url(#p901a2ddd6d)\" d=\"M 47.265625 183.352185 \nL 71.265625 189.908567 \nL 95.265625 190.191325 \nL 119.265625 190.199116 \nL 143.265625 187.701872 \nL 167.265625 189.687974 \nL 191.265625 190.857341 \nL 215.265625 191.01234 \nL 239.265625 190.82481 \nL 263.265625 189.433323 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_11\">\n    <path clip-path=\"url(#p901a2ddd6d)\" d=\"M 47.265625 30.351183 \nL 71.265625 34.544821 \nL 95.265625 65.414611 \nL 119.265625 87.938662 \nL 143.265625 87.494356 \nL 167.265625 86.906383 \nL 191.265625 85.574801 \nL 215.265625 88.010579 \nL 239.265625 89.908524 \nL 263.265625 83.758454 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#p901a2ddd6d)\" d=\"M 47.265625 102.526213 \nL 71.265625 110.726512 \nL 95.265625 123.110242 \nL 119.265625 131.947454 \nL 143.265625 129.276041 \nL 167.265625 131.031667 \nL 191.265625 131.679045 \nL 215.265625 132.788872 \nL 239.265625 133.345329 \nL 263.265625 129.543019 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 36.465625 199.045398 \nL 36.465625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 274.065625 199.045398 \nL 274.065625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 36.465625 199.045398 \nL 274.065625 199.045398 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 36.465625 22.318125 \nL 274.065625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_10\">\n    <!-- Training loss -->\n    <defs>\n     <path d=\"M -0.296875 72.90625 \nL 61.375 72.90625 \nL 61.375 64.59375 \nL 35.5 64.59375 \nL 35.5 0 \nL 25.59375 0 \nL 25.59375 64.59375 \nL -0.296875 64.59375 \nz\n\" id=\"DejaVuSans-84\"/>\n     <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n     <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n     <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n     <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n     <path id=\"DejaVuSans-32\"/>\n     <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n     <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n    </defs>\n    <g transform=\"translate(117.226562 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-84\"/>\n     <use x=\"60.865234\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"101.978516\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"163.257812\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"191.041016\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"254.419922\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"282.203125\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"345.582031\" xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"409.058594\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"440.845703\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"468.628906\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"529.810547\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"581.910156\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 170.01875 74.90875 \nL 267.065625 74.90875 \nQ 269.065625 74.90875 269.065625 72.90875 \nL 269.065625 29.318125 \nQ 269.065625 27.318125 267.065625 27.318125 \nL 170.01875 27.318125 \nQ 168.01875 27.318125 168.01875 29.318125 \nL 168.01875 72.90875 \nQ 168.01875 74.90875 170.01875 74.90875 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_13\">\n     <path d=\"M 172.01875 35.416562 \nL 192.01875 35.416562 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_14\"/>\n    <g id=\"text_11\">\n     <!-- capsnet_loss -->\n     <defs>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 50.984375 -16.609375 \nL 50.984375 -23.578125 \nL -0.984375 -23.578125 \nL -0.984375 -16.609375 \nz\n\" id=\"DejaVuSans-95\"/>\n     </defs>\n     <g transform=\"translate(200.01875 38.916562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"54.980469\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"179.736328\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"231.835938\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"295.214844\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"356.738281\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"395.947266\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"445.947266\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"473.730469\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"534.912109\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"587.011719\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_15\">\n     <path d=\"M 172.01875 50.372812 \nL 192.01875 50.372812 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_16\"/>\n    <g id=\"text_12\">\n     <!-- decoder_loss -->\n     <defs>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n     </defs>\n     <g transform=\"translate(200.01875 53.872812)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"179.980469\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"304.638672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"366.162109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"407.275391\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"457.275391\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"485.058594\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"546.240234\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"598.339844\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 172.01875 65.329062 \nL 192.01875 65.329062 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_18\"/>\n    <g id=\"text_13\">\n     <!-- loss -->\n     <g transform=\"translate(200.01875 68.829062)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_8\">\n    <path d=\"M 36.465625 411.118125 \nL 274.065625 411.118125 \nL 274.065625 234.390852 \nL 36.465625 234.390852 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_6\">\n     <g id=\"line2d_19\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.265625\" xlink:href=\"#m5cedccc211\" y=\"411.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0 -->\n      <g transform=\"translate(44.084375 425.716562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"95.265625\" xlink:href=\"#m5cedccc211\" y=\"411.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 2 -->\n      <g transform=\"translate(92.084375 425.716562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_21\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"143.265625\" xlink:href=\"#m5cedccc211\" y=\"411.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 4 -->\n      <g transform=\"translate(140.084375 425.716562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"191.265625\" xlink:href=\"#m5cedccc211\" y=\"411.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 6 -->\n      <g transform=\"translate(188.084375 425.716562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_23\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"239.265625\" xlink:href=\"#m5cedccc211\" y=\"411.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 8 -->\n      <g transform=\"translate(236.084375 425.716562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_5\">\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3261af2d68\" y=\"400.163955\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 0.44 -->\n      <g transform=\"translate(7.2 403.963174)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_25\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3261af2d68\" y=\"376.795057\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 0.46 -->\n      <g transform=\"translate(7.2 380.594276)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3261af2d68\" y=\"353.42616\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 0.48 -->\n      <g transform=\"translate(7.2 357.225379)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_27\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3261af2d68\" y=\"330.057262\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- 0.50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(7.2 333.856481)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_28\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3261af2d68\" y=\"306.688365\"/>\n      </g>\n     </g>\n     <g id=\"text_23\">\n      <!-- 0.52 -->\n      <g transform=\"translate(7.2 310.487583)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_29\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3261af2d68\" y=\"283.319467\"/>\n      </g>\n     </g>\n     <g id=\"text_24\">\n      <!-- 0.54 -->\n      <g transform=\"translate(7.2 287.118686)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_30\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3261af2d68\" y=\"259.950569\"/>\n      </g>\n     </g>\n     <g id=\"text_25\">\n      <!-- 0.56 -->\n      <g transform=\"translate(7.2 263.749788)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_31\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3261af2d68\" y=\"236.581672\"/>\n      </g>\n     </g>\n     <g id=\"text_26\">\n      <!-- 0.58 -->\n      <g transform=\"translate(7.2 240.380891)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_32\">\n    <path clip-path=\"url(#p04d8cc610d)\" d=\"M 47.265625 344.662809 \nL 71.265625 403.085067 \nL 95.265625 366.571165 \nL 119.265625 308.148907 \nL 143.265625 395.782294 \nL 167.265625 395.782294 \nL 191.265625 257.029457 \nL 215.265625 300.846168 \nL 239.265625 278.937813 \nL 263.265625 359.268391 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path clip-path=\"url(#p04d8cc610d)\" d=\"M 47.265625 330.057262 \nL 71.265625 330.057262 \nL 95.265625 242.42391 \nL 119.265625 330.057262 \nL 143.265625 330.057262 \nL 167.265625 330.057262 \nL 191.265625 330.057262 \nL 215.265625 242.42391 \nL 239.265625 330.057262 \nL 263.265625 242.42391 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 36.465625 411.118125 \nL 36.465625 234.390852 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 274.065625 411.118125 \nL 274.065625 234.390852 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 36.465625 411.118125 \nL 274.065625 411.118125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 36.465625 234.390852 \nL 274.065625 234.390852 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_27\">\n    <!-- Training and validation accuracy -->\n    <defs>\n     <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n     <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n     <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n    </defs>\n    <g transform=\"translate(57.101875 228.390852)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-84\"/>\n     <use x=\"60.865234\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"101.978516\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"163.257812\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"191.041016\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"254.419922\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"282.203125\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"345.582031\" xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"409.058594\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"440.845703\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"502.125\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"565.503906\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"628.980469\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"660.767578\" xlink:href=\"#DejaVuSans-118\"/>\n     <use x=\"719.947266\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"781.226562\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"809.009766\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"836.792969\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"900.269531\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"961.548828\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"1000.757812\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"1028.541016\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"1089.722656\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"1153.101562\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1184.888672\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"1246.167969\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"1301.148438\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"1356.128906\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"1419.507812\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"1460.621094\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"1521.900391\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"1576.880859\" xlink:href=\"#DejaVuSans-121\"/>\n    </g>\n   </g>\n   <g id=\"legend_2\">\n    <g id=\"patch_13\">\n     <path d=\"M 43.465625 272.303352 \nL 185.004687 272.303352 \nQ 187.004687 272.303352 187.004687 270.303352 \nL 187.004687 241.390852 \nQ 187.004687 239.390852 185.004687 239.390852 \nL 43.465625 239.390852 \nQ 41.465625 239.390852 41.465625 241.390852 \nL 41.465625 270.303352 \nQ 41.465625 272.303352 43.465625 272.303352 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_34\">\n     <path d=\"M 45.465625 247.48929 \nL 65.465625 247.48929 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_35\"/>\n    <g id=\"text_28\">\n     <!-- capsnet_accuracy -->\n     <g transform=\"translate(73.465625 250.98929)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"54.980469\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"179.736328\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"231.835938\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"295.214844\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"356.738281\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"395.947266\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"445.947266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"507.226562\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"562.207031\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"617.1875\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"680.566406\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"721.679688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"782.958984\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"837.939453\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n    <g id=\"line2d_36\">\n     <path d=\"M 45.465625 262.44554 \nL 65.465625 262.44554 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_37\"/>\n    <g id=\"text_29\">\n     <!-- val_capsnet_accuracy -->\n     <g transform=\"translate(73.465625 265.94554)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"253.222656\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"314.501953\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"377.978516\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"430.078125\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"493.457031\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"554.980469\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"594.189453\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"644.189453\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"705.46875\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"760.449219\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"815.429688\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"878.808594\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"919.921875\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"981.201172\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"1036.181641\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p901a2ddd6d\">\n   <rect height=\"176.727273\" width=\"237.6\" x=\"36.465625\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p04d8cc610d\">\n   <rect height=\"176.727273\" width=\"237.6\" x=\"36.465625\" y=\"234.390852\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained model saved to './result/trained_model.h5'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 288x432 with 2 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"434.99625pt\" version=\"1.1\" viewBox=\"0 0 281.265625 434.99625\" width=\"281.265625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 434.99625 \nL 281.265625 434.99625 \nL 281.265625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.465625 199.045398 \nL 274.065625 199.045398 \nL 274.065625 22.318125 \nL 36.465625 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m57ac51160e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.265625\" xlink:href=\"#m57ac51160e\" y=\"199.045398\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(44.084375 213.643835)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"95.265625\" xlink:href=\"#m57ac51160e\" y=\"199.045398\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(92.084375 213.643835)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"143.265625\" xlink:href=\"#m57ac51160e\" y=\"199.045398\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(140.084375 213.643835)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"191.265625\" xlink:href=\"#m57ac51160e\" y=\"199.045398\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(188.084375 213.643835)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"239.265625\" xlink:href=\"#m57ac51160e\" y=\"199.045398\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(236.084375 213.643835)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m01b9e0d18d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m01b9e0d18d\" y=\"193.455646\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.2 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(13.5625 197.254865)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m01b9e0d18d\" y=\"150.371447\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.4 -->\n      <g transform=\"translate(13.5625 154.170666)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m01b9e0d18d\" y=\"107.287247\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.6 -->\n      <g transform=\"translate(13.5625 111.086466)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m01b9e0d18d\" y=\"64.203048\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.8 -->\n      <g transform=\"translate(13.5625 68.002267)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_10\">\n    <path clip-path=\"url(#p1a7b4acdfa)\" d=\"M 47.265625 183.352185 \nL 71.265625 189.908567 \nL 95.265625 190.191325 \nL 119.265625 190.199116 \nL 143.265625 187.701872 \nL 167.265625 189.687974 \nL 191.265625 190.857341 \nL 215.265625 191.01234 \nL 239.265625 190.82481 \nL 263.265625 189.433323 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_11\">\n    <path clip-path=\"url(#p1a7b4acdfa)\" d=\"M 47.265625 30.351183 \nL 71.265625 34.544821 \nL 95.265625 65.414611 \nL 119.265625 87.938662 \nL 143.265625 87.494356 \nL 167.265625 86.906383 \nL 191.265625 85.574801 \nL 215.265625 88.010579 \nL 239.265625 89.908524 \nL 263.265625 83.758454 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#p1a7b4acdfa)\" d=\"M 47.265625 102.526213 \nL 71.265625 110.726512 \nL 95.265625 123.110242 \nL 119.265625 131.947454 \nL 143.265625 129.276041 \nL 167.265625 131.031667 \nL 191.265625 131.679045 \nL 215.265625 132.788872 \nL 239.265625 133.345329 \nL 263.265625 129.543019 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 36.465625 199.045398 \nL 36.465625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 274.065625 199.045398 \nL 274.065625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 36.465625 199.045398 \nL 274.065625 199.045398 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 36.465625 22.318125 \nL 274.065625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_10\">\n    <!-- Training loss -->\n    <defs>\n     <path d=\"M -0.296875 72.90625 \nL 61.375 72.90625 \nL 61.375 64.59375 \nL 35.5 64.59375 \nL 35.5 0 \nL 25.59375 0 \nL 25.59375 64.59375 \nL -0.296875 64.59375 \nz\n\" id=\"DejaVuSans-84\"/>\n     <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n     <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n     <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n     <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n     <path id=\"DejaVuSans-32\"/>\n     <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n     <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n    </defs>\n    <g transform=\"translate(117.226562 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-84\"/>\n     <use x=\"60.865234\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"101.978516\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"163.257812\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"191.041016\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"254.419922\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"282.203125\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"345.582031\" xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"409.058594\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"440.845703\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"468.628906\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"529.810547\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"581.910156\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 170.01875 74.90875 \nL 267.065625 74.90875 \nQ 269.065625 74.90875 269.065625 72.90875 \nL 269.065625 29.318125 \nQ 269.065625 27.318125 267.065625 27.318125 \nL 170.01875 27.318125 \nQ 168.01875 27.318125 168.01875 29.318125 \nL 168.01875 72.90875 \nQ 168.01875 74.90875 170.01875 74.90875 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_13\">\n     <path d=\"M 172.01875 35.416562 \nL 192.01875 35.416562 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_14\"/>\n    <g id=\"text_11\">\n     <!-- capsnet_loss -->\n     <defs>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 50.984375 -16.609375 \nL 50.984375 -23.578125 \nL -0.984375 -23.578125 \nL -0.984375 -16.609375 \nz\n\" id=\"DejaVuSans-95\"/>\n     </defs>\n     <g transform=\"translate(200.01875 38.916562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"54.980469\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"179.736328\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"231.835938\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"295.214844\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"356.738281\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"395.947266\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"445.947266\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"473.730469\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"534.912109\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"587.011719\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_15\">\n     <path d=\"M 172.01875 50.372812 \nL 192.01875 50.372812 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_16\"/>\n    <g id=\"text_12\">\n     <!-- decoder_loss -->\n     <defs>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n     </defs>\n     <g transform=\"translate(200.01875 53.872812)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"179.980469\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"304.638672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"366.162109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"407.275391\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"457.275391\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"485.058594\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"546.240234\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"598.339844\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 172.01875 65.329062 \nL 192.01875 65.329062 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_18\"/>\n    <g id=\"text_13\">\n     <!-- loss -->\n     <g transform=\"translate(200.01875 68.829062)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_8\">\n    <path d=\"M 36.465625 411.118125 \nL 274.065625 411.118125 \nL 274.065625 234.390852 \nL 36.465625 234.390852 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_6\">\n     <g id=\"line2d_19\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.265625\" xlink:href=\"#m57ac51160e\" y=\"411.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0 -->\n      <g transform=\"translate(44.084375 425.716562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"95.265625\" xlink:href=\"#m57ac51160e\" y=\"411.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 2 -->\n      <g transform=\"translate(92.084375 425.716562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_21\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"143.265625\" xlink:href=\"#m57ac51160e\" y=\"411.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 4 -->\n      <g transform=\"translate(140.084375 425.716562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"191.265625\" xlink:href=\"#m57ac51160e\" y=\"411.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 6 -->\n      <g transform=\"translate(188.084375 425.716562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_23\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"239.265625\" xlink:href=\"#m57ac51160e\" y=\"411.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 8 -->\n      <g transform=\"translate(236.084375 425.716562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_5\">\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m01b9e0d18d\" y=\"400.163955\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 0.44 -->\n      <g transform=\"translate(7.2 403.963174)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_25\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m01b9e0d18d\" y=\"376.795057\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 0.46 -->\n      <g transform=\"translate(7.2 380.594276)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m01b9e0d18d\" y=\"353.42616\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 0.48 -->\n      <g transform=\"translate(7.2 357.225379)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_27\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m01b9e0d18d\" y=\"330.057262\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- 0.50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(7.2 333.856481)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_28\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m01b9e0d18d\" y=\"306.688365\"/>\n      </g>\n     </g>\n     <g id=\"text_23\">\n      <!-- 0.52 -->\n      <g transform=\"translate(7.2 310.487583)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_29\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m01b9e0d18d\" y=\"283.319467\"/>\n      </g>\n     </g>\n     <g id=\"text_24\">\n      <!-- 0.54 -->\n      <g transform=\"translate(7.2 287.118686)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_30\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m01b9e0d18d\" y=\"259.950569\"/>\n      </g>\n     </g>\n     <g id=\"text_25\">\n      <!-- 0.56 -->\n      <g transform=\"translate(7.2 263.749788)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_31\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m01b9e0d18d\" y=\"236.581672\"/>\n      </g>\n     </g>\n     <g id=\"text_26\">\n      <!-- 0.58 -->\n      <g transform=\"translate(7.2 240.380891)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_32\">\n    <path clip-path=\"url(#p556b70ae39)\" d=\"M 47.265625 344.662809 \nL 71.265625 403.085067 \nL 95.265625 366.571165 \nL 119.265625 308.148907 \nL 143.265625 395.782294 \nL 167.265625 395.782294 \nL 191.265625 257.029457 \nL 215.265625 300.846168 \nL 239.265625 278.937813 \nL 263.265625 359.268391 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path clip-path=\"url(#p556b70ae39)\" d=\"M 47.265625 330.057262 \nL 71.265625 330.057262 \nL 95.265625 242.42391 \nL 119.265625 330.057262 \nL 143.265625 330.057262 \nL 167.265625 330.057262 \nL 191.265625 330.057262 \nL 215.265625 242.42391 \nL 239.265625 330.057262 \nL 263.265625 242.42391 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 36.465625 411.118125 \nL 36.465625 234.390852 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 274.065625 411.118125 \nL 274.065625 234.390852 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 36.465625 411.118125 \nL 274.065625 411.118125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 36.465625 234.390852 \nL 274.065625 234.390852 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_27\">\n    <!-- Training and validation accuracy -->\n    <defs>\n     <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n     <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n     <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n    </defs>\n    <g transform=\"translate(57.101875 228.390852)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-84\"/>\n     <use x=\"60.865234\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"101.978516\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"163.257812\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"191.041016\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"254.419922\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"282.203125\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"345.582031\" xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"409.058594\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"440.845703\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"502.125\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"565.503906\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"628.980469\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"660.767578\" xlink:href=\"#DejaVuSans-118\"/>\n     <use x=\"719.947266\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"781.226562\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"809.009766\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"836.792969\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"900.269531\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"961.548828\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"1000.757812\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"1028.541016\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"1089.722656\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"1153.101562\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1184.888672\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"1246.167969\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"1301.148438\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"1356.128906\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"1419.507812\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"1460.621094\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"1521.900391\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"1576.880859\" xlink:href=\"#DejaVuSans-121\"/>\n    </g>\n   </g>\n   <g id=\"legend_2\">\n    <g id=\"patch_13\">\n     <path d=\"M 43.465625 272.303352 \nL 185.004687 272.303352 \nQ 187.004687 272.303352 187.004687 270.303352 \nL 187.004687 241.390852 \nQ 187.004687 239.390852 185.004687 239.390852 \nL 43.465625 239.390852 \nQ 41.465625 239.390852 41.465625 241.390852 \nL 41.465625 270.303352 \nQ 41.465625 272.303352 43.465625 272.303352 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_34\">\n     <path d=\"M 45.465625 247.48929 \nL 65.465625 247.48929 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_35\"/>\n    <g id=\"text_28\">\n     <!-- capsnet_accuracy -->\n     <g transform=\"translate(73.465625 250.98929)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"54.980469\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"179.736328\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"231.835938\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"295.214844\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"356.738281\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"395.947266\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"445.947266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"507.226562\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"562.207031\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"617.1875\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"680.566406\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"721.679688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"782.958984\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"837.939453\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n    <g id=\"line2d_36\">\n     <path d=\"M 45.465625 262.44554 \nL 65.465625 262.44554 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_37\"/>\n    <g id=\"text_29\">\n     <!-- val_capsnet_accuracy -->\n     <g transform=\"translate(73.465625 265.94554)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"253.222656\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"314.501953\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"377.978516\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"430.078125\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"493.457031\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"554.980469\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"594.189453\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"644.189453\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"705.46875\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"760.449219\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"815.429688\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"878.808594\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"919.921875\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"981.201172\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"1036.181641\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p1a7b4acdfa\">\n   <rect height=\"176.727273\" width=\"237.6\" x=\"36.465625\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p556b70ae39\">\n   <rect height=\"176.727273\" width=\"237.6\" x=\"36.465625\" y=\"234.390852\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARkAAAG0CAYAAAAGklMnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOydeXhU1fnHP28mOwn7TkACInsSlrAKCC6AsgiKuIFg0doi2tK6FW2plV9tpVq1FlwqAtIquLCIYrWAoICyyK6gWdiEEAJkJcvMvL8/7mSYhOzJMBM4n+e5z7333LO8987Md84595z3iKpiMBgM3iLA1wYYDIZLGyMyBoPBqxiRMRgMXsWIjMFg8CpGZAwGg1cxImMwGLyKERlDuYiITUSyRKRNTcatgh3PiMhbNZ2vwbsE+toAQ80jIlkep+FAHuBwnf9cVZdUJj9VdQARNR3XcHlgROYSRFXdP3IRSQamqernpcUXkUBVtV8M2wyXH6a5dBniana8KyL/EZFM4G4R6S8iW0TkrIgcF5GXRCTIFT9QRFRE2rrO33Zd/0REMkVks4hEVzau6/pIETkoIuki8rKIfCUiUyp4H+NEZJ/L5rUi0tHj2u9E5CcRyRCR70XkGld4PxHZ4QpPEZHnauCRGsrAiMzlyzjg30A94F3ADjwMNAYGAiOAn5eR/k7gKaAhcBj4U2XjikhTYCnwiKvcJKBPRYwXkc7AYmAG0AT4HFgpIkEi0tVle09VrQuMdJUL8DLwnCv8SuC9ipRnqDpGZC5fvlTVVarqVNVzqrpVVb9WVbuqJgKvAUPKSP+eqm5T1QJgCRBXhbijgJ2qusJ17QXgVAXtvx1YqaprXWmfxRLMvliCGQp0dTUFk1z3BFAAdBCRRqqaqapfV7A8QxUxInP5csTzREQ6ichqETkhIhnA01i1i9I44XGcQ9mdvaXFbelph1qzdY9WwPbCtIc80jpdaVup6gHgN1j3cNLVLGzuijoV6AIcEJFvROTGCpZnqCJGZC5fik+/fxXYC1zpakr8HhAv23AciCo8EREBWlUw7U/AFR5pA1x5HQNQ1bdVdSAQDdiAP7vCD6jq7UBT4G/A+yISWv1bMZSGERlDIZFAOpDt6u8oqz+mpvgI6Ckio0UkEKtPqEkF0y4FxojINa4O6keATOBrEeksIkNFJAQ459qcACIySUQau2o+6Vhi66zZ2zJ4YkTGUMhvgHuwfqivYnUGexVVTQEmAs8DaUB74FuscT3lpd2HZe88IBWro3qMq38mBPgrVv/OCaABMMuV9EbgO9dbtbnARFXNr8HbMhRDjNMqg78gIjasZtCtqrrR1/YYagZTkzH4FBEZISL1XU2bp7De/nzjY7MMNYgRGYOvuRpIxGryDAfGqWq5zSVD7cE0lwwGg1cxNRmDweBVjMgYDAav4nezsBs3bqxt27b1tRkGg6ESbN++/ZSqljjGye9Epm3btmzbts3XZhgMhkogIodKu2aaSwaDwasYkTEYDF7FiIzBYPAqftcnYzB4UlBQwNGjR8nNzfW1KQYgNDSUqKgogoKCKpzGiIzBrzl69CiRkZG0bdsWyxOEwVeoKmlpaRw9epTo6OjyE7iovSKzexns+xCadoZmXaBpV2jUHmwVV1iD/5Obm2sExk8QERo1akRqamql0tVekcnPgrQf4OAnoC53ILZgaHwVNO1yXniadoZ6UWC+pLUWIzD+Q1U+i9orMr2nWltBLpw6CCf3Q8o+OPkdHPoK9iw9HzeknkeNp8t5EQpr4Dv7DYbLhNorMoUEhUKLGGvz5NwZOPk9nNwHKfstEdrzPuS9eT5OZMuiza1mXaBxRytPg8EPWb9+PcHBwQwYMKDUOLNnzyYiIoLf/va3F9Gy0qn9IlMaYQ3giv7WVogqZPxkCc7J/S7x2QdffwkOl3cBCYCG7S3BaXcN9JpqmloGv2H9+vVERESUKTL+xuU1TkYE6rWCDtfDwIdh/KvwwJfwu59g+laY8BYMfgSadITju+CjX8PWN3xttcEPWLRoETExMcTGxjJp0iRWrVpF37596dGjB9dddx0pKSmAVYuYNGkS/fv3p0OHDrz++usAHD9+nMGDBxMXF0e3bt3YuNFy/BcREcGsWbOIjY2lX79+7nxSU1O55ZZbiI+PJz4+nq+++ork5GTmz5/PCy+8QFxcnDuPsti5cyf9+vUjJiaGcePGcebMGQBeeuklunTpQkxMDLfffjsAX3zxBXFxccTFxdGjRw8yMzNr5NldujWZymALhCZXWVvXcVaY0wn/uR3WPAEt4qB1vG9tNPDHVfvY/1NGjebZpWVd/jC6a5lx9u3bxzPPPMOmTZto3Lgxp0+fRkTYsmULIsIbb7zBX//6V/72t78BsHv3brZs2UJ2djY9evTgpptu4j//+Q/Dhw9n1qxZOBwOcnJyAMjOzqZfv37MmTOHRx99lNdff50nn3yShx9+mF//+tdcffXVHD58mOHDh/Pdd9/xwAMPVKopNHnyZF5++WWGDBnC73//e/74xz/y97//nWeffZakpCRCQkI4e/YsAHPnzuWVV15h4MCBZGVlERpaM90GRmRKIyDAqum8OgSW3QM/3wB1ylqGyHCpsnbtWiZMmEDjxtbn37BhQ/bs2cPEiRM5fvw4+fn5RcaNjB07lrCwMMLCwhg6dCjffPMN8fHx3HvvvRQUFHDzzTcTF2etbxccHMyoUaMA6NWrF5999hkAn3/+Ofv373fnmZGRQVZWVqXsTk9P5+zZswwZYq3Rd8899zBhwgQAYmJiuOuuu7j55pu5+eabARg4cCAzZ87krrvuYvz48URFRZWad2UwIlMWYQ1g4mL41w3w3r0w6UMIsPnaqsuW8mocF5MZM2Ywc+ZMxowZw/r165k9e7b7WvHXvCLC4MGD2bBhA6tXr2bKlCnMnDmTyZMnExQU5I5vs9mw2+0AOJ1OtmzZUmO1ieKsXr2aDRs2sGrVKubMmcOePXt4/PHHuemmm/j4448ZOHAgn376KZ06dap2WZdXn0xVaBELN/0Nkr6Atc/42hqDDxg2bBjLli0jLS0NgNOnT5Oenk6rVtY6dAsXLiwSf8WKFeTm5pKWlsb69euJj4/n0KFDNGvWjPvuu49p06axY8eOMsu84YYbePnll93nO3fuBCAyMrLCfSX16tWjQYMG7r6bxYsXM2TIEJxOJ0eOHGHo0KH85S9/IT09naysLBISEujevTuPPfYY8fHxfP/99xV7QOVgajIVocfdcOQb+PJ5iOoNnW7ytUWGi0jXrl2ZNWsWQ4YMwWaz0aNHD2bPns2ECRNo0KABw4YNIykpyR0/JiaGoUOHcurUKZ566ilatmzJwoULee655wgKCiIiIoJFixaVWeZLL73E9OnTiYmJwW63M3jwYObPn8/o0aO59dZbWbFiBS+//DKDBg0qM5+FCxfywAMPkJOTQ7t27ViwYAEOh4O7776b9PR0VJWHHnqI+vXr89RTT7Fu3ToCAgLo2rUrI0eOrJHn53eOxHv37q1+6bSqIBfeHA6nE+H+9dYUBoPX+e677+jcubOvzagw/jZGxRuU9JmIyHZV7V1SfNNcqihBoVb/TIANlk6G/BxfW2Qw1ApMc6ky1G8Dt7wBb99qjaEZN98M1DMUwbMD2NvMmTOHZcuWFQmbMGECs2bNKiWFbzAiU1muvA6ueQLW/581diZ+mq8tMlymzJo1y+8EpSRMc6kqDH4EOtwAnzwOR/2w/8hg8COMyFSFgAAY9yrUbWH1z2Sf8rVFBoPfYkSmqoQ3hNsWWwLz/s/A6fC1RQaDX2JEpjq0jIOb5kLielg3x9fWGAx+iRGZ6tJzMvSYBBv/Bt9/7GtrDBeB2bNnM3fuXL/O+6233uLBBx+sAYuqjxGZmuDGudb0gw8fgLQEX1tjuIwonOvkz5hX2DVBUCjctsiasb10MvzsMwgO97VVlx6fPA4n9tRsns27w8hny402Z84cFi5cSNOmTWndujW9evUiISGB6dOnk5qaSnh4OK+//jqdOnUiJSWFBx54gMTERADmzZvHgAEDeP7553nzTcsz47Rp0/jVr35Vat5AqflPmTKF0NBQvv32WwYOHMjzzz9fpu3Jycnce++9nDp1iiZNmrBgwQLatGnDsmXL+OMf/4jNZqNevXps2LCBffv2MXXqVPLz83E6nbz//vt06NChOk/YiEyN0aCtNVBvyQRYPRNunmcG6l0ibN++nXfeeYedO3dit9vp2bMnvXr14v7772f+/Pl06NCBr7/+ml/+8pesXbuWhx56iCFDhvDhhx/icDjIyspi+/btLFiwgK+//hpVpW/fvu7JiiXlDZSaP1hLxWzatAmbrXyvADNmzOCee+7hnnvu4c033+Shhx5i+fLlPP3003z66ae0atXK7VNm/vz5PPzww9x1113k5+fjcFT/hYYRmZqkw/Uw5DH44lmIiof4n/naokuLCtQ4vMHGjRsZN24c4eFW7XTMmDHk5uayadMmt38WgLw8y4Xr2rVr3RMgC2sJX375JePGjaNOnToAjB8/no0bN+J0Oi/IGyArK6vU/MEa2VsRgQHYvHkzH3zwAQCTJk3i0UcfBSz/MVOmTOG2225j/PjxAPTv3585c+Zw9OhRxo8fX+1aDBiRqXmGPAbHtsGaxy2PelG9fG2RwQs4nU7q16/vdsFwsfMvFKvqMH/+fL7++mtWr15Nr1692L59O3feeSd9+/Zl9erV3Hjjjbz66qsMGzasWuWYjt+aJiAAxr8OEc1dA/XSfG2RoZoMHjyY5cuXc+7cOTIzM1m1ahXh4eFER0e75w6pKrt27QLg2muvZd68eQA4HA7S09MZNGgQy5cvJycnh+zsbD788EMGDRpUYt4AdevWLTX/yjJgwADeeecdAJYsWeJ2D5GQkEDfvn15+umnadKkCUeOHCExMZF27drx0EMPMXbsWHbv3l31B+fCiIw3CG8IExdBdiq8f68ZqFfL6dmzJxMnTiQ2NpaRI0cSH2/5e16yZAn/+te/iI2NpWvXrqxYsQKAF198kXXr1tG9e3d69erF/v376dmzJ1OmTKFPnz707duXadOm0aNHj1LzLiv/yvLyyy+zYMECYmJiWLx4MS+++CIAjzzyCN27d6dbt24MGDCA2NhYli5dSrdu3YiLi2Pv3r1Mnjy5mk/P+JPxLtsXwqqHYNBv4dqnfG1NraS2+ZO5HDD+ZPyJXvdYXvU2zoUDn/jaGoPBJxiR8TY3zoXmMfDBzy2vegZDDbJgwQL3WkmF2/Tp031tVhHM2yVvExRmedR7dQi8Oxl+9l8zUM9QY0ydOpWpU6f62owyqVZNRkRGiMgBEflRRB4v4XobEVknIt+KyG4RubE65dVaGrS13jil7IXVv7GWyzUYLhOqLDIiYgNeAUYCXYA7RKRLsWhPAktVtQdwO/DPqpZX67nqBhjyKOz6N2xf4GtrDIaLRnVqMn2AH1U1UVXzgXeAscXiKFDXdVwP+Kka5dV+hjwG7a+FTx6DY9t9bY3BcFGojsi0Ao54nB91hXkyG7hbRI4CHwMzqlFe7SfAZs1vimhu9c+YgXq1goiICF+bUKvx9tulO4C3VDUKuBFYLCIXlCki94vINhHZlpqa6mWTfEx4Q7htIWSfhPemgj2v/DQGQy2mOiJzDGjtcR7lCvPkZ8BSAFXdDIQCF6xar6qvqWpvVe3dpEmTaphUS2jVE0b93Vr69t+3QV7lFlI3+AZV5ZFHHqFbt250796dd999F4Djx48zePBg4uLi6NatGxs3bsThcDBlyhR33BdeeMHH1vuO6rzC3gp0EJFoLHG5HbizWJzDwLXAWyLSGUtkLvGqSgXpcRdIAKz4JSy+Ge5aBmENfG2VX/OXb/7C96drZn3mQjo17MRjfR6rUNwPPviAnTt3smvXLk6dOkV8fDyDBw/m3//+N8OHD2fWrFk4HA5ycnLYuXMnx44dY+/evQBuVwqXI1WuyaiqHXgQ+BT4Dust0j4ReVpExrii/Qa4T0R2Af8Bpqi/zWPwJXF3WM6uju+Ct0ZBZoqvLTKUwZdffskdd9yBzWajWbNmDBkyhK1btxIfH8+CBQuYPXs2e/bsITIyknbt2pGYmMiMGTNYs2YNdevWLb+AS5RqDcZT1Y+xOnQ9w37vcbwfGFidMi55Oo+GO5fCO3fCghEweYW1UqXhAipa47jYDB48mA0bNrB69WqmTJnCzJkzmTx5Mrt27eLTTz9l/vz5LF261O0V73LDTCvwB9oPtcQlJw3eHAGnfvC1RYYSGDRoEO+++y4Oh4PU1FQ2bNhAnz59OHToEM2aNeO+++5j2rRp7Nixg1OnTuF0Ornlllt45pln2LFjh6/N9xlmWoG/0LoPTFkNi8dZQjPpA8s5ucFvGDduHJs3byY2NhYR4a9//SvNmzdn4cKFPPfccwQFBREREcGiRYs4duwYU6dOxel0AvDnP//Zx9b7DuPqwd849SMsGgt5mXDXUmjTz9cW+RTj6sH/MK4eajuNr4R710BEE1h0M/z4ua8tMhiqhREZf6R+a5i6xhKcf98O+5b72iKDocoYkfFXIprAPR9Bq17WyOBv3/a1RQZDlTAi48+E1bc6gNtdAyumw5Z5vrbIJ/hbv+HlTFU+CyMy/k5wHbjjHeg8xlpmZf2zl5U/mtDQUNLS0ozQ+AGqSlpaGqGhoZVKZ15h1wYCQ+DWBZZT8vV/htx0uGGOtfzKJU5UVBRHjx7lkp84W0sIDQ0lKiqqUmmMyNQWbIEw5h8QUhe2/BNyM2DMS5b7iEuYoKAgoqOjfW2GoRoYkalNBATAiD9DaD1rKdz8TMutZ2CIry0zGErFiExtQwSGPgGhdeHT31luIiYutvpuDAY/5NJv1F+q9J9uNZ8S18Hi8XDu8nUlYPBvjMjUZnpOsjqEj22HhaMgy3SOGmoAVUhLgP1VWxa3OKa5VNvpejOERMA7d8OCkTB5OdSrXO+/wcDZw5C0AZI2WvvMnyynao8dsprm1cCIzKXAldfBpA8tV55vunzSNGrva6t8i8NudYznZVpv4vJcx3kZ5/dOB0Q2d20trH1ofavf61In84RLUL6A5I1wJtkKD28M0YOg7SCIHgIhkdUuyojMpcIV/eGeVfD2eJeriA+heTdfW1U+quAoAEd+sa0ACs6VLA7usExrzJDneWGcgpyq2RMYWlR0StvXwI/vopKdZolJsqumcuqgFR5aD664Gvr+whKXJp1rfPyVcfVwqZF60PIZnJ8Ft74J9dqAs8D60Trt1uYosMKcjvPHDtd5ZePa80oXCUd+sesF4Mgret2RX/l7lADrRx5S17Uvfuw6Dy0hzDOeBEBWivWvnnncYztxPizjOBRkX2hDcIQlNhHNL6wNuffNISjcNzWj3HQ4tMnVBNpgrV4KEFQHrhhgCUr0YGud9hoYa1WWqwcjMpciZw9bPmlOJ9Z83gFBYAuCgEBrCwyxzm0hYAu2jgM9jm3BRbdAz/PCdK54gSFF0wSGXCgMIZHW6/qL+cPNy/QQojL29twL0waGWk2Q8IYQ3sja6jR2HXuEhXuE2YIqb2N+NhzefL5f5fhOUKdVfus+lqBED4GWPaqWfzmUJTKmuXQpUr8NTPsf/Pg/68dYKAiF4uAWiSBrJHFAUCnXC48Lz22XR39FcQrFrXGH0uOoQu7ZYuJzAs6dtpoqOa7tTLK1z8soo7x6UKeRhwCVsNVpbDUnk7+0hOXYdqtmGRAIUfEw+BGrXyUqHoIqN9eopjEic6kS3hBiJvjaissHEWtJm7AG0LQCnvzs+ZYA5aRB9qnzIpTjCstxhWUcgxN7rDiOEhYClACrdtJ/ulVbadPP7wZmGpExGHxBYPD5fpuKoGo1iXI8akVgNYVC63nPzhrAiIzBUBsQscZDhURAgyt8bU2lMCN+DQaDVzEiYzAYvIoRGYPB4FWMyBgMBq9iRMZgMHgVIzIGg8GrGJExGAxexYiMwWDwKkZkDAaDV6m1IrP1xFb+ufOfJJ71wkxjg8FQY9TaaQU7UnYwf9d85u2ax1UNrmJk9EiGtx1O68jWvjbNYDB4UC1/MiIyAngRsAFvqOqzJcS5DZgNKLBLVe8sK8/K+JM5mXOSzw59xpqkNexM3QlAt0bdGBE9guFth9O8TgUnnxkMhmrhFadVImIDDgLXA0eBrcAdqrrfI04HYCkwTFXPiEhTVT1ZVr5VdVp1POs4nyZ/yprkNexL2wdAj6Y9GN52OMPbDqdxWONK52kwGCqGt0SmPzBbVYe7zp8AUNU/e8T5K3BQVd+oaL414RnvcMZhPk3+lE+SP+GHMz8QIAH0btabEdEjuK7NdTQIbVCt/A0GQ1G8JTK3AiNUdZrrfBLQV1Uf9IizHKu2MxCrSTVbVdeUlW9Nu99MOJvAmuQ1rElaQ3JGMjax0a9lP0a0HcGwNsOoG1y95R4MBoNvReYjoAC4DYgCNgDdVfVssbzuB+4HaNOmTa9Dhw5VyaayUFUOnDnAmqQ1rElew7GsYwQFBDGw1UBGtB3B0NZDCQ8Kr/FyDYbLAW/5+D0GeL7KiXKFeXIU+FpVC4AkETkIdMDqv3Gjqq8Br4FVk6mGTaUiInRq2IlODTvxcM+H2XtqL58kf8KnyZ+y/sh6Qm2hDIoaxMjokQxqNYjQQN/6RTUYLhWqU5MJxGoKXYslLluBO1V1n0ecEVidwfeISGPgWyBOVdNKy/dir1bgVCffnvyWNUlr+O+h/3I69zThgeFc0/oaRrcfzcCWA5HL0Xm2wVAJvLYkiojcCPwdq7/lTVWdIyJPA9tUdaVYv86/ASMABzBHVd8pK09fLolid9rZlrKNNUlr+Pzw56TnpdOtUTdm9JhB/5b9jdgYDKVg1l2qAgWOAj5K/Ih5u+ZxPPs4PZv2ZEaPGfRuXuJzNBgua4zIVIN8Rz4f/PABr+1+jdRzqfRv0Z8HezxITJMYX5tmMPgNRmRqgFx7Lu8eeJd/7fkXZ/LOcE3UNUzvMZ1ODTv52jSDwecYkalBcgpyWPLdEhbsW0BmfiY3XHED0+Om065+O1+bZjD4DCMyXiAjP4NF+xaxeP9ich253BR9E7+I/QWt65oJmobLDyMyXuRM7hkW7F3Af77/D3annZs73MzPY35uJmcaLiuMyFwEUnNSeWPPGyw7uAyA2zrexrTu08zETMNlgRGZi8jxrOO8uvtVlv+4nKCAIO7ofAf3dr2X+qH1fW2aweA1jMj4gMMZh5m3ax6rE1cTHhTOpC6TmNxlMpHBkb42zWCocYzI+JCEswm8svMVPjv0GXWD6zK121Tu7HSnmYxpuKQwIuMHfJf2Ha/sfIUvjn5Bw9CGTOs+jds63kaILcTXphkM1caIjB+xK3UX//j2H2w5voVGoY0Y1W4Uo9uPpmPDjr42zWCoMkZk/JCtJ7by9v632XBsA3annY4NOjKm/RhubHejeSNlqHUYkfFjzuSeYU3yGlb+uJK9aXuxiY0BLQcwpv0Yrml9jfFrY6gVGJGpJSSeTWRV4ipWJawiJSeFyKBIbmh7A2Paj6FH0x7G1YTBbzEiU8twqpOtJ7ayMmElnx36jHP2c0RFRDGm/RhGtR9l1pYy+B1GZGoxOQU5/O/w/1iRsIJvjn+DovRs2pPR7UdzQ9sbjCN0g19gROYS4UT2CT5K/IiVCStJSk8iOCCYYW2GMbr9aAa0HEBgQM0vCJpdkE1Kdgonsk+QklN0n1WQRb2QetQLrke9kHrUD6lf6j4sMMw09/wcVSX1XCpJ6UkkpieSkp3Cr3r9qkJpjchcYqgq+9P2syJhBZ8kfcLZvLM0Cm3Eje1uZGz7sRV+HZ5TkMOJ7BOcyDlhCUmxfUp2CpkFmRekaxTaiGZ1mhEZHElGXgbpeemk56eTXZBdallBAUElCpD7OPjCa5HBkQTbggmQWrtku19id9o5knnELSZJ6UnuLasgyx0vIiiCtbetJSwwrNw8jchcwhQ4Cth4bCMrE1byxdEvsDvtXNXgKsa0H0O/Fv1Iy02rkoA0D29OszrNaBbejOZ1mrv3TcObEmwLLtWW9Px0zuaetfZ5Zy0ByrvwuPD8bN5ZCpwFZd5joAQSZAsi2BZMcEAwwbZgggKKnduCCA7wCC8jjmdYeFA44YHhhAeFExYY5j4OD7TObQG2GvmcfEFOQQ5JGUkkni0qJIcyD2F32t3xmoY1Jbp+NNF1o2lXvx3R9aJpV68dTcKaVLj2aUTmMuFs7lnWJK9hVcIqdp/afcH1hqENiwhGZQTEW6gq5+zn3LUhtwDlppNZkEmBo4B8Zz75DmsrcBZQ4Cxwn+c784vGKTwvPHbFLXAUYFd7+QYVI9QWaolPoQgVilJgOGFBYe7jksQqNDDULXZBAUEEBgS6j4NsJZxLYKWblKpKWm6aW0AKayaJ6YmcyD7hjmcTG60jW7sFxHMfERxR6edSHCMylyGJ6YkcOH2AJmFN3DWSiy0g/obD6bBExyVIeY48zhWcI8eewzn7OXIKcsixuzbXcWF4keuF58Xi1QSeouM+LiZEhddyHbkkpyeTkZ/hTh8WGHaBkLSr147Wka0JsgXViI0l4a3F3Qx+TOGXy3AeW4ANW4CNUGp+gKNTneTacy3B8RCuwpqX3WmnwFHgPi9wFlx4XizM7rSXHtdRQKgtlBFtR1hNHFdTp1l4M7/rYDciYzDUAAESYDWZgsKh/H7SywrTbW8wGLyKERmDweBVjMgYDAavYkTGYDB4FSMyBoPBqxiRMRgMXsWIjMFg8CpGZAwGg1cxImMwGLyKERmDweBVjMgYDAavUi2REZERInJARH4UkcfLiHeLiKiIlDhL02AwXLpUWWRExAa8AowEugB3iEiXEuJFAg8DX1e1LIPBUHupTk2mD/Cjqiaqaj7wDjC2hHh/Av4C5FajLIPBUEupjsi0Ao54nB91hbkRkZ5Aa1VdXY1yDAZDLcZrHb8iEgA8D/ymAnHvF5FtIrItNTXVWyYZDAYfUB2ROQZ4rjIW5QorJBLoBqwXkWSgH7CypM5fVX1NVXurau8mTZpUwySDweBvVEdktgIdRCRaRIKB24GVhRdVNV1VG6tqW1VtC2wBxqiqceBrMI+P9ysAACAASURBVFxGVFlkVNUOPAh8CnwHLFXVfSLytIiMqSkDDQZD7aZaPn5V9WPg42Jhvy8l7jXVKctgMNROzIhfg8HgVYzIGAwGr2JExmAweBUjMgaDwasYkTEYDF7FiIzBYPAqRmQMBoNXMSJjMBi8ihEZg8HgVYzIGAwGr2JExmAweBUjMgaDwasYkTEYDF7FiIzBYPAqRmQMBoNXMSJjMBi8ihEZg8HgVYzIGAwGr2JExmAweBUjMgaDwasYkTEYDF7FiIzBYPAqRmQMBoNXMSJjMBi8ihEZg8HgVYzIGAwGr2JExmAweJVqrYXtS1bu+omPdx9n0FWNGdyhCa0bhvvaJIPBUAK1VmSy8+zsOZbOmn0nAGjbKJxBHZowqENj+rdvRGRokI8tNBgMAKKqvrahCL1799Zt27ZVKK6qkngqm40HU/nyx1NsSkgjJ9+BLUDo0bq+JTpXNSamVT0CbaZlaDB4CxHZrqq9S7xWm0WmOPl2J98ePsPGH06x8YdUdh9LRxXqhgYy8MrG7pqOaVoZDDXLZSMyxTmTnc9XCafYePAUG35I5Xh6LgDRjeswqENjrr7SNK0qg9OppGXnk5KRS0pGLtn5DhqEB9GwTjCNI0JoEB5McKCpMV6OXLYi44mqkpCazcYfUtn4wyk2J6RxrsBqWvVsU99dy4mJqo8tQGq8fH8nO8/OCZd4pGTkciI97/xxRi4nM/I4mZlLgaPs70tkaCCN6gTTsE4wjSJC3MfWeTAN61hh1nEwIYG2i3SHBm9iRKYE8uwOdhw6y8YfrP6cPa6mVb2wIAZe2YhBHZoQ17o+IYEB2AKEABFsAVL0WISAAEoI8x+RsjucpGblcSI9l5SMPLdonBcTS0Ay8+wXpI0ICaRZ3RCa1wulWWQozeqF0rxuKM3qhtCsbigRIYGcySngdHYep7LyOZ1tbWnZ+ZzOziMtyzo+k52P3Vny9ywiJNAtQo0jCgXJEqL64UFEhARSJySQOiE2ax9snYcH2wgJDEDEf551bcDucJKZa7e2vILzx7kF5/d5VlhuvoPnJ8ZVKN+yRKZab5dEZATwImAD3lDVZ4tdnwlMA+xAKnCvqh6qTpk1RUigjf7tG9G/fSMeBU5n5/PVj6fcNZ2P95yoVv5FRMhDoDwFKaAKP5DKJMmzOzmVlUfx/5HAAKFpZAjN6oVyVbNIBnVoQrO6oTSvF+IWk0IRqQlUlYxzdtKy8zidne8hSHkuQbK2Y2dz2XMsndPZ+eXWmArvIzzYRkRIIOEhgdQJtrkEKJCIEBvhIYHWtcI4wS6xcglVaFAAAWJ9DiLWs/U8DxAQEQRKjOe5F4QAz3PXXp3gVHVt1rNw6vkwdR/jOve47qRYnKJ5FDicZOYWkOESiixPsXAJSEaunazc82JyrsBR7nMNDgygbmggkaFB2B3Oar80qXJNRkRswEHgeuAosBW4Q1X3e8QZCnytqjki8gvgGlWdWFa+F6smUxZW0yqL745n4nCqtani9Nw7FYfiDnM4i11XxeH6ktgd1hfEUSx9KX/updtF5RIEBQRYtQ53DcTaGtUJ9qvaVnFUlcw8O2ezC8jOt5OTbycrz0FOnp2sPDs5+Q7X3k52noPsPDvZRY6tvZXOTm6B09e3dNEID7YRGWqJa2RoEJGhgdR17SNdwmFds44LxaTwekRoYJWasN6qyfQBflTVRFch7wBjAbfIqOo6j/hbgLurUd5FQ0S4smkkVzaN9LUplyUiQt3QIOrWUIe8w6mWWOWdFydLfByoUqQ2AZ61ivN7xaNmwfnahHrUQBTrT8epuONYNSAICBBEztd2CmtJAVK0BhTgEVYkfsCF8W0BUkREIkIC/XKoRnVEphVwxOP8KNC3jPg/Az6pRnkGQ5WwBdSsaBkqx0UZ8SsidwO9gSGlXL8fuB+gTZs2F8Mkg8FwkahO3eoY0NrjPMoVVgQRuQ6YBYxR1bySMlLV11S1t6r2btKkSTVMMhgM/kZ1RGYr0EFEokUkGLgdWOkZQUR6AK9iCczJapRlMBhqKVUWGVW1Aw8CnwLfAUtVdZ+IPC0iY1zRngMigGUislNEVpaSncFguESpVp+Mqn4MfFws7Pcex9dVJ3+DwVD78b/3XQaD4ZLC76YViEgqUNFRwY2BU140x9sY+32Lsb/muEJVS3xr43ciUxlEZFtpowxrA8Z+32LsvziY5pLBYPAqRmQMBoNXqe0i85qvDagmxn7fYuy/CNTqPhmDweD/1PaajMFg8HNqrciIyAgROSAiP4rI4762pzKISGsRWSci+0Vkn4g87GubqoKI2ETkWxH5yNe2VBYRqS8i74nI9yLynYj097VNlUFEfu367uwVkf+ISKivbSqNWikyLodZrwAjgS7AHSLSxbdWVQo78BtV7QL0A6bXMvsLeRhrSklt5EVgjap2AmKpRfchIq2Ah4DeqtoNyzPl7b61qnRqpcjg4TBLVfOBQodZtQJVPa6qO1zHmVhf8Fa+tapyiEgUcBPwhq9tqSwiUg8YDPwLQFXzVfWsb62qNIFAmIgEAuHATz62p1Rqq8iU5DCrVv1ICxGRtkAP4GvfWlJp/g48CtRG35bRWD6nF7iae2+ISB1fG1VRVPUYMBc4DBwH0lX1v761qnRqq8hcEohIBPA+8CtVzfC1PRVFREYBJ1V1u69tqSKBQE9gnqr2ALKBWtOvJyINsGru0UBLoI7LMZxfUltFpkIOs/wZEQnCEpglqvqBr+2pJAOBMSKSjNVUHSYib/vWpEpxFDiqqoW1x/ewRKe2cB2QpKqpqloAfAAM8LFNpVJbRaZch1n+jFiLBf0L+E5Vn/e1PZVFVZ9Q1ShVbYv17Neqqt/+kxZHVU8AR0SkoyvoWjwc4NcCDgP9RCTc9V26Fj/uuL4oPn5rGlW1i0ihwywb8Kaq7vOxWZVhIDAJ2CMiO11hv3P55zFcHGYAS1x/UonAVB/bU2FU9WsReQ/YgfWm8lv8ePSvGfFrMBi8Sm1tLhkMhlqCERmDweBVjMgYDAavYkSmkrjm62SJSLmr0FUmri8RkStFpMY750TkOtdr7sLzAyIyqCJxq1DWGyLyu6qmN3iPWvl2qTKISJbHaTiQBzhc5z9X1SWVyU9VHVjLvNRo3MsBVe1YfqzyEZFpwN2qeo1H3tNqIm9DzXPJi4yqun/krn/Kaar6eWnxRSTQtaaUweBzLoXv42XfXBKRZ0TkXdd0+UzgbhHpLyJbROSsiBwXkZdcI3QRkUARUdecI0Tkbdf1T0QkU0Q2i0h0ZeO6ro8UkYMiki4iL4vIVyIypRS7K2Ljz12uMM6IyEseaW0i8oKIpIlIIjCijOczS0TeKRb2iog87zqe5nKVkCkiCa5aRml5HRWRa1zH4SKy2GXbPqBXsbhPikiiK9994lowUES6A/8ABrmaoqc8nu1sj/QPuO49TUSWi0iLijybyjznQntE5HMROS0iJ0TkUY9ynnI9kwwR2SYiLUtqmorIl4Wfs+t5bnCVcxp4UkQ6iOUa5LSInHI9t3oe6a9w3WOq6/qLIhLqsrmzR7wWIpIjIo1Ku1+voKqXzQYkA9cVC3sGyAdGY4luGBAP9MWq6bUDDgIPuuIHAgq0dZ2/jbUsRW8gCHgXeLsKcZsCmVhzUoKAmUABMKWUe6mIjSuAekBb4HThvWOt/LkPazpGI2CD9VUosZx2QBZQxyPvk1huBnA9t3aAAMOAc0CM69p1QLJHXkeBa1zHc4H1QAPgCqwRt55xbwNauD6TO102NHNdmwasL2bn28Bs1/ENLhvjgFDgn1ijkst9NpV8zvWAFCyXFyFAXaCP69oTwC6gg+se4oCGwJXFnzXwZeHn7Lo3O/ALrIGmYcBVWKN6g13fk6+AuR73s9f1POu44g90XXsNmONRzm+ADy/6787XP/yLerOli8zactL9FlhW7EvqKRzzPeKOAfZWIe69wEaPa4I1w7ZEkamgjf08rn8A/NZ1vAGr2Vh47cbiX/xieW8B7nQdjwQOlBH3I2C667gskTns+VkAv/SMW0K+e4GbXMflicxC4P88rtXF6oeLKu/ZVPI5TwK2lhIvodDeYuEVEZnEcmy4tbBcYBBwArCVEG8gkMT5Qbc7gfE1/bsqb7vsm0suPN1GICKdRGS1q/qbATyNtZBWaZzwOM6h7M7e0uK29LRDrW/F0dIyqaCNFSqL8hfT+zdwh+v4Ttd5oR2jRORrV1X+LFYtoqxnVUiLsmwQkSkisstV5T8LdKpgvmDdnzs/tWa4n6GoO5AKfWblPOfWWGJSEmVdK4/i38fmIrJURI65bHirmA3Jar1kKIKqfoVVK7paRLoBbYDVVbSpyhiRsSj++vZVrH/OK1W1LvB7rJqFNzmO9U8LuCdRluUjpzo2HqfoLPbyXrEvBa4TyyPbWFwiIyJhWDOY/4zVlKkP/LeCdpwozQYRaQfMw2oyNHLl+71HvuW9bv8JqwlWmF8kVrOsKjP1y3rOR4D2paQr7Vq2y6Zwj7DmxeIUv7+/YL0V7e6yYUoxG64Qy1tkSSwC7saqdS1V1bxS4nkNIzIlEwmkA9mujrOfX4QyPwJ6ishosbydPQyUuOxnDdi4FPiViLRydQI+VlZktWYtf4n1D3pAVX9wXQrB6idIBRxi+Zm5thI2/E4sX7ttsPqJConA+qGlYuntfVg1mUJSgCjPDthi/Af4mYjEiEgIlghuVNVSa4ZlUNZzXgm0EZEHRSREROqKSB/XtTeAZ0SkvVjEiUhDLHE9gfWCwSYi9+MhiGXYkA2ki0hrrCZbIZuBNOD/xOpMDxORgR7XF2M1r+7EEpyLjhGZkvkNcA9WR+yrWB20XkVVU4CJwPNYX5r2WLNrS/vnqY6N84D/AXuw3Ga8V4E0/8bqY3E3ldRyWflr4EOsztNbscSyIvwBq0aVDHyCxw9AVXcDLwPfuOJ0pKjnwM+AH4AUEfFs9hSmX4PVrPnQlb4NcFcF7SpOqc9ZVdOB64FbsITvIDDEdfk5YDnWc87A6oQNdTWD7wN+h/US4ErK94r4ByyXs+lYwva+hw12YBTQGatWcxjrcyi8noz1Oeep6qZK3nuNYGZh+ymu6u9PwK2qutHX9hhqLyKyCKszebYvyr/kB+PVJkRkBNabnHNYr0ALsP7NDYYq4erfGgt095UNprnkX1yN5UApFRgOjPNFR53h0kBE/ow1Vuf/VPWwz+wwzSWDweBNKlSTkXJWa3SNaUgVkZ2ubZrHtb+KNSz8O9dQaW+/CjYYDH5EuX0ycn61xuuxBodtFZGVqlrc8fK7qvpgsbQDsEYdxriCvsTqfV9fTbsNBkMtoSIdv+7VGgHEmiw3lop5d1esuSPBWIOHgrBe9ZVK48aNtW3bthXI2mAw+Avbt28/paoljuuqiMiUtFpj3xLi3SIig7HGCvxaVY+o6mYRWYc1VkGAf6hqmUs3tG3blm3btlXALIPB4C+ISKlTU2rq7dIqrEmAMVgDpRa6Cr4Sa5BQFJZYDZMSPKOJyP2uqfDbUlNTa8gkg8HgD1REZMpdrVFV0zxetb7Bed8g44AtqpqlqllYIzv7Fy9AVV9T1d6q2rtJk7JG0hsMhtpGRUSm3NUaxeUQyMUYzq9mdxgYIpYDnyCsTl+/XenOYDDUPOX2yWgpqzWKyNPANlVdCTwklucyO9Yclimu5O9hOTLag9UJvEZVV1XWyIKCAo4ePUpubm5lkxoMAISGhhIVFUVQUGlzKg3ewu8G4/Xu3VuLd/wmJSURGRlJo0aNMMNsDJVFVUlLSyMzM5Po6OjyExgqjYhsV9XeJV2rFdMKcnNzLz2BKTgHmWW+zTfUECJCo0aNLm5NOGUffPnCxSuvpvl+NaycAbkZ1c6qVogMcGkJDEBWCmT+BHYzNelicNG/P1+9CJ/PhtOJF7fcmmL/Cvj+Ywiu/oo+tUZkLilUIS/TOs6r/D/F+vXr2bTJJ65BDBXB6YSEddZx4b42UWh/+6EQUH2JMCLjC+znwOlaSqdQbCqBP4mMquJ0On1thn9xch9kn7SOE9b61paqUGh/+2E1kp0RmUqwaNEiYmJiiI2NZdKkSaxatYq+ffvSo0cPrrvuOlJSrD6W2bNnM2nSJPr370+HDh14/fXXATh+/DiDBw8mrlcfug2bwMYdByAvi4iICGbNmkVsbCz9+vVz55Oamsott9xCfHw88fHxfPXVVyQnJzN//nxeeOEF4uLi2LixZH9WpdmWlZXF1KlT6d69OzExMbz/vuVkbc2aNfTs2ZPY2FiuvfZa933MnTvXnWe3bt1ITk4mOTmZjh07MnnyZLp168aRI0f4xS9+Qe/evenatSt/+MMf3Gm2bt3KgAEDiI2NpU+fPmRmZjJ48GB27tzpjnP11Veza9eumvqYfE+hsHQYDkkbwFHgW3sqS6H97YbWTH4Xe3mE8rZevXppcfbv339B2MVm79692qFDB01NTVVV1bS0ND19+rQ6nU5VVX399dd15syZqqr6hz/8QWNiYjQnJ0dTU1M1KipKjx07pnPnztVnnnlGNfWg2n/aoxkph1SP7VBAV65cqaqqjzzyiP7pT39SVdU77rhDN27cqKqqhw4d0k6dOrnzf+6558q0tzTbHn30UX344YeLxDt58qRGRUVpYmKi+95KKqdr166alJSkSUlJKiK6efNm97XCNHa7XYcMGaK7du3SvLw8jY6O1m+++UZVVdPT07WgoEDfeusttw0HDhzQkj5zb3DRvkdvjVZ9pZ/q3g9V/1BX9dDm8tP4EwvHWPZXAqzhLCX+pmudZ7w/rtrH/p+q3+PtSZeWdfnD6K5lxlm7di0TJkygcWNrJYqGDRuyZ88eJk6cyPHjx8nPzy/yenTs2LGEhYURFhbG0KFD+eabb4iPj+fee++l4PQRbr55PHEDO8GJNIKDgxk1ahQAvXr14rPPPgPg888/Z//+8/NQMzIyyMryXNq7dI4ePVqibZ9//jnvvHN+QcgGDRqwatUqBg8e7I7TsGHDcvO/4oor6Nevn/t86dKlvPbaa9jtdo4fP87+/fsREVq0aEF8fDwAdevWBWDChAn86U9/4rnnnuPNN99kypQpFbqnWkF+DhzeDH3uh3ZDQAKsmkGbfuWn9Qfyc+DQZuhzX41laZpL1WDGjBk8+OCD7Nmzh1dffbXIK9LibzNEhMGDB7Phv6tp1bwJUx78LYve/jcEhRMUGOiOb7PZsNut/hqn08mWLVvYuXMnO3fu5NixY0REVKy3vyzbKkpgYGCR/hbPPOrUqeM+TkpKYu7cufzvf/9j9+7d3HTTTWWWFx4ezvXXX8+KFStYunQpd91VVR/ffsihTeDIt/ozwhpAq161q1/m0CZw5FmdvjVEravJlFfj8BbDhg1j3LhxzJw5k0aNGnH69GnS09Np1cpaGmnhwoVF4q9YsYInnniC7Oxs1q9fz7PPPsuhQ4eIqh/KfXfdQl5oU3bs2MHkm68H1OoIDij6cdxwww28/PLLPPLIIwDs3LmTuLg4IiMjycgouzZXmm3XX389r7zyCn//+98BOHPmDP369eOXv/wlSUlJREdHc/r0aRo2bEjbtm356CNr8YEdO3aQlJRUYlkZGRnUqVOHevXqkZKSwieffMI111xDx44dOX78OFu3biU+Pp7MzEzCwsIIDAxk2rRpjB49mkGDBtGgQYMKfgq1gIS1YAuBKwZY5+2HwYbn4NwZS3T8Hbf9A8uPW0FMTaaCdO3alVmzZjFkyBBiY2OZOXMms2fPZsKECfTq1cvdjCokJiaGoUOH0q9fP5566ilatmzJ+vXriR1wHT2G38m7S5fy8MMPQ0iklSDvwmbQSy+9xLZt24iJiaFLly7Mnz8fgNGjR/Phhx+W2fFbmm1PPvkkZ86coVu3bsTGxrJu3TqaNGnCa6+9xvjx44mNjWXixIkA3HLLLZw+fZquXbvyj3/8g6uuuqrEsmJjY+nRowedOnXizjvvZOBA6wsaHBzMu+++y4wZM4iNjeX6669313B69epF3bp1mTp1aiU+hVpAwlpLYILCrPP2w0CdVgdwbaC4/TVBaZ01vtr8teO3MpTaMWvPUz22QzXzxPkwp0P1p12qZw5dPAP9gGPHjmmHDh3U4XBctDK9/j1KP2Z19H754vkwe77q/0WprnzIu2XXBCXZX0Eoo+PX1GQuJoVjYkLqng+TAAiJsK752Twyb7Fo0SL69u3LnDlzCKiBwV5+Q+HAO8/xJbYgiB4MP671/8+3JPtrgFrXJ1MbmD17dskXcjOtfpfA0KLhIZGQm251uBW/Vg5z5sxh2bJlRcImTJjArFmzKpXPxWTy5MlMnjzZ12bUPAlroU5TaFas37D9UPj+I2uKQaPSls72A0qzv5oYkblYqEJ+plWLKT6PprBmk5dZaZGZNWuWXwvKZYPTCYnr4MrrL/x8C2sGP/7Pf0WmLPurySVUV/VzClxTCQo7ej0JDAFbcI3MeDVUHK3J5suJXZCTVnJTo2E7aNDWv19ln9hduv3V5GKsu9RGRP7rWndpv4i0rTnzaxGFEyFLEhmwajP5WdabCIPXeXfrYQb9dR3p52poyH+hgJQ2vqT9tZC8Eez5NVNeTVOe/dWgXJHxWHdpJNAFuENEupQQ9V1VjXNtb3iELwKeU9XOWMurnKwBu2sfeZkQGGZ1BJZESKQlMPk5F9euy5Svfkzj6Jlz/HP9jzWTYcI6aN4dIpqWfL39MOtP5OjWmimvpklYW7b91aAiNRn3ukuqmg8UrrtULi4xClTVzwDUcih++f2KnA7Iz4bQUmoxYL1hgiq5fjBUngMnrDd9C75K5tjZc9XLLC8LDm8pu6kRPQjE5p9NporYXw0qIjIlrbvUqoR4t4jIbhF5T0QKVze4CjgrIh+IyLci8pyrZnR5kZ8FaNFX18UJCISgOlVy/WCoHPl2JwmpWdwc1xKAv/33QPUyPPQVOAvK/pGG1oOoeP8UmYrYXw28uu4S1turQcBvgXigHeedjLu5FNddKjLHKC8TCLBEpCxCI6EgBxx2r9pWnOXLlxeZiHmpk5yWjd2pXNOxKfcOjObDb4+x76f0qmeYsNZqCrcuZxJk+2Hw07eQc7rqZXmDitpfRby97tJRYKerqWUHlgM9ixegl/q6S3kZEFKnfC9jhTWd/Itbm/EnkSmcHOpNCptKVzWL5JdD21M/LIhnP/m+6hkmrIW2AyGonOEH7YcBConrq16WN6io/VWkIuNk3OsuYYnL7cCdnhFEpIWqHnedeq67tBWoLyJNVDUVa3mU6q1B+8njcGJPtbK4gObdYeSzZUZ5/PHHad26NdOnTwesAXeBgYGsW7eOM2fOUFBQwDPPPMPYscW6q+z5lh/f8KJzm/7yl7/w9ttvExAQwMiRI3n22Wd5/a0lvPbPl8i3O7myY2cWL15MeHg4U6ZMITQ0lG3btpGRkcHzzz/PqFGj2LdvH1OnTiU/Px+n08n7779PUFAQI0eO5Oqrr2bTpk20atWKFStWEBYWRkJCAtOnTyc1NZXw8HBef/11Tp8+zcqVK/niiy945plneP/992nf/sKxHK+//jqvvfYa+fn5XHnllW7bUlJSeOCBB0hMtHzZzps3jwEDBrBo0SLmzp2LiBATE8PixYuZMmUKo0aN4tZbbwWs2l5WVhbr16/nqaeeokGDBnz//fccPHiQm2++mSNHjpCbm8vDDz/M/fffD1jOtX73u9/hcDho3Lgxn332GR07dmTTpk00adIEp9PJVVddxebNmyntD+vAiUxsAUL7pnUICbQxY1gHnv5oPxsOpjL4qkr+yZ09AqcOQq8p5cdt2cNqNiWshW7jK1eOt6iM/VWltPkGnhtwI9Ya1wnALFfY08AY1/GfgX3ALmAd0Mkj7fXAbqy1l94Cgssqq9y5Sx8/pvrmjTW7ffxYuXMzduzYoYMHD3afd+7cWQ8fPqzp6emqqpqamqrt27d3O4qqU6eOFTEr1ZqvlJ9z/hY+/lj79++v2dnZqnre4dOpU6dU0xJUj+/RWb/7nb700kuqqnrPPffo8OHD1eFw6MGDB7VVq1Z67tw5ffDBB/Xtt99WVdW8vDzNycnRpKQktdls+u2336qq6oQJE3Tx4sWqqjps2DA9ePCgqqpu2bJFhw4d6s5/2bJlZd7/qVOn3MezZs1y23bbbbfpCy+8oKqWw6qzZ8+W6OCrpHIKn9G6des0PDzc7TTLM01OTo527dpVT506VapzrdmzZ7tt+PTTT3X8+PEl3kPh92jawq167d/Wu8PzChw66C9rdcTfN6jd4SzzOVzA9oXWfJ+UCs6Leudu1b91VnVWshxvUVn7S4HqOq1S1Y+Bj4uF/d7j+AngiVLSfgbEVEjxKkI5NQ5v0aNHD06ePMlPP/1EamoqDRo0oHnz5vz6179mw4YNBAQEcOzYMVJSUmjevPn5hHmZEBBUZCTv559/ztSpUwkPDwfOO4nau3cvTz7xGGfPpJGVW8Dw4SPcaW677TYCAgLo0KED7dq14/vvv6d///7MmTOHo0ePMn78eDp06ABAdHQ0cXFxgDXbOTk5maysLDZt2sSECRPOm5ZX8ZUS9u7dy5NPPsnZs2fJyspi+PDhgOXMa9GiRYDlC6devXosWrToAgdf5dGnT58iTr9eeuklPvzwQwCOHDnCDz/8QGpqaonOte69917Gjh3Lr371K958881yZ3YfTMmkW8t67vPgwAAeGd6RGf/5luXfHuOWXlEVfSzWKN7IltCkU8Xitx8G3620ag9NOla8HG+RsBYiW1Tc/ipgphVUggkTJvDee+9x4sQJJk6cyJIlS0hNTWX79u0EBQXRtm3bos6aClclCK1XoaHaU6ZMYfl7S4ltEchbKzeyfssO97WSnGDdeeed9O3bl9WrV3PjjTfy6quv0q5dO0JCQtzxbDYb586dw+l0Ur9+/SK+dSvDlClTWL58ObGxzYebqQAAIABJREFUsbz11lusX7++0nl4OsFyOp3k558fmObpBGv9+vV8/vnnbN68mfDwcK655poynWC1bt2aZs2asXbtWr755huWLFlSatycfDuHT+cwvkdRIRkV04I3Nibyt/8e4KaYFoQGVeAlqNNh9a90GlXxofiFb3AS1vpeZJwOa3xPp5tqfCqBJ2ZaQSWYOHEi77zzDu+99x4TJkwgPT2dpk2bEhQUxLp16zh06FDRBAU5oI4LRvlef/31LFiwgJwca8jQ6dPW24bMzExatL6CAmcAS95ZWiTNsmXLcDqdJCQkkJiYSMeOHUlMTKRdu3Y89NBDjB07lt27d5dqe926dYmOjnZPplRVt/PuyMhIMjPL7mzOzMykRYsWFBQUFPkRX3vttcybNw8Ah8NBeno6w4YNY9myZaSlpRW5v7Zt27J9+3YAVq5cSUFByaNt09PTadCgAeHh4Xz//fds2bIFgH79+rFhwwa386zCfAGmTZvG3XffzYQJE7DZSheIH1KyUIWOzYt+JiLCEzd25qf0XBZ8lVzms3Dz007IPVu5UbINroBGV/rHq2y3/d55dV2IEZlK0LVrVzIzM2nVqhUtWrTgrrvuYtu2bXTv3p1FixbRqVOxKmdJrh2AESNGMGbMGHr37k1cXJx7RYA//elP9O3bl4Fj76FTu9ZYy4dbtGnThj59+jBy5Ejmz59PaGgoS5cupVu3bsTFxbF3795yZzYvWbKEf/3rX8TGxtK1a1dWrFgBwO23385zzz1Hjx49SEhIKDGt27aBA4vc54svvsi6devo3r07vXr1Yv/+/SU6+AK47777+OKLL4iNjWXz5s1Fai/Fn4/dbqdz5848/vjjbl/CpTnXAhgzZox7JYayOJBifSbFRQagX7tGXNe5Kf9c9yOnsysw/D9hLSCV9+rffhgkf+n7hf3+v70zj4+rvO7+95nRvlm7ZFuyZMmSJWxj491geZFMgIRCCEsgdpLmTRvShCZNaVKSfNrshSxvlrZpE15SaLFLEwxJgLIELIMxWF4BG1uWbMnaLGu3pNEuzTzvH3ckZGskzXbnzh09389HH1szd+Ye6VydeZ5zzzk/b+33lOmSNUZ9hcLQqgnaq6Rsq/T8dYPdWrJ4qFdK6V5idq5z9OhRuXnz5hmPOXPmjPze86dl4TdfnDbBW93SKxc/9IL8znOnZz/pb26W8ldbZj/uas6+qCVba9/w/LX+xFv7XYAaWmUADrvWhzRTle90RMQBQlX/uskjjzzCnXfeycMPPzzrsVWtNgoy4rBaXOcgCjLi+fi6bJ6sqKOhc4YOmKFeaDri3VYjd7NW4W3klskX+z1EBRm9GO7jVGU1q0puZtWqVRNfGzZsmP21FitExE70MT3xxBMTtSV688UvfvEKe1etWsXjjz8ekHN7y0MPPUR9fT2bN2+e9diqFhtLM2YO/F/ZUUiYxcKPXpmhQK/uoDa6w5s/0sh4yN5gbJDxxX4PUXeX9GK4lxXXLNXu5ggvYnlkPNguaeqD03Vu68Avf/nLgJ0r0DgckjbbMEszZ5aVSU+I4i+35PHP+87xFyXdrMpOnHpQTbnWJpK93jtj8rdD+fehvwNiU2c/3t/4ar8HmGYlI4N9PurVDNu0bY83AQYmqRioLZM/kFIy6tCuocKMGbrhnXxuSx6pcRE8/GKl62uvplzb9oRFTn3OHSZuZe/37vW+4qv9HmCKIBMVFUVnZ6d5As3YsDavd7oBVe4QHqONBlBBxmeklHR2dmJz3jEvypw9TxYXGcaXdxRy+EIX5WevGoF0uQ66anzbasxfpekwGbFl8of9HmCK7VJWVhZNTU2YpkN7uA8GuyDeCtZO79+nvwfs7ZAw90bw+JuoqCj2N9pJiAojI8G9T+9712Xz+MELPPzSWbYWphFmdX4mjweGJWXeG2SxareOa5wqBjoWw01hYgqeCjIThIeHX1FyHvT8dpdW6PQ3p3y7eE48CS88AH91CDJcDSNUeMKpV95maWb8lOrp6Qi3Wvj7W4q4/8njPH28ifvWL9KeqCmHedlaUZ0v5JfC6WehrTKw/h23P7UgIKczxXbJVNjHoPaAltjz9dNpvJI0GKpDTY6UkrMtNrfyMZP50DUZrM1J4qevVjMwMmZ+//rTfjdRQcbfNJ+A4R7/LEXnZUHqUhVk/EBL7xC2oTGKXFT6zsR4u0G7bZjH3rwQVP4dHrN7/iJ/2u8mKsj4m/FS7cVb/fN++aXaeMTR6RsEFbMzeVCVp6zJSeKW5Zn8+o0a+s/8CaP9Ozhi5y/+8xibf7ifwREPA42/r0830F0Sxfl8ghCiSQjxr/4yPGipKYeFqyFm9vEGbpFfCmND0HDIP+83RxkPMq56ltzhazcXMTzmoOPky4b6t2dglE/+5jCvVbbSbhvmUG2HZ+fz9/XpBoGQRAH4HnDAZ2uDncFuaDrm36Vo7g3aPBq1ZfKJqlYbGQmRJMZEePX6xamxfHZNEgv7TtM1f/bKYrfxwL+tvUPc8+tDvNfUzc8+vpLYCCuvVXqgMKTH9ekGukqiAAgh1gAZwJ+8M9FE1L2pjXbwpxMjYmHRRuOKtkKE6lbPk75X88W8S4QJB79pzvWPUTDJvzMHmdr2Pj72b2/TdHmAJz6znjuuy6KkII3yyjb368f0uD7dQFdJFCGEBfi/aGoFoU9NOUTEa9IX/iS/FFpPga3Vv+87R7A7JOda+1jqY5BJuPgmI9ZYfl2bwrE6PyoO5JdC6/tga3H59Mmmbu761SGGRu38z+c2ccMSrQ2hrDidlt4hTje7qdV1fp8+1+cs6C2J8gXgRSll00wvDglJFCk1Jy7e4v9eo/Gir1q1mvGG+s5+hsccFHqZjwEm/GvN30pKQiz/NF27gTdM+Pf1KU8dPNfBfY9WEB1u5enPb2JF1gdjQ7cXpSMEUyuSp7O/Rqfrcxb0lkTZBDwghKgDfgJ8SggxZUivDAVJlK5a6K7XRUuYjBWa2oHKy3hFtXNQlae3r6/A6V/rklIevHEpJxq6efl91ysPj5nGvy+cbOYzTxwhKymGZ79wPXlpVzZ2psZFsio7kX2Vbqxwu2qhu0Gf63MW3AkyE5IoQogINEmU5yYfIISYP+nbCUkUKeVOKeUiKWUu2pbpv6SUU+5OhQR6lmpbLNrFUbMfnDNyFe5T1dKHELAkfebu6xmZ5N8712RRmBHHD18+y6jdD/5w4d8nK+r566feYVV2Ir+7fxMZCa41kcqK0nmvqYc22yy3wAPcSjCZWYOM1ETZHgBeQQsev5NSnhZCfFcIcZvzsC8JIU4LId4DvoQLlciQp2Y/JOZAcp4+759fCv1t0HZan/cPYapae1mUHENMhA9dNJP8a7UIvn5LMXWdAzx1pME/Rjr9K1vf52evVvMPf3ifsqJ0nvzsBubFTL+9KSvOAGD/bFsmva/PGXArJyOlfFFKWSilzJdS/sD52D9KKZ9z/v/rUsplUsqVUsrtUsop036klE9IKR/wr/lBgn0ULhzQLhS9SrXzVIuBt2iDqnzYKrnw77alaWzKS+EXr53DNuR6ILpHOP37yvNP8Yt957hrTRa/2rVmVtWEosx4FsyLYt9Mt7IDcX3OgKr49QdNxzRpWT2XognzIf0aFWQ8ZGjUTl3ngNdFeIBL/woh+MaHi+nsH+HXb9T6bOdwTDoXIxYT23iA+7fm8eO7rv2g63sGhBCUFWfw5rkOhkanqf4NxPU5AyrI+IOacm041eIt+p4nvxTqD2mzgxVuUdvej90hfauRmca/K7LmcfuqBTx2sJaWHu/bPvqGx/g/TxzlxYFiNoVX8/WyHLc7xQFKi9MZHLVTUTvNWJFAXZ/ToIKMP6gph4VrIdrFmEZ/kr9dG4bV8La+5wkhqlq1GhKfVjIz+PfvPrQUhwN+9mq1V2/d0TfMfY9WUFHbRfENtxPmGIF6z/y7KS+F6HDr9FumQF2f06CCjK8MdGmdrb4MMHKXnBvAGqmqfz2gqqWPcKtgcaprjadZmcW/2ckxfGpTDk8fb5zoj3KXxq4B7v7VIc612fh/n1rD5h23O/3r2ZY4KtzK5oJUys+6qP4dt9+grRKoIOM7Fw6AdATGieHRkHO9yst4QHWrjfy0OMLdyG+4xA3/PlC6hLjIMB55qdLttz3b0sud//42nX3D7PmLDZQWZfjk3x3F6VzsHuTs1YHuwhua/YH4EJwGFWR8pWYfRM6DBasDc778Umg7A73NgTmfyanyYlDVFbjh38SYCB4oXcL+qnbePj97V/TRui7u+dUhhICnP389a3ImdUTnl0J7pcf+3b40HXBR/VtTHtjr0wUqyPiClNrWJW8LWAM0ydToKfcmwjY0ysXuQe/zMR7491ObclmYGM3DL53F4Zi+3eC1M63seuwwqXGRPPNX10+1zUv/pidEsTJrHq9Nrv414vp0gQoyvtB5HnoaA7vfzVgGselqy+QG1a19AN7XyHjg36hwK393UyGnLvbw/EnXq5CnjzVy/+7jFGXG8/TnN5GVFDP1IB/8W1qUwbuN3XT0DXtsv56oIOMLRpRqC6Gdr1a1GMzGeM+S1ysZD/17+8qFXDM/gR+/UjVlNOav36jhq3tPcn1+Cv/9lxtJiZtGMcEH/5YVpyPlpOpfA1sJJqOCjC/UlGtl2km5gT1vfikMdELLycCe12RUtdiIibCyMDHauzfw0L8Wi1ag13R5kCcP1QOaauU/vVjJwy+d5dZr5/ObT68jNnKWrYuX/l22IIHMhKgP8jJGXZ9XoYKMt4yNwIU3jfmUyNum/au2TDMynvS1WLwopffSv5sLUtlamMa/lJ+ns2+Yr+49yaMHavn0phz++d7riAhz408ub5v2r4f+FUJQWpzOgep2hocHjbs+r0IFGW9pOgKj/cY4MT5DGw+ggsyMVLf60LPkg38fuqWI3qFRbvr5AZ450cTf3ljIt29b5n6w88G/ZUXp9I/YqTq6z7jr8ypUkPGWmnKwhEFuiTHnX1IKDRUw0m/M+YOcjr5hOvtHvB9U5YN/i+cncNfqLDr7R/jBHcv5UlmBR20CwAf+He7z6GU3LEklKtxCz6lXjL0+J6GCjLfUlEPWeoiaXVdZF/JLwTEKdW8Zc/4gZ7z61utBVT769wd3rKD8wW3s3JDj3fnH/VvvmX+jwq3ckJ9KWvtbyKx1xl2fk1BBxhv6OzUZWiOXotkbISxaKxZTTMEXnSV/+DcizOJ9KwNM8q/nW6YP54VTaK+lM9OPqgo+oKvukhBilRDikHOg1UkhxMf9/QMYQu1+QBobZMKjNDkNlZdxSXWrjeTYCFLjvJBAMbl/y6IqsQjJG2MrdDDMc/TWXRoAPiWlXAbcDPxcCGFMK6g/qdkPUYmwYJWxduSXQkc1dDfOfuwcQ9O9jvM8FwKm929i80FsIo7fNgVOwG0mdNVdklJWSynPOf/fDLQBJp0U7kRK7dMlbxtYZp5apjvjn7RKxeAKHA7JuVYbRZle5CPM7l+n/c3JGznW2EtX/4g+tnmArrpLkxFCrAcigBoXz5lHEqW9CmzNQXFrkLQiiJ+vtkxXcbF7kP4Ru3f5GLP712l/TPEOHBJer/JAYVIn9NZdAibUDJ4EPiOlnFIrbSpJlIlS7cBLS0xhogT9dXBcWcb+/HvN3PvoIewzNOuFKh+0E3ihTmAS/06L0/6Fqz9MWnwk+9zRZNIZvXWXEEIkAP8LfFNKWeGbuUFATTmkFEDiIqMt0cgvhcHLcOndiYeklPxi3zkqart4/2KPgcYZw/hMlQJvVjLB6t/md2c/FrS7jSkFWJJzKF2azoGqdkbGjO1x01V3yXn879H0lvb6x2QDGRuGuoOGDgCaQt52QFyxpK6o7eJ8m1bE9ea5IN9+6kB1q42FidEkRHmolGgS/07L6JBWN+Xc6pUVp2MbHvOvpK4X6K27dA+wBfjzSbe3DU7Z+0BDBYwNBsd+fZzYFJi/8or5I7sP1zMvOpylGfEcqJ59iFKoUeW8s+QxQe1fN4JMo9N+Z5DcXJBKRJjF8C2TrrpLUsrdUsrwSbe2V0kp3Vz3BSE1+8ASrs3aDSbyS6HxMAz10tY7xCvvt3DXmizKitM50XDZP7pAJmHU7qCmvc+7doJg9m/TERjqnfm4mvIr7I+JCOP6/BT2Vbb6T7fbC1TFryfUlMOijRDpg9ypHuSXgmMM6g7y26ONjDkkOzcsoqQgjTGHpKLW2OVyIKnr6GfULr1rJzCBf2fEhf1lRenUdQ5Q22Fcj5sKMu7S1wYtp4LjrsPVZK+H8FgcNeU8daSBG5akkJcWx+qcRGIirHMqL1PV6mU7gQn8O+OWaRr7S50ytvsmj+UMMCrIuEvt69q/wbRfHycsEnI3M1j5Ks09Q+xyNuVFhlnZmJfCm+fmTl6musWGRUB+moerERP4d8YgM439CxOjKcqMn1nGVmdUkHGXmnKITobMlUZb4pr8UmL76lgV182OazImHi4pSOVCRz+NXXNDdfJsi43c1NhZNaSnYAL/0lUDl+tcPz+D/TuKMzhWf5meAWNycyrIuMN4qXn+drAE56/sYspGAB7IabxCY6ikQCtunCurmepWm+f5GBP4d0YVg1nsLy1Ox+6QvF5tzGomSH+jQUbbGehrDc6ltJP/qo6gWaawWZy64vH8tFgWJkbPibzM4Iid+q4Bz/MxJvAvqQWQkOV6tEfr6RntX5WVSEpshGFbJhVk3CFIpr5Px9Cond8db6ImYQNRTW+CfWziOSEEJQWpvHW+gzF7aKsbnGuzIaUXEihB7l9AazFYUgq1B67wLzCr/RaLYHtROq9XtRlyDagg4w415ZBWDAkLjLbEJS+9f4nLA6OkrrwZhnqg+Z0rni8pSKN3aIz3mkK7xWB8UJXHEihB7t8J8kthuEfTtp6MG/bvKE6nd2iMY/WXdTZyKirIzMboINS/HdSfcrsrGshNiWHppj/DVQn6DUtSECL0WwyqW21EhFnISfFgIp0J/DvB4q1M8a+b9m8uSCPCapkqYxsAVJCZjfq3YWwoaC/Cyku9HK+/zM4NOVhik2Hh6in79sSYCK7NSgz55G9Vax8F6XFYPZFACXL/XkHMuH8nBZn6t8E+PKv9cZFhbMhLvlLGNkCoIDMbNeVgjYCc6422xCW7K+qJDLNw15os7YH8Umg6BoPdVxy3pSCVdxu76RkM3RaDqpZe7/IxQezfKVztXw/sLytKp7a9nwsBrv5VQWY2avbDok0Q4UK32GBsQ6P8/p2L3HrtApJinbNs80tB2qHuzSuOLSlIw+6QHKrpNMBS/ekeGKG1d9iLfEzw+tclV/vXA/vLDKr+VUFmJmwt0HY6aJfSf3jnIgMjdnZtnDT7JGsdRMRNyctctyiR2BBuMahu1UZbeNQYGeT+dclk/3pof3ZyDIUZcQHPy6ggMxPjhU9BeBFKKdld0cCyBQmsyp40m90aDou3TAky4VYLm/JTQzYvU9WidSh7tF0KYv9Oy7h/z+/z6tZ7WXEGRy500RvAznxdJVGcz31aCHHO+fVpfxqvOzXlEJsGGcuNtmQKx+ovU9VqY9fGnKkT+fNLtfLzrtorHt5amEpD1wD1naGnOlnVaiM+Koz586Lcf1EQ+3dG8kuhux6O/sZj+8uK0hlzSA5UB25Fq6skihAiGfgWsAFN9eBbQogkv1mvJw6HNiU+vzQoS813V9QTHxnG7atc1EZMlKBfuZoZbzE4EIKrmeqWPpZmxLsvgRLk/p2Rcf9ePOax/dctSiIpJjyg1b+6SqIANwGvSim7pJSX0YaM3+ydqVfhcGjDlfX6ajkJ/e1BuZTu6BvmpVMt3Lkmi5iIsKkHJOdBYg6cL7/iZ8pJiiQnKYKDVS36/u4C/CXtY5xr6WZpRkxI+HdWxv0LHttvtQi2L01nf1VbwIbMu7hCp+BKEmWDi+PuFEJsAaqBr0gpG6d5rSs5Fc9544fwxiN+easZydum/zk85HfHGhmxO9i5YZph1+NT7o8/Dt/9QOBLAG8AXAC+GwBDA4QA3gE46fzyhLxtfrYmAEz2b942j19eVpzBs+9c5ETDZdbl6i8A506QcYfngaeklMNCiPvRJFHcDrFCiM8BnwNYtMjNKfGLS/QX30rOg/hMfc/hIXaH5L8PN7BhcfLM0/hLHoR5C7UO3Umca7Xx3HvNfHx9NlmJJrltOwsXOvp59kQT96zLJjvJg58pCP3rNlu/Bkt2eGV/SWEqYRbBvsq2oAkybkmiTPr2MeBHk1677arXvn71CaSUjwKPAqxdu9a9NVzuZu1rjnGgup2my4P8/c1FMx+YmA1bvjrl4fTBUX75zp8Q0Uv4261LdbIysLx2oJZ/sVfymRtvhFgvtK/NSMICr3utEqLC2ZCXzL7KVh66ZZbryA/oKomCpnDwISFEkjPh+yHnYwov2V1RT2pcJDct8+4TeF50OKuyE0Mq+Xu2xUZafCTJcyXA+IHSogzOtfXR0Kn/MDNdJVGklF3A99AC1VHgu87HFF7QdHmA8qo2Pr4ui4gw7++IlBSkcbKpm+4B43WS/YFXg6rmOGVF6QDsO6t/9a+ukijO5/5DSrnE+fW4Pj/G3OCpIw0I4L71vqkbbilMxSHh7RBoMbA7JOfabN7pXs9hclNjyU+LDUj1r8kKBOYuI2MOfnu0kdKidLI8SW66YGVWIvFRYSHRYtDYNcDQqMPzxkgFZcUZVNR26q7LpYKMSXj5dAsdfSPs3Jjj83uFWS3ckJ/KgeoOQ0W//MG47rVXYm5znLKidEbtkoM65+dUkDEJuyvqyU6OZquzatdXSgpTudg9GPC2f39TPaGzFGSCbCZgTU4S86LDeU3n6l8VZExAdauNIxe6+MT6HCyeDGSagS3jLQYB7GHRg6pWG4uSY1xXPitmJMxqYdvSNF7XufpXBRkTsKeingirhXvWZvntPbOTY8hNiTF9V3ZVi0r6+kJpUTqd/SO829g9+8FeooJMkNM/PMazJy7y4RWZpMRF+vW9SwrSOFTbyciYOVUMhsfsXOjoV7evfWBbYTpWi6Bcx1vZKsgEOX98txnb8Bi7/JDwvZqSglQGRuycaAj8BHt/UNvej90hVdLXB+bFhLM2J0nXrmwVZIIYbTBVPUWZ8azJ8f+EjE35KVgtwrS3sseTvur2tW/sKM7gbIuNpsv6VP+aNsicb+vjyUN1RpuhK+80dnPmUi87XQ2m8gPxUeGsXmReFYOzLTbCLILFqR5IoCimUFqsVf/qVZhn2iDz3HvN/ONzpwPSe2EUuyvqiY2wcsd1/pmO4YqSgjROXeyhq998LQbVLTby0+J8arFQQH5aHItTY3XbMpnWO/etz8YiBHuO1Bttii5c7h/hhZOX+Oh1C4mL1O/27JbCNKSEt86bbzVT1WpT+Rg/UVqUzqGaTvqHx2Y/2ENMG2Tmz4tmR3E6Tx9rYmjUbrQ5fmfv8SZGxhy6JHwns2LhPOZFh5suL9M3PEbT5UGWqiI8v1BWnM6I3cFBHT5sTBtkAHZtzKGrf4SX3r9ktCl+xeGQ7D5cz9qcJIrnJ+h6LqtFsHmJpmJgphaDiaRvpr6/n7nCutxk4qPCKNdhy2TqIHNDfiq5KTHsrmgw2hS/cvB8B/WdA7qvYsYpKUjlUs8Q59v6AnI+f1Ddou4s+ZNwq4WthWnsO9uGw8/Vv36RRJl03J1CCCmEWOv8PlwI8Z9CiFNCiEohxNf9ZTiAxSLYuSGH4/WXqbzU68+3NpTdFfUkx0Zwy4rAjIbcXJAKmEvFoKrVRnS4laykaKNNCRnKitPp6Bvm1MUev76v3yRRhBDxwJeBw5MevhuIlFKuANYA9wshcn03+wPuWqMNcNpdERoJ4Es9g7xW2crda7OIDNN5hrGTrKQY8tJiTZWX0doJ4vzWy6XQqn8twv8ytv6URPke8ENgaNJjEogVQoQB0cAI4NclR1JsBLdeO58/vHORPh0y44HmqSONSGDn+sBslcbZUpBGRW0nw2PmSKJXt9o8171WzEhSbARrcpLY5+d6GXeCzKyyJkKI1UC2lPJ/r3rtXqAfuAQ0AD/RY/zmJzfm0D9i5/fvXJz94CBm1O7gf440sLUwjUUpgVUSKClIZWjUwfG64G8x6OgbpqNvRDVG6kBZcQanm3u51DPot/f0OfErhLAAPwUedPH0esAOLAAWAw8KIfJcvMfnhBDHhBDH2ts9X7Kvyk5k2YIE9lTUm+oOydW8eqaVNtswuzYEdhUDsDEvhXCrMEVeZiLpq1Yyfmd89q8/q3/dCTKzSaLEA8uB14UQdcBG4Dln8vcTwMtSylEpZRvwFrD26hNIKR+VUq6VUq5NS/N8KJMQgl0bczjbYuNYffB/Ek/H7op6FiZGs93p6EASGxnGmpwkU+RlqlpVkNGLJelxLEqO8Wv1r8+SKFLKHillqpQyV0qZC1QAt0kpj6FtkUoBhBCxaAHo7NUn8Ae3r1pAfGSYaRPANe19vF3TyX3rs7EalMwsKUjjdHMvHX3DhpzfXapbbSTFhJPm59EXCu0Du7QonbfOdzA44p/8nL8kUabjl0CcEOI0WrB6XErpqZCoW8REhPGx1Qt56VQLnUH+R+KKPRUNhFkE96zLnv1gnRiflhfsLQbjg6r0aBpVaF3Zw2MOv10HfpFEuerYbc5VDFLKPinl3U65lGuklD/2i9XTsHNjDiN2B7871qTnafzO4IidvccbuWl5JunxUYbZsWxBAkkx4bwRxCM5pZRUt/aprZKOrF+cTFxkmN/uMpm64vdqCjPi2bA4mf8+Uu/3qkU9ef5kM71DY3wyQBW+02GxCDYXpAV1i8HF7kH6hsdUkNGRiDALWwpTKT/b6pfrIKSCDGj9TI1dg7xhggTmOLsr6ilIj2PDYv3Fz2ejpCCVdtvwRHI12FCDqgLDR1YsYF1uMjY/1J6FXJC5aVkmqXGR7D5kjgTwyaZuTjb1sHPDoqDIMZQaLTIwAAAMxUlEQVQ4WwzerA7OvExVi9ZfVaCCjK585Nr5/OsnVpMQFe7ze4VckIkIs/DxdVmUV7XpNk7Qn+yuqCc63MrH1vhPicAX5s+LpiA9jgNBuhKsaullwbwo5kX7fvErAkPIBRn4QCv6qSPB3Z3dMzDKc+81c/uqBX75xPAXJQVpHLnQFZRzeqpa+9SgKpMRkkEmKymG0qXp/PZoY1DLfTxzoomhUf0HU3nKlsJUhsccHK3zeweIT4zZHdS09al8jMkIySADsGtTDh19I7xyusVoU1wipTaYalV2IssXzjPanCvYsDiFCKsl6AaM13X2M2J3qJ4lkxGyQWZrQRrZydFBWwF8qKaT2vb+oFvFAERHWFm3OCnoJGzHk77q9rW5CNkgY7EIPrE+h8MXujgXZLdjx+wO/umlSlLjIrn12vlGm+OSkoI0zrbYaOsdmv3gAFHVasMitP4ahXkI2SADcM/aLCKswTfQ6tE3a3n/Yi/fu30ZUeGBGUzlKRO3soNoy1TdYiM3JTZof2cK14R0kEmJi+SWFZk8e+KiLlIP3nC+zcbPXz3Hh1dkcsuK4FzFABRnJpAaFxFUXdlValCVKQnpIAPaQCvb8BjPvddstCnYHZKv7j1JbKSV79y23GhzZsTiVDE4eL4jKFo0hkbt1HX2q6SvCQn5ILMmJ4mizHh2B8FAq8ffusA7Dd18+7ZlpMUH/5iCkoI0OvpGqGwxfkj7+bY+pFRJXzMS8kFGCMHOjTmcbu7l3cZuw+yo6+jnJ3+qYkdxOretXGCYHZ4QTHmZs85peGolYz5CPsgA3HHdQmIjrIbpMzkckq89c5Jwq4Xvf3RFUPQouUN6QhRFmfFBkZepbrUREWYhN8CzjxW+o6vukvOxa4UQh4QQp536SwEfmBIXGcZHr1vI8yebuWyAsPyew/UcudDFP9x6DZnzjJsX4w1bCtM4euGy36akeUtVi40laXGEWefE52JIoavuklMKZTfweSnlMmAbMOoXyz1k18YcRsYc7D0e2IFWjV0DPPzSWUoKUrk7SJogPaGkIJURu4PDFzoNtUNJoJgXvXWXPgSclFK+ByCl7JRSGvKRWDw/gbU5Sew5HLiBVlJKvvH7Uwjg4Y+ZZ5s0mXW5yUSGGdti0DMwyqWeIRVkTIreukuFgBRCvCKEOCGE+JqrE/gqieIuuzbmUNc5wFs1gfmD+d2xRt4818FDHy4mK8mcuYSocCvrFycb2mJQ3aYGVZkZvXWXwoDNwE7nv3cIIcquPshXSRR3uWVFJsmxEQGpAG7pGeL7L1SyMS+Znc7RE2ZlS0Ea59r6/Cr45QlV43eW1ErGlOitu9QEHJBSdkgpB4AXgdX+MNwbIsOs3L02i9cq22jp0a8nR0rJN39/ilGHgx/eea3p9ZpLCo29lV3VYiM+MowFJkuaKzT01l16BVghhIhxJoG3Amf8/lN4wM71OTik1HWg1R/evci+s2189aYiclJidTtPoFiaEU9afKRxQabVRmGmkkAxK7rqLkkpL6NtpY4C7wInXORtAsqilBi2FKTx1JEGRu3+H2jVZhvi28+dYfWiRP78+ly/v78RCCEoKUjl4Ln2gLcYaBIoNlWEZ2J01V1yfr/bqbu0XErpMvEbaD65MYc22zCvnWn1+3t/64+nGRy186O7VhqmBKkHWwrSuDwwyunmwLYYtNuG6R4YZWmGGu9gVuZkZdP2onQWJkaz+7B/E8AvnrrES++38JUdhSE382Szs8Ug0APGx9sJlmYmBPS8Cv8xJ4OM1SK4b302b53vpLa9zy/v2dU/wj/84X1WLJzHX5Ys9st7BhOpcZEsW5AQ8BaDcZ2lQrWSMS1zMsgA3LMumzCLYM9h/ySAv/P8aXqHRvnx3deGbOl7SUEax+svB3Q2T1WLjdS4SFLigr9rXeGa0PxrcIP0+ChuWp7J3uNNPvflvHqmlT++28wD2wsoCuFl/ZaCVEbtkorawLUYaIOq1CrGzMzZIAOwa0MOPYOjPH/S+4FWPQOjfPP3pyjKjOevtuX70brgY01uElHhgWsxcDi0O0tLM0I3cM8F5nSQ2ZiXzJL0OPb4UAH8/f89Q2f/CD++ayURYaH964wMs7IxLyVgyd/GywMMjTrUSsbkhPZfxSwIIdi1YRHvNfVwqqnH49e/Ud3O08ebuH9LHiuygks7SS9KCtKobe8PiARwlRpUFRLM6SAD8LE1WUSHWz3uZ7INjfL1Z06yJD2OL5UV6GRd8LHFeSv7YAC2TCrIhAZzPsgkRIVz+6oF/PG9i/QMuj/q5pGXznKpd4gf3XXtnJLoWJIeR2ZCVEDyMlWtNrKTo4mNDNP9XAr9mPNBBrQREEOjDp494d5Aq7drOthzuIHP3rCY1YuSdLYuuBBCsKVQUzGw69xioCV91SrG7KggAyxfOI+V2YluKRoMjIzx0DOnyE2J4cEPLQ2QhcFFSUEaPYOjnLroeR7LXUbGHNS2KwmUUEAFGSef3JhDTXs/h2apAfnJK9U0dA3wwzuvJTpi7myTJnPDklSEgDd1HGRV29HHmEOqaXghgNrsOrn12vl874Uz7Klo4Pr8VJfHHKvr4vG3L/CpTTlsyEsJsIXBQ3JsBCsWzuOVMy0s1+mu2vG6y4DSWQoFVJBxEhVu5e41WTzxdh1tvUOkJ1w5IGlo1M7X9p5kwbxovnZzkUFWBg+lRen8/LVzfObxo7qdIzbCyuJU88/jmeu4FWSEEDcDvwCswGNSykemOe5OYC+wbvK4ByHEIrRhVd+WUv7EZ6t1YufGHB47eIHfHm3kr6+6Lf3z185R29HPk59dT5y628EXti1h+9J0HDqqcqYnRBEZNje3pKHErH8tkyRRbkQbp3lUCPGclPLMVcdNkUSZxE+Bl3w3V18Wp8ayeUkqTx1p4Avbl0zMg3mvsZtHD9Rw77psSgr0m0FsJiLCLKzMTjTaDIUJ0FsSBSHER4ELwGkfbQ0IuzYuorlniPKzbQAMj2nbpPT4KL7xkWKDrVMozIeukihCiDjg74Hv+GhnwNhRnEFGQiRPOiuAf7m/hqpWGz+4YzkJUeEGW6dQmA+9JVG+DfxMSjnjZKhA6S65Q5jVwn3rF3Ggup2X37/Ev+0/zx3XLaSsOMNQuxQKs6K3JMoG4EfOx/8G+IYQ4oGrTxAo3SV3uXfdIqwWwRf2nCAxJoJv/dkUVV6FQuEm7twmmZBEQQsu9wKfGH9SStkDTBSWCCFeB/7OeXepZNLj3wb6pJT/6hfLdSRzXhQ3Fmfw8ukWvv/RZSTGRBhtkkJhWmYNMlLKMefq4xW0W9j/MS6JAhxzpVgQCnzzI8XceE0GNy+fb7QpCoWpEbP16gSatWvXymPHjs1+oEKhCBqEEMellGtdPad6lxQKha6oIKNQKHRFBRmFQqErKsgoFApdUUFGoVDoigoyCoVCV4LuFrYQoh1wVzogFQiM0pg+KPuNRdnvP3KklC7L9YMuyHiCEOLYdPfmzYCy31iU/YFBbZcUCoWuqCCjUCh0xexB5lGjDfARZb+xKPsDgKlzMgqFIvgx+0pGoVAEOaYNMkKIm4UQVUKI80KIh4y2xxOEENlCiP1CiDNCiNNCiC8bbZM3CCGsQoh3hBAvGG2LpwghEoUQe4UQZ4UQlUKITUbb5AlCiK84r533hRBPCSGiZn+VMZgyyExSULgFuAa4TwhhpvF1Y8CDUspr0CYJftFk9o/zZaDSaCO85BfAy1LKImAlJvo5hBALgS8Ba6WUy9HmPN1rrFXTY8ogg/sKCkGJlPKSlPKE8/82tAt84cyvCi6EEFnAR4DHjLbFU4QQ84AtwG8ApJQjUspuY63ymDAgWggRBsQAzQbbMy1mDTKzKiiYBSFELnAdrvWqgpmfA18DHEYb4gWLgXbgced27zEhhGmkKqWUF4GfAA3AJaBHSvknY62aHrMGmZDAKRnzDPA3Uspeo+1xFyHErUCblPK40bZ4SRiwGvh3KeV1QD9gmryeECIJbeW+GFgAxAohdhlr1fSYNcjMpqAQ9AghwtECzB4p5bNG2+MhNwC3OVUo/gcoFULsNtYkj2gCmqSU46vHvWhBxyzsAC5IKdullKPAs8D1Bts0LWYNMhMKCkKICLSkl2kGmgshBFo+oFJK+VOj7fEUKeXXpZRZUspctN99uZQyaD9Jr0ZK2QI0CiGWOh8qQ9NqNwsNwEYhRIzzWiojiBPXplSOn05BwWCzPOEG4JPAKSHEu87HviGlfNFAm+Yafw3scX5I1QKfMdget5FSHhZC7AVOoN2pfIcgrv5VFb8KhUJXzLpdUigUJkEFGYVCoSsqyCgUCl1RQUahUOiKCjIKhUJXVJBRKBS6ooKMQqHQFRVkFAqFrvx/UmnhHhEHOzIAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.training.Model at 0x7fa18f2b6e80>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "train(model=model, data=((train_features, y_tran), (validation_features, y_val)), args=args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x_tran' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-174-e1d609945349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tran\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tran\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_tran' is not defined"
          ]
        }
      ],
      "source": [
        "train(model=model, data=((x_tran, y_tran), (x_val, y_val)), args=args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2706080d-2d50-4876-bd4d-c0f3c4ce87b5",
        "_uuid": "9afcde53f3cf3ba3eeeed1f083241874b4cd84e2",
        "id": "lMRMqKA9o8yS"
      },
      "source": [
        "# Show the results on the hold-out\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "56a6fe58-fe97-45c8-95da-223297842f79",
        "_uuid": "25ac7feb2d111b82e755169288ffd47ebc4d196a",
        "id": "PL8it8clo8yT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "e65e69e0-03f2-49bf-efbc-ec13927ec499"
      },
      "source": [
        "\n",
        "\n",
        "test(model=eval_model, data=(x_test, y_test), args=args)\n",
        "#test(model=model, data=(x_test[:100], y_test[:100]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (500, 28, 28, 1) for input Tensor(\"input_1:0\", shape=(500, 28, 28, 1), dtype=float32), but it was called on an input with incompatible shape (100, 28, 28, 1).\n",
            "------------------------------Begin: test------------------------------\n",
            "Test acc: 0.0875\n",
            "\n",
            "Reconstructed images are saved to ./result/real_and_recon.png\n",
            "------------------------------End: test------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"251.929058pt\" version=\"1.1\" viewBox=\"0 0 257.9275 251.929058\" width=\"257.9275pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 251.929058 \nL 257.9275 251.929058 \nL 257.9275 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 228.050933 \nL 250.7275 228.050933 \nL 250.7275 10.610933 \nL 33.2875 10.610933 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pbe78a7df50)\">\n    <image height=\"218\" id=\"imageb465b2224e\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"33.2875\" xlink:href=\"data:image/png;base64,\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\" y=\"-10.050933\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m83a7fbefce\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.675786\" xlink:href=\"#m83a7fbefce\" y=\"228.050933\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(30.494536 242.649371)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"72.504357\" xlink:href=\"#m83a7fbefce\" y=\"228.050933\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(66.141857 242.649371)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"111.332929\" xlink:href=\"#m83a7fbefce\" y=\"228.050933\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(101.789179 242.649371)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"150.1615\" xlink:href=\"#m83a7fbefce\" y=\"228.050933\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g transform=\"translate(140.61775 242.649371)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"188.990071\" xlink:href=\"#m83a7fbefce\" y=\"228.050933\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(179.446321 242.649371)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"227.818643\" xlink:href=\"#m83a7fbefce\" y=\"228.050933\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 250 -->\n      <g transform=\"translate(218.274893 242.649371)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"md547ed1201\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md547ed1201\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(19.925 14.798438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md547ed1201\" y=\"49.82779\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 50 -->\n      <g transform=\"translate(13.5625 53.627009)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md547ed1201\" y=\"88.656362\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 92.45558)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md547ed1201\" y=\"127.484933\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 150 -->\n      <g transform=\"translate(7.2 131.284152)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md547ed1201\" y=\"166.313504\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 200 -->\n      <g transform=\"translate(7.2 170.112723)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md547ed1201\" y=\"205.142076\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 250 -->\n      <g transform=\"translate(7.2 208.941295)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.2875 228.050933 \nL 33.2875 10.610933 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 250.7275 228.050933 \nL 250.7275 10.610933 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.2875 228.050933 \nL 250.7275 228.050933 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.2875 10.610933 \nL 250.7275 10.610933 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pbe78a7df50\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"33.2875\" y=\"10.610933\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiBpPdkmY500"
      },
      "source": [
        "# pick some collabs stuff "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.compat.v1.losses import sparse_softmax_cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_29\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nefficientnetb3 (Model)       (None, 7, 8, 1536)        10783535  \n_________________________________________________________________\nglobal_average_pooling2d_16  (None, 1536)              0         \n_________________________________________________________________\ndropout_16 (Dropout)         (None, 1536)              0         \n_________________________________________________________________\ndense_32 (Dense)             (None, 5)                 7685      \n_________________________________________________________________\ndense_33 (Dense)             (None, 2)                 12        \n=================================================================\nTotal params: 10,791,232\nTrainable params: 10,703,929\nNon-trainable params: 87,303\n_________________________________________________________________\nNone\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from tensorflow.python.keras.applications.efficientnet import EfficientNetB3\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D,BatchNormalization,MaxPool2D,GlobalMaxPool2D, TimeDistributed, GRU, Dense, Dropout\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def get_logits(labels, y_pred):\n",
        "    s = 64.\n",
        "    cos_t = y_pred\n",
        "    sin_m = tf.math.sin(0.5)\n",
        "    cos_m = tf.math.cos(0.5)\n",
        "    mm = sin_m * 0.5  \n",
        "    cos_t2 = tf.square(cos_t, name='cos_2')\n",
        "    sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n",
        "    sin_t = tf.sqrt(sin_t2, name='sin_t')\n",
        "    cos_mt = s * tf.subtract(tf.multiply(cos_t, cos_m), tf.multiply(sin_t, sin_m), name='cos_mt')\n",
        "    threshold = math.cos(math.pi - 0.5)\n",
        "    cond_v = cos_t - threshold\n",
        "    cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n",
        "    keep_val = s*(cos_t - mm)\n",
        "    cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n",
        "    mask = tf.one_hot(labels, depth=2, name='one_hot_mask')\n",
        "    inv_mask = tf.subtract(1., mask, name='inverse_mask')\n",
        "    s_cos_t = tf.multiply(s, cos_t, name='scalar_cos_t')\n",
        "    output = tf.add(tf.multiply(s_cos_t, inv_mask), tf.multiply(cos_mt_temp, mask), name='arcface_logits')\n",
        "    return output\n",
        "def loss(y_true, y_pred):\n",
        "    labels = K.argmax(y_true, axis=-1)\n",
        "    logits = get_logits(labels, y_pred)\n",
        "    loss = sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "    return loss\n",
        "effnet = EfficientNetB3(weights = \"imagenet\", include_top = False, input_shape=(224,244,3), pooling = None, classes = 2)\n",
        "model = Sequential()\n",
        "model.add(effnet)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(2, activation=\"softmax\"))\n",
        "model.compile(loss=loss,\n",
        "                      optimizer=Adam(lr=0.001), \n",
        "                  metrics=['acc'])\n",
        "print(model.summary())\n",
        "\n",
        "# Initialize model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cnn_effnet(shape=(112, 112, 3)):\n",
        "    #model = EfficientNetB3(weights = \"imagenet\", include_top = False, input_shape=shape, pooling = None, classes = 2)\n",
        "    model = Sequential()\n",
        "    #model.add(effnet)\n",
        "    momentum = .9\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3,3), input_shape=shape,\n",
        "        padding='same', activation='relu'))\n",
        "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    model.add(MaxPool2D())\n",
        "    \n",
        "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    model.add(MaxPool2D())\n",
        "    \n",
        "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    model.add(MaxPool2D())\n",
        "    \n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # flatten...\n",
        "    model.add(GlobalMaxPool2D())\n",
        "    model.compile(loss=loss,\n",
        "                        optimizer=Adam(lr=0.001), \n",
        "                    metrics=['acc'])\n",
        "    print(model.summary())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_28\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_28 (Conv2D)           (None, 112, 112, 64)      1792      \n_________________________________________________________________\nconv2d_29 (Conv2D)           (None, 112, 112, 64)      36928     \n_________________________________________________________________\nbatch_normalization_13 (Batc (None, 112, 112, 64)      256       \n_________________________________________________________________\nmax_pooling2d_9 (MaxPooling2 (None, 56, 56, 64)        0         \n_________________________________________________________________\nconv2d_30 (Conv2D)           (None, 56, 56, 128)       73856     \n_________________________________________________________________\nconv2d_31 (Conv2D)           (None, 56, 56, 128)       147584    \n_________________________________________________________________\nbatch_normalization_14 (Batc (None, 56, 56, 128)       512       \n_________________________________________________________________\nmax_pooling2d_10 (MaxPooling (None, 28, 28, 128)       0         \n_________________________________________________________________\nconv2d_32 (Conv2D)           (None, 28, 28, 256)       295168    \n_________________________________________________________________\nconv2d_33 (Conv2D)           (None, 28, 28, 256)       590080    \n_________________________________________________________________\nbatch_normalization_15 (Batc (None, 28, 28, 256)       1024      \n_________________________________________________________________\nmax_pooling2d_11 (MaxPooling (None, 14, 14, 256)       0         \n_________________________________________________________________\nconv2d_34 (Conv2D)           (None, 14, 14, 512)       1180160   \n_________________________________________________________________\nconv2d_35 (Conv2D)           (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nbatch_normalization_16 (Batc (None, 14, 14, 512)       2048      \n_________________________________________________________________\nglobal_max_pooling2d_2 (Glob (None, 512)               0         \n=================================================================\nTotal params: 4,689,216\nTrainable params: 4,687,296\nNon-trainable params: 1,920\n_________________________________________________________________\nNone\n"
          ]
        }
      ],
      "source": [
        "model = cnn_effnet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "def action_model(shape=(1, 112, 112, 3), nbout=2):\n",
        "    # Create our convnet with (112, 112, 3) input shape\n",
        "    convnet = cnn_effnet(shape[1:])\n",
        "    \n",
        "    # then create our final model\n",
        "    model = Sequential()\n",
        "    # add the convnet with (5, 112, 112, 3) shape\n",
        "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
        "    # here, you can also use GRU or LSTM\n",
        "    model.add(GRU(64))\n",
        "    # and finally, we make a decision network\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(nbout, activation='softmax'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_40\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_60 (Conv2D)           (None, 112, 112, 64)      1792      \n_________________________________________________________________\nconv2d_61 (Conv2D)           (None, 112, 112, 64)      36928     \n_________________________________________________________________\nbatch_normalization_29 (Batc (None, 112, 112, 64)      256       \n_________________________________________________________________\nmax_pooling2d_21 (MaxPooling (None, 56, 56, 64)        0         \n_________________________________________________________________\nconv2d_62 (Conv2D)           (None, 56, 56, 128)       73856     \n_________________________________________________________________\nconv2d_63 (Conv2D)           (None, 56, 56, 128)       147584    \n_________________________________________________________________\nbatch_normalization_30 (Batc (None, 56, 56, 128)       512       \n_________________________________________________________________\nmax_pooling2d_22 (MaxPooling (None, 28, 28, 128)       0         \n_________________________________________________________________\nconv2d_64 (Conv2D)           (None, 28, 28, 256)       295168    \n_________________________________________________________________\nconv2d_65 (Conv2D)           (None, 28, 28, 256)       590080    \n_________________________________________________________________\nbatch_normalization_31 (Batc (None, 28, 28, 256)       1024      \n_________________________________________________________________\nmax_pooling2d_23 (MaxPooling (None, 14, 14, 256)       0         \n_________________________________________________________________\nconv2d_66 (Conv2D)           (None, 14, 14, 512)       1180160   \n_________________________________________________________________\nconv2d_67 (Conv2D)           (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nbatch_normalization_32 (Batc (None, 14, 14, 512)       2048      \n_________________________________________________________________\nglobal_max_pooling2d_6 (Glob (None, 512)               0         \n=================================================================\nTotal params: 4,689,216\nTrainable params: 4,687,296\nNon-trainable params: 1,920\n_________________________________________________________________\nNone\n"
          ]
        }
      ],
      "source": [
        "#INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) # (5, 112, 112, 3)\n",
        "INSHAPE = (1, 112, 112, 3)\n",
        "model = action_model(INSHAPE, )\n",
        "optimizer = Adam(0.001)\n",
        "model.compile(\n",
        "    optimizer,\n",
        "    'categorical_crossentropy',\n",
        "    metrics=['acc']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-77d6c5a8c1a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit_generator(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ],
      "source": [
        "model.fit_generator(\n",
        "    train,\n",
        "    validation_data=valid,\n",
        "    verbose=1,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        y_pred = self(x, training=True)\n    /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:885 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_41 is incompatible with the layer: expected ndim=5, found ndim=4. Full shape received: [None, None, None, None]\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-e09a7109e1d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit(train_gen, steps_per_epoch=train_steps, \n\u001b[0m\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     epochs=20, verbose=1)\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 505\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    506\u001b[0m             *args, **kwds))\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2657\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        y_pred = self(x, training=True)\n    /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:885 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_41 is incompatible with the layer: expected ndim=5, found ndim=4. Full shape received: [None, None, None, None]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize model\n",
        "model.fit(train_gen, steps_per_epoch=train_steps, \n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=val_steps,\n",
        "                    epochs=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'videos' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-96bd0afc3969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'FileName'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ClassName'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mvideo_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FileName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'videos' is not defined"
          ]
        }
      ],
      "source": [
        "data = {'FileName':[],'Label':[],'ClassName':[]}\n",
        "for video_name in videos:\n",
        "    for frames in frames_list:\n",
        "        data['FileName'].append(os.path.join(dataset_path,frames))\n",
        "        data['Label'].append(dict_of_labels[video_name])\n",
        "        data['ClassName'].append(emotions)\n",
        "data_frame = pd.DataFrame(data)\n",
        "path = 'path to the corresponding folders'+d_type+'/{}_{}.csv'.format(video_name,frame_name)\n",
        "data_frame.to_csv(filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filegenerator(CSV_folder,temporal_length,temporal_stride):\n",
        "    for file in CSV_folder:\n",
        "        data = pd.read_csv('path to each .csv file')\n",
        "        labels = list(data.Label)\n",
        "        img_list = list(data.FileName)\n",
        "        samples = deque()\n",
        "        sample_count = 0\n",
        "    for img in img_list:\n",
        "        samples.append(img)\n",
        "        if len(samples)== temporal_length: \n",
        "            samples_c = copy.deepcopy(samples)\n",
        "            samp_count += 1\n",
        "            for i in range(temporal_stride):\n",
        "                samples.popleft() \n",
        "            yield samples_c,labels[0]\n",
        "            samples.popleft()\n",
        "\n",
        "##Function to create the files structured based on the temporal requirements.:\n",
        "def seq_of_frames(folder,d_type,length,stride):\n",
        "    for csv_file in os.listdir(folder+'/'+d_type):\n",
        "        file_gen = filegenerator(csv_file,temporal_length,temporal_stride)\n",
        "        iterator = True\n",
        "        data_list = []\n",
        "        while iterator:\n",
        "            try:\n",
        "                X,y = next(file_gen)\n",
        "                X = list(X) \n",
        "                data_list.append([X,y])\n",
        "            except Exception as e:\n",
        "                print(\"An exception has occured:\",e)\n",
        "                iterator = False\n",
        "    return data_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'path to folder containing .csv files/Train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-4ecac9b5eee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_of_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path to folder containing .csv files'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mseq_of_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path to folder containing .csv files'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Validation'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-109-989a958c6cf7>\u001b[0m in \u001b[0;36mseq_of_frames\u001b[0;34m(folder, d_type, length, stride)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m##Function to create the files structured based on the temporal requirements.:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mseq_of_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mcsv_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0md_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mfile_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilegenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemporal_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemporal_stride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path to folder containing .csv files/Train'"
          ]
        }
      ],
      "source": [
        "training_data = seq_of_frames('path to folder containing .csv files','Train',5,2)\n",
        "validation_data= seq_of_frames('path to folder containing .csv files','Validation',5,2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data_utils' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-c2180cd14c11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_autoencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Initializing the values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_utils' is not defined"
          ]
        }
      ],
      "source": [
        "class DataGenerator(data_utils.Sequence):\n",
        "    def __init__(self,data,batch_size,dim,n_classes,is_autoencoder,shuffle):\n",
        "#Initializing the values\n",
        "        self.dim = dim\n",
        "        self.data  = data\n",
        "        self.batch_size = batch_size\n",
        "        self.list_IDs = np.arange(len(data))\n",
        "        self.n_classes = n_classes\n",
        "        self.is_autoencoder = is_autoencoder\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def on_epoch_end(self): \n",
        "    self.indexes = self.list_IDs  #Load the indexes of the data\n",
        "    if self.shuffle == True:\n",
        "        np.random.shuffle(self.indexes)\n",
        "def __len__(self): \n",
        "    return int(np.floor(len(self.data)/self.batch_size))\n",
        "def __getitem__(self, index):\n",
        " #Generate batch at position 'index' \n",
        "    index = self.indexes[index*self.batch_size\n",
        "    :(index+1)*self.batch_size]\n",
        "    #Generate a temporary list of indexes that forms a batch based on  ##the index selected above.\n",
        "    list_IDs_temp = [self.list_IDs[k] for k in index]\n",
        "    #Generate batch\n",
        "    X,y = self.__data_generation(list_IDs_temp)\n",
        "        return X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "def on_epoch_end(self): \n",
        "    self.indexes = self.list_IDs  \n",
        "    if self.shuffle == True:\n",
        "        np.random.shuffle(self.indexes)\n",
        "def __len__(self): \n",
        "    return int(np.floor(len(self.data)/self.batch_size))\n",
        "def __getitem__(self, index):\n",
        "    index = self.indexes[index*self.batch_size\n",
        "    :(index+1)*self.batch_size]\n",
        "    #Generate a temporary list of indexes that forms a batch based on  ##the index selected above.\n",
        "    list_IDs_temp = [self.list_IDs[k] for k in index]\n",
        "    #Generate batch\n",
        "    X,y = self.__data_generation(list_IDs_temp)\n",
        "    return X,y\n",
        "def __data_generation(self,list_IDs_temp):\n",
        "    X_data = []\n",
        "    y_data = []\n",
        "    for i,_ in enumerate(list_IDs_temp): #Iterating through each #\n",
        "        seq_frames = self.data.iloc[i,0]\n",
        "        y = self.data.iloc[i,1]\n",
        "        temp_data_list = []\n",
        "        for img in seq_frames:\n",
        "            try:\n",
        "                image = cv2.imread(img,0)\n",
        "                ext_img = cv2.resize(image,self.dim)\n",
        "            except Exception as e: \n",
        "                temp_data_list.append(ext_img)\n",
        "        X_data.append(temp_data_list)\n",
        "        y_data.append(y)\n",
        "    X = np.array(X_data) \n",
        "    y = np.array(y_data)\n",
        "    if self.is_autoencoder == True:\n",
        "        return X, X\n",
        "    else:\n",
        "        return X, keras.utils.to_categorical(y,num_classes=self.n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-9f7e2be14360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-128-9f7e2be14360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m~/.vscode/extensions/ms-python.python-2021.2.576481509/pythonFiles/lib/python/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads_suspended_single_notification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_thread_suspended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m                 \u001b[0mkeep_suspended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \u001b[0mframes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.vscode/extensions/ms-python.python-2021.2.576481509/pythonFiles/lib/python/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36m_do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   1888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_current_thread_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(train_gen,epochs,validation_data=valid_gen,use_multiprocessing=True,workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "import numpy as np\n",
        "\n",
        "class Extractor():\n",
        "    def __init__(self, weights=None):\n",
        "        \"\"\"Either load pretrained from imagenet, or load our saved\n",
        "        weights from our own training.\"\"\"\n",
        "\n",
        "        self.weights = weights  # so we can check elsewhere which model\n",
        "\n",
        "        if weights is None:\n",
        "            # Get model with pretrained weights.\n",
        "            base_model = InceptionV3(\n",
        "                weights='imagenet',\n",
        "                include_top=True\n",
        "            )\n",
        "\n",
        "            # We'll extract features at the final pool layer.\n",
        "            self.model = Model(\n",
        "                inputs=base_model.input,\n",
        "                outputs=base_model.get_layer('avg_pool').output\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            # Load the model first.\n",
        "            self.model = load_model(weights)\n",
        "\n",
        "            # Then remove the top so we get features not predictions.\n",
        "            # From: https://github.com/fchollet/keras/issues/2371\n",
        "            self.model.layers.pop()\n",
        "            self.model.layers.pop()  # two pops to get to pool layer\n",
        "            self.model.outputs = [self.model.layers[-1].output]\n",
        "            self.model.output_layers = [self.model.layers[-1]]\n",
        "            self.model.layers[-1].outbound_nodes = []\n",
        "\n",
        "    def extract(self, image_path):\n",
        "        img = image.load_img(image_path, target_size=(299, 299))\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = preprocess_input(x)\n",
        "\n",
        "        # Get the prediction.\n",
        "        features = self.model.predict(x)\n",
        "\n",
        "        if self.weights is None:\n",
        "            # For imagenet/default network:\n",
        "            features = features[0]\n",
        "        else:\n",
        "            # For loaded network:\n",
        "            features = features[0]\n",
        "\n",
        "        return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Class for managing our data.\n",
        "\"\"\"\n",
        "import csv\n",
        "import numpy as np\n",
        "import random\n",
        "import glob\n",
        "import os.path\n",
        "import sys\n",
        "import operator\n",
        "import threading\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "class threadsafe_iterator:\n",
        "    def __init__(self, iterator):\n",
        "        self.iterator = iterator\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        with self.lock:\n",
        "            return next(self.iterator)\n",
        "\n",
        "def threadsafe_generator(func):\n",
        "    \"\"\"Decorator\"\"\"\n",
        "    def gen(*a, **kw):\n",
        "        return threadsafe_iterator(func(*a, **kw))\n",
        "    return gen\n",
        "\n",
        "class DataSet():\n",
        "\n",
        "    def __init__(self, seq_length=40, class_limit=None, image_shape=(224, 224, 3)):\n",
        "        \"\"\"Constructor.\n",
        "        seq_length = (int) the number of frames to consider\n",
        "        class_limit = (int) number of classes to limit the data to.\n",
        "            None = no limit.\n",
        "        \"\"\"\n",
        "        self.seq_length = seq_length\n",
        "        self.class_limit = class_limit\n",
        "        self.sequence_path = os.path.join('data', 'sequences')\n",
        "        self.max_frames = 300  # max number of frames a video can have for us to use it\n",
        "\n",
        "        # Get the data.\n",
        "        self.data = self.get_data()\n",
        "\n",
        "        # Get the classes.\n",
        "        self.classes = self.get_classes()\n",
        "\n",
        "        # Now do some minor data cleaning.\n",
        "        self.data = self.clean_data()\n",
        "\n",
        "        self.image_shape = image_shape\n",
        "\n",
        "    @staticmethod\n",
        "    def get_data():\n",
        "        \"\"\"Load our data from file.\"\"\"\n",
        "        with open(os.path.join('data', 'data_file.csv'), 'r') as fin:\n",
        "            reader = csv.reader(fin)\n",
        "            data = list(reader)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def clean_data(self):\n",
        "        \"\"\"Limit samples to greater than the sequence length and fewer\n",
        "        than N frames. Also limit it to classes we want to use.\"\"\"\n",
        "        data_clean = []\n",
        "        for item in self.data:\n",
        "            if int(item[3]) >= self.seq_length and int(item[3]) <= self.max_frames \\\n",
        "                    and item[1] in self.classes:\n",
        "                data_clean.append(item)\n",
        "\n",
        "        return data_clean\n",
        "\n",
        "    def get_classes(self):\n",
        "        \"\"\"Extract the classes from our data. If we want to limit them,\n",
        "        only return the classes we need.\"\"\"\n",
        "        classes = []\n",
        "        for item in self.data:\n",
        "            if item[1] not in classes:\n",
        "                classes.append(item[1])\n",
        "\n",
        "        # Sort them.\n",
        "        classes = sorted(classes)\n",
        "\n",
        "        # Return.\n",
        "        if self.class_limit is not None:\n",
        "            return classes[:self.class_limit]\n",
        "        else:\n",
        "            return classes\n",
        "\n",
        "    def get_class_one_hot(self, class_str):\n",
        "        \"\"\"Given a class as a string, return its number in the classes\n",
        "        list. This lets us encode and one-hot it for training.\"\"\"\n",
        "        # Encode it first.\n",
        "        label_encoded = self.classes.index(class_str)\n",
        "\n",
        "        # Now one-hot it.\n",
        "        label_hot = to_categorical(label_encoded, len(self.classes))\n",
        "\n",
        "        assert len(label_hot) == len(self.classes)\n",
        "\n",
        "        return label_hot\n",
        "\n",
        "    def split_train_test(self):\n",
        "        \"\"\"Split the data into train and test groups.\"\"\"\n",
        "        train = []\n",
        "        test = []\n",
        "        for item in self.data:\n",
        "            if item[0] == 'train':\n",
        "                train.append(item)\n",
        "            else:\n",
        "                test.append(item)\n",
        "        return train, test\n",
        "\n",
        "    def get_all_sequences_in_memory(self, train_test, data_type):\n",
        "        \"\"\"\n",
        "        This is a mirror of our generator, but attempts to load everything into\n",
        "        memory so we can train way faster.\n",
        "        \"\"\"\n",
        "        # Get the right dataset.\n",
        "        train, test = self.split_train_test()\n",
        "        data = train if train_test == 'train' else test\n",
        "\n",
        "        print(\"Loading %d samples into memory for %sing.\" % (len(data), train_test))\n",
        "\n",
        "        X, y = [], []\n",
        "        for row in data:\n",
        "\n",
        "            if data_type == 'images':\n",
        "                frames = self.get_frames_for_sample(row)\n",
        "                frames = self.rescale_list(frames, self.seq_length)\n",
        "\n",
        "                # Build the image sequence\n",
        "                sequence = self.build_image_sequence(frames)\n",
        "\n",
        "            else:\n",
        "                sequence = self.get_extracted_sequence(data_type, row)\n",
        "\n",
        "                if sequence is None:\n",
        "                    print(\"Can't find sequence. Did you generate them?\")\n",
        "                    raise\n",
        "\n",
        "            X.append(sequence)\n",
        "            y.append(self.get_class_one_hot(row[1]))\n",
        "\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    @threadsafe_generator\n",
        "    def frame_generator(self, batch_size, train_test, data_type):\n",
        "        \"\"\"Return a generator that we can use to train on. There are\n",
        "        a couple different things we can return:\n",
        "\n",
        "        data_type: 'features', 'images'\n",
        "        \"\"\"\n",
        "        # Get the right dataset for the generator.\n",
        "        train, test = self.split_train_test()\n",
        "        data = train if train_test == 'train' else test\n",
        "\n",
        "        print(\"Creating %s generator with %d samples.\" % (train_test, len(data)))\n",
        "\n",
        "        while 1:\n",
        "            X, y = [], []\n",
        "\n",
        "            # Generate batch_size samples.\n",
        "            for _ in range(batch_size):\n",
        "                # Reset to be safe.\n",
        "                sequence = None\n",
        "\n",
        "                # Get a random sample.\n",
        "                sample = random.choice(data)\n",
        "\n",
        "                # Check to see if we've already saved this sequence.\n",
        "                if data_type is \"images\":\n",
        "                    # Get and resample frames.\n",
        "                    frames = self.get_frames_for_sample(sample)\n",
        "                    frames = self.rescale_list(frames, self.seq_length)\n",
        "\n",
        "                    # Build the image sequence\n",
        "                    sequence = self.build_image_sequence(frames)\n",
        "                else:\n",
        "                    # Get the sequence from disk.\n",
        "                    sequence = self.get_extracted_sequence(data_type, sample)\n",
        "\n",
        "                    if sequence is None:\n",
        "                        raise ValueError(\"Can't find sequence. Did you generate them?\")\n",
        "\n",
        "                X.append(sequence)\n",
        "                y.append(self.get_class_one_hot(sample[1]))\n",
        "\n",
        "            yield np.array(X), np.array(y)\n",
        "\n",
        "    def build_image_sequence(self, frames):\n",
        "        \"\"\"Given a set of frames (filenames), build our sequence.\"\"\"\n",
        "        return [process_image(x, self.image_shape) for x in frames]\n",
        "\n",
        "    def get_extracted_sequence(self, data_type, sample):\n",
        "        \"\"\"Get the saved extracted features.\"\"\"\n",
        "        filename = sample[2]\n",
        "        path = os.path.join(self.sequence_path, filename + '-' + str(self.seq_length) + \\\n",
        "            '-' + data_type + '.npy')\n",
        "        if os.path.isfile(path):\n",
        "            return np.load(path)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def get_frames_by_filename(self, filename, data_type):\n",
        "        \"\"\"Given a filename for one of our samples, return the data\n",
        "        the model needs to make predictions.\"\"\"\n",
        "        # First, find the sample row.\n",
        "        sample = None\n",
        "        for row in self.data:\n",
        "            if row[2] == filename:\n",
        "                sample = row\n",
        "                break\n",
        "        if sample is None:\n",
        "            raise ValueError(\"Couldn't find sample: %s\" % filename)\n",
        "\n",
        "        if data_type == \"images\":\n",
        "            # Get and resample frames.\n",
        "            frames = self.get_frames_for_sample(sample)\n",
        "            frames = self.rescale_list(frames, self.seq_length)\n",
        "            # Build the image sequence\n",
        "            sequence = self.build_image_sequence(frames)\n",
        "        else:\n",
        "            # Get the sequence from disk.\n",
        "            sequence = self.get_extracted_sequence(data_type, sample)\n",
        "\n",
        "            if sequence is None:\n",
        "                raise ValueError(\"Can't find sequence. Did you generate them?\")\n",
        "\n",
        "        return sequence\n",
        "\n",
        "    @staticmethod\n",
        "    def get_frames_for_sample(sample):\n",
        "        \"\"\"Given a sample row from the data file, get all the corresponding frame\n",
        "        filenames.\"\"\"\n",
        "        path = os.path.join('data', sample[0], sample[1])\n",
        "        filename = sample[2]\n",
        "        images = sorted(glob.glob(os.path.join(path, filename + '*jpg')))\n",
        "        return images\n",
        "\n",
        "    @staticmethod\n",
        "    def get_filename_from_image(filename):\n",
        "        parts = filename.split(os.path.sep)\n",
        "        return parts[-1].replace('.jpg', '')\n",
        "\n",
        "    @staticmethod\n",
        "    def rescale_list(input_list, size):\n",
        "        \"\"\"Given a list and a size, return a rescaled/samples list. For example,\n",
        "        if we want a list of size 5 and we have a list of size 25, return a new\n",
        "        list of size five which is every 5th element of the origina list.\"\"\"\n",
        "        assert len(input_list) >= size\n",
        "\n",
        "        # Get the number to skip between iterations.\n",
        "        skip = len(input_list) // size\n",
        "\n",
        "        # Build our new output.\n",
        "        output = [input_list[i] for i in range(0, len(input_list), skip)]\n",
        "\n",
        "        # Cut off the last one if needed.\n",
        "        return output[:size]\n",
        "\n",
        "    def print_class_from_prediction(self, predictions, nb_to_return=5):\n",
        "        \"\"\"Given a prediction, print the top classes.\"\"\"\n",
        "        # Get the prediction for each label.\n",
        "        label_predictions = {}\n",
        "        for i, label in enumerate(self.classes):\n",
        "            label_predictions[label] = predictions[i]\n",
        "\n",
        "        # Now sort them.\n",
        "        sorted_lps = sorted(\n",
        "            label_predictions.items(),\n",
        "            key=operator.itemgetter(1),\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        # And return the top N.\n",
        "        for i, class_prediction in enumerate(sorted_lps):\n",
        "            if i > nb_to_return - 1 or class_prediction[1] == 0.0:\n",
        "                break\n",
        "            print(\"%s: %.2f\" % (class_prediction[0], class_prediction[1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Process an image that we can pass to our networks.\n",
        "\"\"\"\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np\n",
        "\n",
        "def process_image(image, target_shape):\n",
        "    \"\"\"Given an image, process it and return the array.\"\"\"\n",
        "    # Load the image.\n",
        "    h, w, _ = target_shape\n",
        "    image = load_img(image, target_size=(h, w))\n",
        "\n",
        "    # Turn it into numpy, normalize and return.\n",
        "    img_arr = img_to_array(image)\n",
        "    x = (img_arr / 255.).astype(np.float32)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/data_file.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-5096fed26b95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Get the dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# get the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-133-f7c057893696>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, seq_length, class_limit, image_shape)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Get the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Get the classes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-133-f7c057893696>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;34m\"\"\"Load our data from file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_file.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/data_file.csv'"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This script generates extracted features for each video, which other\n",
        "models make use of.\n",
        "\n",
        "You can change you sequence length and limit to a set number of classes\n",
        "below.\n",
        "\n",
        "class_limit is an integer that denotes the first N classes you want to\n",
        "extract features from. This is useful is you don't want to wait to\n",
        "extract all 101 classes. For instance, set class_limit = 8 to just\n",
        "extract features for the first 8 (alphabetical) classes in the dataset.\n",
        "Then set the same number when training models.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import os.path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set defaults.\n",
        "seq_length = 40\n",
        "class_limit = None  # Number of classes to extract. Can be 1-101 or None for all.\n",
        "\n",
        "# Get the dataset.\n",
        "data = DataSet(seq_length=seq_length, class_limit=class_limit)\n",
        "\n",
        "# get the model.\n",
        "model = Extractor()\n",
        "\n",
        "# Loop through data.\n",
        "pbar = tqdm(total=len(data.data))\n",
        "for video in data.data:\n",
        "\n",
        "    # Get the path to the sequence for this video.\n",
        "    path = os.path.join('data', 'sequences', video[2] + '-' + str(seq_length) + \\\n",
        "        '-features')  # numpy will auto-append .npy\n",
        "\n",
        "    # Check if we already have it.\n",
        "    if os.path.isfile(path + '.npy'):\n",
        "        pbar.update(1)\n",
        "        continue\n",
        "\n",
        "    # Get the frames for this video.\n",
        "    frames = data.get_frames_for_sample(video)\n",
        "\n",
        "    # Now downsample to just the ones we need.\n",
        "    frames = data.rescale_list(frames, seq_length)\n",
        "\n",
        "    # Now loop through and extract features to build the sequence.\n",
        "    sequence = []\n",
        "    for image in frames:\n",
        "        features = model.extract(image)\n",
        "        sequence.append(features)\n",
        "\n",
        "    # Save the sequence.\n",
        "    np.save(path, sequence)\n",
        "\n",
        "    pbar.update(1)\n",
        "\n",
        "pbar.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        id  label dataset_type\n",
              "0        youtube_04140.jpg      0      youtube\n",
              "1        youtube_02810.jpg      0      youtube\n",
              "2        youtube_05490.jpg      0      youtube\n",
              "3        youtube_03030.jpg      0      youtube\n",
              "4      youtube_00710_2.jpg      0      youtube\n",
              "..                     ...    ...          ...\n",
              "195  Deepfakes_04300_3.jpg      1    Deepfakes\n",
              "196  Deepfakes_07110_2.jpg      1    Deepfakes\n",
              "197    Deepfakes_01520.jpg      1    Deepfakes\n",
              "198  Deepfakes_05470_3.jpg      1    Deepfakes\n",
              "199  Deepfakes_00130_2.jpg      1    Deepfakes\n",
              "\n",
              "[200 rows x 3 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>dataset_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>youtube_04140.jpg</td>\n      <td>0</td>\n      <td>youtube</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>youtube_02810.jpg</td>\n      <td>0</td>\n      <td>youtube</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>youtube_05490.jpg</td>\n      <td>0</td>\n      <td>youtube</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>youtube_03030.jpg</td>\n      <td>0</td>\n      <td>youtube</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>youtube_00710_2.jpg</td>\n      <td>0</td>\n      <td>youtube</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>Deepfakes_04300_3.jpg</td>\n      <td>1</td>\n      <td>Deepfakes</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>Deepfakes_07110_2.jpg</td>\n      <td>1</td>\n      <td>Deepfakes</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>Deepfakes_01520.jpg</td>\n      <td>1</td>\n      <td>Deepfakes</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>Deepfakes_05470_3.jpg</td>\n      <td>1</td>\n      <td>Deepfakes</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>Deepfakes_00130_2.jpg</td>\n      <td>1</td>\n      <td>Deepfakes</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 3 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "df_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_unique_video_names = df_data[\"id\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          youtube_04140.jpg\n",
              "1          youtube_02810.jpg\n",
              "2          youtube_05490.jpg\n",
              "3          youtube_03030.jpg\n",
              "4        youtube_00710_2.jpg\n",
              "               ...          \n",
              "195    Deepfakes_04300_3.jpg\n",
              "196    Deepfakes_07110_2.jpg\n",
              "197      Deepfakes_01520.jpg\n",
              "198    Deepfakes_05470_3.jpg\n",
              "199    Deepfakes_00130_2.jpg\n",
              "Name: id, Length: 200, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "get_unique_video_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "unique_video_name = get_unique_video_names.str.split(\"_\")[:][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0           [youtube, 04140.jpg]\n",
              "1           [youtube, 02810.jpg]\n",
              "2           [youtube, 05490.jpg]\n",
              "3           [youtube, 03030.jpg]\n",
              "4        [youtube, 00710, 2.jpg]\n",
              "                 ...            \n",
              "195    [Deepfakes, 04300, 3.jpg]\n",
              "196    [Deepfakes, 07110, 2.jpg]\n",
              "197       [Deepfakes, 01520.jpg]\n",
              "198    [Deepfakes, 05470, 3.jpg]\n",
              "199    [Deepfakes, 00130, 2.jpg]\n",
              "Name: id, Length: 200, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ],
      "source": [
        "unique_video_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'unique_video_name' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b131534b6b8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munique_video_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munqiue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'unique_video_name' is not defined"
          ]
        }
      ],
      "source": [
        "unique_video_name.str.split(\"_\").unqiue()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['04140.jpg',\n",
              " '02810.jpg',\n",
              " '05490.jpg',\n",
              " '03030.jpg',\n",
              " '00710',\n",
              " '02170',\n",
              " '03720.jpg',\n",
              " '02790.jpg',\n",
              " '01490',\n",
              " '03790.jpg',\n",
              " '01070',\n",
              " '01610.jpg',\n",
              " '01790.jpg',\n",
              " '00410.jpg',\n",
              " '01280',\n",
              " '00250.jpg',\n",
              " '03270.jpg',\n",
              " '02690.jpg',\n",
              " '02730.jpg',\n",
              " '01600',\n",
              " '00180',\n",
              " '01830.jpg',\n",
              " '01620.jpg',\n",
              " '00990',\n",
              " '03110.jpg',\n",
              " '05440.jpg',\n",
              " '02900.jpg',\n",
              " '03610.jpg',\n",
              " '03250.jpg',\n",
              " '02180',\n",
              " '04610.jpg',\n",
              " '00190.jpg',\n",
              " '04500.jpg',\n",
              " '00690.jpg',\n",
              " '04570.jpg',\n",
              " '04130',\n",
              " '01560.jpg',\n",
              " '05060.jpg',\n",
              " '01570.jpg',\n",
              " '01690',\n",
              " '04810',\n",
              " '03750.jpg',\n",
              " '01650.jpg',\n",
              " '00080',\n",
              " '04840',\n",
              " '04050.jpg',\n",
              " '02150.jpg',\n",
              " '01270',\n",
              " '04800.jpg',\n",
              " '04580',\n",
              " '00130.jpg',\n",
              " '02520.jpg',\n",
              " '04000.jpg',\n",
              " '03180.jpg',\n",
              " '00430.jpg',\n",
              " '00800',\n",
              " '01860',\n",
              " '02910',\n",
              " '00870.jpg',\n",
              " '00270.jpg',\n",
              " '01540',\n",
              " '03700.jpg',\n",
              " '00700',\n",
              " '03020.jpg',\n",
              " '05110.jpg',\n",
              " '01410.jpg',\n",
              " '02450.jpg',\n",
              " '03990',\n",
              " '03130.jpg',\n",
              " '01930.jpg',\n",
              " '00090',\n",
              " '02540.jpg',\n",
              " '02770',\n",
              " '04980.jpg',\n",
              " '00390',\n",
              " '01320.jpg',\n",
              " '02500.jpg',\n",
              " '01940.jpg',\n",
              " '00160.jpg',\n",
              " '00890.jpg',\n",
              " '03130',\n",
              " '04410.jpg',\n",
              " '02750.jpg',\n",
              " '03200.jpg',\n",
              " '00400',\n",
              " '01280.jpg',\n",
              " '03440.jpg',\n",
              " '00480.jpg',\n",
              " '00520.jpg',\n",
              " '00550.jpg',\n",
              " '01540',\n",
              " '01680',\n",
              " '01320',\n",
              " '01010',\n",
              " '03050',\n",
              " '00980.jpg',\n",
              " '00100.jpg',\n",
              " '04020.jpg',\n",
              " '04330.jpg',\n",
              " '03080',\n",
              " '06290',\n",
              " '01740.jpg',\n",
              " '06690',\n",
              " '01320',\n",
              " '05370.jpg',\n",
              " '04220',\n",
              " '03850',\n",
              " '04440.jpg',\n",
              " '05640.jpg',\n",
              " '01830.jpg',\n",
              " '02170.jpg',\n",
              " '03210.jpg',\n",
              " '01620',\n",
              " '07270',\n",
              " '04900',\n",
              " '03120',\n",
              " '02260',\n",
              " '04100',\n",
              " '01380.jpg',\n",
              " '01880.jpg',\n",
              " '05500',\n",
              " '01070.jpg',\n",
              " '02160.jpg',\n",
              " '07260.jpg',\n",
              " '03980',\n",
              " '01910.jpg',\n",
              " '03350.jpg',\n",
              " '05050',\n",
              " '02890.jpg',\n",
              " '05170',\n",
              " '06500',\n",
              " '00850',\n",
              " '03370',\n",
              " '07120',\n",
              " '03930',\n",
              " '05960',\n",
              " '06580.jpg',\n",
              " '00490.jpg',\n",
              " '02590.jpg',\n",
              " '01180.jpg',\n",
              " '07660',\n",
              " '01450',\n",
              " '00120',\n",
              " '03690',\n",
              " '00070',\n",
              " '02970.jpg',\n",
              " '07210',\n",
              " '00830.jpg',\n",
              " '03070.jpg',\n",
              " '07570',\n",
              " '00210',\n",
              " '07910',\n",
              " '07890',\n",
              " '05880.jpg',\n",
              " '00980',\n",
              " '06370',\n",
              " '00110.jpg',\n",
              " '08060',\n",
              " '04160.jpg',\n",
              " '06860',\n",
              " '07300',\n",
              " '04180',\n",
              " '05110',\n",
              " '04150',\n",
              " '01300',\n",
              " '02020.jpg',\n",
              " '03810.jpg',\n",
              " '02270',\n",
              " '05420',\n",
              " '00480.jpg',\n",
              " '07130',\n",
              " '00020.jpg',\n",
              " '06900.jpg',\n",
              " '07390.jpg',\n",
              " '00510',\n",
              " '00790.jpg',\n",
              " '06890',\n",
              " '05550',\n",
              " '06140.jpg',\n",
              " '04170',\n",
              " '02280',\n",
              " '02500',\n",
              " '08020',\n",
              " '06450',\n",
              " '07340.jpg',\n",
              " '03340.jpg',\n",
              " '04210',\n",
              " '07250',\n",
              " '06400.jpg',\n",
              " '05080',\n",
              " '07860',\n",
              " '05760',\n",
              " '06720',\n",
              " '07160.jpg',\n",
              " '06940.jpg',\n",
              " '04300',\n",
              " '07110',\n",
              " '01520.jpg',\n",
              " '05470',\n",
              " '00130']"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ],
      "source": [
        "list(list(zip(*unique_video_name))[1]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}