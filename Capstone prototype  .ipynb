{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prototype replicates the approach adopted by Ciftci, Demir & Yin in their paper Synthetic Portrait Videos using Biological Signals. We use the facenet-pytorch package to build a rudimentary deepfake detector without training any models. It also demonstrates a method for (1) loading all video frames, (2) finding all faces, and (3) calculating face embeddings at over 30 frames per second (or greater than 1 video per 10 seconds).\n",
    "The following steps are performed: \n",
    "1. Create pretrained facial detection (MTCNN) and recognition (Inception Resnet) models.\n",
    "2. For each test video, calculate face feature vectors for ALL faces in each video.\n",
    "3. Calculate the distance from each face to the centroid for its video.\n",
    "4. Use these distances as your means of discrimination.\n",
    "5. For (much) better results, finetune the resnet to the fake/real binary classification task instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from facenet_pytorch.models.inception_resnet_v1 import get_torch_home\n",
    "torch_home = get_torch_home()\n",
    "import seaborn as sns\n",
    "# use the face detection pre-trained model from pytorch\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1, extract_face\n",
    "#print wether I am using CPU or CUDAâ€“ used for Google Collab\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Running on device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading parameters (1/2)\n",
      "Downloading parameters (2/2)\n"
     ]
    }
   ],
   "source": [
    "#load the pre-trained model \n",
    "mtcnn = MTCNN(margin=14, keep_all=True, factor=0.5, device=device).eval()\n",
    "# Load facial recognition model\n",
    "resnet = InceptionResnetV1(pretrained='vggface2', device=device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Test Videos\n",
    "After defining a few helper functions, this code loops through all videos and passes all frames from each through the face detector followed by facenet. Finally, we calculate the distance from the centroid to the extracted feature for each face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionPipeline:\n",
    "    \"\"\"Pipeline class for detecting faces in the frames of a video file.\"\"\"\n",
    "    \n",
    "    def __init__(self, detector, n_frames=None, batch_size=60, resize=None):\n",
    "        \"\"\"Constructor for DetectionPipeline class.\n",
    "        \n",
    "        Keyword Arguments:\n",
    "            n_frames {int} -- Total number of frames to load. These will be evenly spaced\n",
    "                throughout the video. If not specified (i.e., None), all frames will be loaded.\n",
    "                (default: {None})\n",
    "            batch_size {int} -- Batch size to use with MTCNN face detector. (default: {32})\n",
    "            resize {float} -- Fraction by which to resize frames from original prior to face\n",
    "                detection. A value less than 1 results in downsampling and a value greater than\n",
    "                1 result in upsampling. (default: {None})\n",
    "        \"\"\"\n",
    "        self.detector = detector\n",
    "        self.n_frames = n_frames\n",
    "        self.batch_size = batch_size\n",
    "        self.resize = resize\n",
    "    \n",
    "    def __call__(self, filename):\n",
    "        \"\"\"Load frames from an MP4 video and detect faces.\n",
    "\n",
    "        Arguments:\n",
    "            filename {str} -- Path to video.\n",
    "        \"\"\"\n",
    "        # Create video reader and find length\n",
    "        v_cap = cv2.VideoCapture(filename)\n",
    "        v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        # Pick 'n_frames' evenly spaced frames to sample\n",
    "        if self.n_frames is None:\n",
    "            sample = np.arange(0, v_len)\n",
    "        else:\n",
    "            sample = np.linspace(0, v_len - 1, self.n_frames).astype(int)\n",
    "\n",
    "        # Loop through frames\n",
    "        faces = []\n",
    "        frames = []\n",
    "        for j in range(v_len):\n",
    "            success = v_cap.grab()\n",
    "            if j in sample:\n",
    "                # Load frame\n",
    "                success, frame = v_cap.retrieve()\n",
    "                if not success:\n",
    "                    continue\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = Image.fromarray(frame)\n",
    "                \n",
    "                # Resize frame to desired size\n",
    "                if self.resize is not None:\n",
    "                    frame = frame.resize([int(d * self.resize) for d in frame.size])\n",
    "                frames.append(frame)\n",
    "\n",
    "                # When batch is full, detect faces and reset frame list\n",
    "                if len(frames) % self.batch_size == 0 or j == sample[-1]:\n",
    "                    faces.extend(self.detector(frames))\n",
    "                    frames = []\n",
    "\n",
    "        v_cap.release()\n",
    "\n",
    "        return faces    \n",
    "\n",
    "\n",
    "def process_faces(faces, resnet):\n",
    "    # Filter out frames without faces\n",
    "    faces = [f for f in faces if f is not None]\n",
    "    faces = torch.cat(faces).to(device)\n",
    "\n",
    "    # Generate facial feature vectors using a pretrained model\n",
    "    embeddings = resnet(faces)\n",
    "\n",
    "    # Calculate centroid for video and distance of each face's feature vector from centroid\n",
    "    centroid = embeddings.mean(dim=0)\n",
    "    x = (embeddings - centroid).norm(dim=1).cpu().numpy()\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict classes\n",
    "The below weights were selected by following the same process as above for the train sample videos and then using a logistic regression model to fit to the labels. Note that, intuitively, this is not a very good approach as it does nothing to take into account the progression of feature vectors throughout a video, just combines them together using the weights below. This step is provided as a placeholder only; it should be replaced with a more thoughtful mapping from a sequence of feature vectors to a single prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8ab5a97f6e4b9085eecf0c571a79cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=58.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second (load+detect+embed):  0.375\n"
     ]
    }
   ],
   "source": [
    "# Define face detection pipeline\n",
    "detection_pipeline = DetectionPipeline(detector=mtcnn, batch_size=60, resize=0.25)\n",
    "\n",
    "# Get all test videos\n",
    "filenames = glob.glob('/Users/asmaaaly/Downloads/test_videos/test_final/*.mp4')\n",
    "\n",
    "X = []\n",
    "start = time.time()\n",
    "n_processed = 0\n",
    "with torch.no_grad():\n",
    "    for i, filename in tqdm(enumerate(filenames), total=len(filenames)):\n",
    "        try:\n",
    "            # Load frames and find faces\n",
    "            faces = detection_pipeline(filename)\n",
    "            \n",
    "            # Calculate embeddings\n",
    "            X.append(process_faces(faces, resnet))\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print('\\nStopped.')\n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            X.append(None)\n",
    "        \n",
    "        n_processed += len(faces)\n",
    "        print(f'Frames per second (load+detect+embed): {n_processed / (time.time() - start):6.3}\\r', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = -0.2942\n",
    "weight = 0.68235746\n",
    "\n",
    "results = []\n",
    "for filename, x_i in zip(filenames, X):\n",
    "    if x_i is not None:\n",
    "        prob = 1 / (1 + np.exp(-(bias + (weight * x_i).mean())))\n",
    "    else:\n",
    "        prob = 0.5\n",
    "    results.append([os.path.basename(filename), prob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame(results, columns=['filename', 'label'])\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.hist(results.label, 20)\n",
    "plt.xlabel(\"Probability of Being Deep Fake\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
